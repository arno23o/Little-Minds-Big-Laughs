{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c2486ab568c48668f9e587d050adbc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8682670140a84d81a5bc1c63321af38b",
              "IPY_MODEL_3dcc8ad29a06498ba99a7709350dd3d1",
              "IPY_MODEL_1c89e57832fa43a398c1201c44737b81"
            ],
            "layout": "IPY_MODEL_2ef9c694f12b4947bf29d63cdddc94f0"
          }
        },
        "8682670140a84d81a5bc1c63321af38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28f12f97eb3a46f2a4e732d3fa3ee8f8",
            "placeholder": "​",
            "style": "IPY_MODEL_ca6549fbd75d479a95b7a21c7bba45fc",
            "value": "Saving the dataset (2/2 shards): 100%"
          }
        },
        "3dcc8ad29a06498ba99a7709350dd3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4f3d36966774a1780c493a5fd510a76",
            "max": 9576,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54591deb5e674a64810de031bb8bc9a1",
            "value": 9576
          }
        },
        "1c89e57832fa43a398c1201c44737b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbb3c05d5392427a9cb18f3d6e1fadac",
            "placeholder": "​",
            "style": "IPY_MODEL_ff80cbd812e2449a878743cbaa45047f",
            "value": " 9576/9576 [00:12&lt;00:00, 884.60 examples/s]"
          }
        },
        "2ef9c694f12b4947bf29d63cdddc94f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f12f97eb3a46f2a4e732d3fa3ee8f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca6549fbd75d479a95b7a21c7bba45fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4f3d36966774a1780c493a5fd510a76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54591deb5e674a64810de031bb8bc9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbb3c05d5392427a9cb18f3d6e1fadac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff80cbd812e2449a878743cbaa45047f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20e89c0f6e4a436cb8461b4775cc655f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06749ce4b31443e1887f1adcdb8a6aa5",
              "IPY_MODEL_eb89dce99d644875b636a09c1651e783",
              "IPY_MODEL_bb03df03220a49bb8812dbb8fac5ed0a"
            ],
            "layout": "IPY_MODEL_67d3d38e4e494279b0ec604842333135"
          }
        },
        "06749ce4b31443e1887f1adcdb8a6aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_298500e6de0048599d79e74f19864d73",
            "placeholder": "​",
            "style": "IPY_MODEL_a389a824c2f34b389a332101987fe2e0",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "eb89dce99d644875b636a09c1651e783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_027a6d82c2a9434fbe89073d49e62849",
            "max": 507,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_856c5040f14e4f6189e4de47c5d78dc8",
            "value": 507
          }
        },
        "bb03df03220a49bb8812dbb8fac5ed0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a686c6f461b144699ce64c37752fd218",
            "placeholder": "​",
            "style": "IPY_MODEL_57a914b9c92a4cabafe15621c60c0a71",
            "value": " 507/507 [00:00&lt;00:00, 2676.72 examples/s]"
          }
        },
        "67d3d38e4e494279b0ec604842333135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298500e6de0048599d79e74f19864d73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a389a824c2f34b389a332101987fe2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "027a6d82c2a9434fbe89073d49e62849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "856c5040f14e4f6189e4de47c5d78dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a686c6f461b144699ce64c37752fd218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57a914b9c92a4cabafe15621c60c0a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65047322e629450eb4bc74457b51570f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1bc8def9ad64e89ab737f998dc64d8a",
              "IPY_MODEL_169d346a9d1b452da85eb313186275b4",
              "IPY_MODEL_fe918761c26849ebbf932e6be094290c"
            ],
            "layout": "IPY_MODEL_fafd747a4f564675b3c7c37650e6e65b"
          }
        },
        "c1bc8def9ad64e89ab737f998dc64d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a5c906a63ef4effb4d4fe9b641abf82",
            "placeholder": "​",
            "style": "IPY_MODEL_cd3731c3ca654db68371c84220455491",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "169d346a9d1b452da85eb313186275b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ab6b99f62734a139282b4d503254136",
            "max": 513,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f902e34a0fb24c9992022a354295c46b",
            "value": 513
          }
        },
        "fe918761c26849ebbf932e6be094290c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_371830efaef346a989ccbf032b237979",
            "placeholder": "​",
            "style": "IPY_MODEL_d33ebb6320ee4c0a818d98209cb9ef21",
            "value": " 513/513 [00:00&lt;00:00, 3172.87 examples/s]"
          }
        },
        "fafd747a4f564675b3c7c37650e6e65b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a5c906a63ef4effb4d4fe9b641abf82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd3731c3ca654db68371c84220455491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ab6b99f62734a139282b4d503254136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f902e34a0fb24c9992022a354295c46b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "371830efaef346a989ccbf032b237979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d33ebb6320ee4c0a818d98209cb9ef21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70668bcb7889461fa8c98b7d5115469c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e4c54cb68a943aabe0ef60cfd0859d8",
              "IPY_MODEL_54cfedb2de084c9886b0a1c4f7cce872",
              "IPY_MODEL_5275aa15b6c74bdc8bc864779577471c"
            ],
            "layout": "IPY_MODEL_bfd483664f674b709bcd56723372a200"
          }
        },
        "7e4c54cb68a943aabe0ef60cfd0859d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57af0820e1114beebd1616e1df7df806",
            "placeholder": "​",
            "style": "IPY_MODEL_8d61fab0248d4d9bb16391dbb0d22103",
            "value": "Saving the dataset (2/2 shards): 100%"
          }
        },
        "54cfedb2de084c9886b0a1c4f7cce872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3acc1037b7ba4b34aec9eaab195083ce",
            "max": 9792,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d0565d893ed4fceb861411fa428855a",
            "value": 9792
          }
        },
        "5275aa15b6c74bdc8bc864779577471c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_609d83d6e3ba4b6da9304a75f87ebf1d",
            "placeholder": "​",
            "style": "IPY_MODEL_54a450d316dc4bec9ffe46167715cc16",
            "value": " 9792/9792 [00:07&lt;00:00, 1317.73 examples/s]"
          }
        },
        "bfd483664f674b709bcd56723372a200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57af0820e1114beebd1616e1df7df806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d61fab0248d4d9bb16391dbb0d22103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3acc1037b7ba4b34aec9eaab195083ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d0565d893ed4fceb861411fa428855a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "609d83d6e3ba4b6da9304a75f87ebf1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54a450d316dc4bec9ffe46167715cc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbe9c6ae4b434892836fee2c6cc5e759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f09344fac484d5eaf6df9bdb6ab005e",
              "IPY_MODEL_3cf57d56281045ac9719120a850bc553",
              "IPY_MODEL_e0e3a1ad977f4124ad750c4abc2aa3ee"
            ],
            "layout": "IPY_MODEL_348188e0b1b547aeb7bc3fb985aff206"
          }
        },
        "8f09344fac484d5eaf6df9bdb6ab005e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34b73dc8bf8d41e994f7d1e99694ddef",
            "placeholder": "​",
            "style": "IPY_MODEL_b5a38db529d744839517bfbbf883ab91",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "3cf57d56281045ac9719120a850bc553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7c1a582ecd74af2ac3ed68cdced5437",
            "max": 531,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb2b2f0cf66e4db083bcd7a5dc074c3b",
            "value": 531
          }
        },
        "e0e3a1ad977f4124ad750c4abc2aa3ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f991b13c8ea4acd97bc9bbc325b70c8",
            "placeholder": "​",
            "style": "IPY_MODEL_d407e5df32fe44a2aebf333b76805a2a",
            "value": " 531/531 [00:00&lt;00:00, 2711.96 examples/s]"
          }
        },
        "348188e0b1b547aeb7bc3fb985aff206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34b73dc8bf8d41e994f7d1e99694ddef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5a38db529d744839517bfbbf883ab91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7c1a582ecd74af2ac3ed68cdced5437": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb2b2f0cf66e4db083bcd7a5dc074c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f991b13c8ea4acd97bc9bbc325b70c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d407e5df32fe44a2aebf333b76805a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbe1c6762ced443181e44c3c1e00e4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49b7b1b2ef474a5395a7a48a533a3956",
              "IPY_MODEL_6f14bc587ea540e0bf6983acb9d77149",
              "IPY_MODEL_0db9632448654af6a657a9da5285ad87"
            ],
            "layout": "IPY_MODEL_8bf3eb214604482b8d0e06bca58e7bee"
          }
        },
        "49b7b1b2ef474a5395a7a48a533a3956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34bb8648b3994413917ca8aef56179b7",
            "placeholder": "​",
            "style": "IPY_MODEL_11687c41e34c434a9e997a7a11d19732",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "6f14bc587ea540e0bf6983acb9d77149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e9b870046334b079084510181fd1b0b",
            "max": 528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c5073a128ba479988256328bbea22ef",
            "value": 528
          }
        },
        "0db9632448654af6a657a9da5285ad87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e965742554ed45e183708df4c7b93ab7",
            "placeholder": "​",
            "style": "IPY_MODEL_e4efb56e05df435a88eae907419fdac4",
            "value": " 528/528 [00:00&lt;00:00, 3070.35 examples/s]"
          }
        },
        "8bf3eb214604482b8d0e06bca58e7bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34bb8648b3994413917ca8aef56179b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11687c41e34c434a9e997a7a11d19732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e9b870046334b079084510181fd1b0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c5073a128ba479988256328bbea22ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e965742554ed45e183708df4c7b93ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4efb56e05df435a88eae907419fdac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "563137ff15024e9583c539a18c79214a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9efcc99f29434126888ad25b729133e6",
              "IPY_MODEL_4bde4134aab740eb9de8aa5a1c68a277",
              "IPY_MODEL_7287a8ddb30b486a83f8c37b8f61b2c8",
              "IPY_MODEL_1ab0381f5ff4464f882632bac6e2fbb4"
            ],
            "layout": "IPY_MODEL_5b709cf4b1ae4782b5384f562ad92b82"
          }
        },
        "e479392627c34241a3df06714660d22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef790356ca074f4088f329de112f72d1",
            "placeholder": "​",
            "style": "IPY_MODEL_ac3f876d723d4b6a8784f68b291ab1eb",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "49270bb5fb8a458a987940251933b4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b2300af3983443df937b777fee04e7eb",
            "placeholder": "​",
            "style": "IPY_MODEL_7c3af8e0734c429c835d771658885f1d",
            "value": ""
          }
        },
        "4ba9fa0053024eada40e7f526db9fc71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_854e4cc6f5c24ecf881c8d17fdb4f4ad",
            "style": "IPY_MODEL_9fa91ceb315346ad95b4d24055bf64c8",
            "value": true
          }
        },
        "4c0217545a9a4b6394e7619682cebc17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_85a5b6012645487fbf8c77f219a18567",
            "style": "IPY_MODEL_fafbf783fe894ac897c0d9ea49aafd56",
            "tooltip": ""
          }
        },
        "7cc39e103c3541a880c60fd79b006192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c450a68f8ce246d986d53bf206681e63",
            "placeholder": "​",
            "style": "IPY_MODEL_3660dada3c0743c09c4c10a9d630374e",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "5b709cf4b1ae4782b5384f562ad92b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "ef790356ca074f4088f329de112f72d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac3f876d723d4b6a8784f68b291ab1eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2300af3983443df937b777fee04e7eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c3af8e0734c429c835d771658885f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "854e4cc6f5c24ecf881c8d17fdb4f4ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fa91ceb315346ad95b4d24055bf64c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85a5b6012645487fbf8c77f219a18567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fafbf783fe894ac897c0d9ea49aafd56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "c450a68f8ce246d986d53bf206681e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3660dada3c0743c09c4c10a9d630374e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ea63e1bd95d4cfbb6ffaaaebdb4f8bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc473da4e09c40de8947671da1180631",
            "placeholder": "​",
            "style": "IPY_MODEL_3829e16b464745da8113ac2c35a316cc",
            "value": "Connecting..."
          }
        },
        "cc473da4e09c40de8947671da1180631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3829e16b464745da8113ac2c35a316cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9efcc99f29434126888ad25b729133e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d8fdd8c6de947c8b135e04aac6da32a",
            "placeholder": "​",
            "style": "IPY_MODEL_110ac94a36c1418eb2c0efd58bb957be",
            "value": "Token is valid (permission: write)."
          }
        },
        "4bde4134aab740eb9de8aa5a1c68a277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_985209f20a3841a99a5064fce809e588",
            "placeholder": "​",
            "style": "IPY_MODEL_1f22876faac447ae8ad07d60b1b825f1",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "7287a8ddb30b486a83f8c37b8f61b2c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c98b3ba18b3e4931b2b51ca19b878bd1",
            "placeholder": "​",
            "style": "IPY_MODEL_b4f21d4ba99f4408ae5b1153945356a4",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "1ab0381f5ff4464f882632bac6e2fbb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe2705903cb24fa0b56624ef70e9cc24",
            "placeholder": "​",
            "style": "IPY_MODEL_1abb1466ed124ecda32a2de4c83b630b",
            "value": "Login successful"
          }
        },
        "4d8fdd8c6de947c8b135e04aac6da32a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "110ac94a36c1418eb2c0efd58bb957be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "985209f20a3841a99a5064fce809e588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f22876faac447ae8ad07d60b1b825f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c98b3ba18b3e4931b2b51ca19b878bd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f21d4ba99f4408ae5b1153945356a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe2705903cb24fa0b56624ef70e9cc24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1abb1466ed124ecda32a2de4c83b630b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d423c815a6f14cb88cb0675f9dd737dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10feffe0d442411b98ae122de57de471",
              "IPY_MODEL_d5e1515d9bc9488fb3a35da5e57e6423",
              "IPY_MODEL_efe4c4fc13604097931bb64145adbf5f"
            ],
            "layout": "IPY_MODEL_7daaecf1cf3f44f198e56ebdfcd9ebcd"
          }
        },
        "10feffe0d442411b98ae122de57de471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e1ecf3a31e24d1eae094c109e66cf36",
            "placeholder": "​",
            "style": "IPY_MODEL_7f1e06efe91c4df8a35dd6a1594a6eb7",
            "value": "config.json: 100%"
          }
        },
        "d5e1515d9bc9488fb3a35da5e57e6423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e58be1cce5145f2b8506d1e6526cb5a",
            "max": 596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_401ad267d8a648c5ac7765f34d576498",
            "value": 596
          }
        },
        "efe4c4fc13604097931bb64145adbf5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_370df8d917c6419fa2fb4355a5aba79a",
            "placeholder": "​",
            "style": "IPY_MODEL_fcc7cc9d25104a9c8d93db20af4b826a",
            "value": " 596/596 [00:00&lt;00:00, 46.0kB/s]"
          }
        },
        "7daaecf1cf3f44f198e56ebdfcd9ebcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e1ecf3a31e24d1eae094c109e66cf36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f1e06efe91c4df8a35dd6a1594a6eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e58be1cce5145f2b8506d1e6526cb5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401ad267d8a648c5ac7765f34d576498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "370df8d917c6419fa2fb4355a5aba79a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcc7cc9d25104a9c8d93db20af4b826a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53fa0672af804a9a9055f81a12e74c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a96d5283337e474e83d32207fcdc287f",
              "IPY_MODEL_d6ba7162c5ea497193abb478b813a4ab",
              "IPY_MODEL_f6b5836b328449a99dea9518b3579003"
            ],
            "layout": "IPY_MODEL_bc62137bc9b1476296ed08757ddf0509"
          }
        },
        "a96d5283337e474e83d32207fcdc287f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56ec430fc3504ec8bd474c1a8defac09",
            "placeholder": "​",
            "style": "IPY_MODEL_5aef0abb07cd4846a216597dbb1d6d45",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "d6ba7162c5ea497193abb478b813a4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f923007f5dd74f3a9257cdc95ac22e02",
            "max": 25125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffa829aff807408e8ae4a25d627c5767",
            "value": 25125
          }
        },
        "f6b5836b328449a99dea9518b3579003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2be5680d533c49bd96b8d5194ec675fa",
            "placeholder": "​",
            "style": "IPY_MODEL_61dc0bb2bc404c32b50daa7158e6506b",
            "value": " 25.1k/25.1k [00:00&lt;00:00, 2.24MB/s]"
          }
        },
        "bc62137bc9b1476296ed08757ddf0509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ec430fc3504ec8bd474c1a8defac09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aef0abb07cd4846a216597dbb1d6d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f923007f5dd74f3a9257cdc95ac22e02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa829aff807408e8ae4a25d627c5767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2be5680d533c49bd96b8d5194ec675fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61dc0bb2bc404c32b50daa7158e6506b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bd3bd95af4040f588eb68898679245d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa572e76a5804f829c58c54e037f3bae",
              "IPY_MODEL_fcd4d8045c13450c8bc1a9b340727904",
              "IPY_MODEL_17c0c54fb7a14284bd09591a9861c379"
            ],
            "layout": "IPY_MODEL_b766520ef0224597b2916c8a580e8e25"
          }
        },
        "aa572e76a5804f829c58c54e037f3bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afdf7843a79f4e9f8009b7d5ffd93cb0",
            "placeholder": "​",
            "style": "IPY_MODEL_82c6dcf3393146b9a6207e3c52c9b248",
            "value": "Downloading shards: 100%"
          }
        },
        "fcd4d8045c13450c8bc1a9b340727904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_674a51787adb4536b285c21202aef178",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7286782384834e3aa9c6f23c7295fe71",
            "value": 3
          }
        },
        "17c0c54fb7a14284bd09591a9861c379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b86f4236e5434f8f9ae2f1b12afd81ce",
            "placeholder": "​",
            "style": "IPY_MODEL_bcc013f44ab54208bf1180fa996bb89d",
            "value": " 3/3 [00:43&lt;00:00, 13.97s/it]"
          }
        },
        "b766520ef0224597b2916c8a580e8e25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afdf7843a79f4e9f8009b7d5ffd93cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82c6dcf3393146b9a6207e3c52c9b248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "674a51787adb4536b285c21202aef178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7286782384834e3aa9c6f23c7295fe71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b86f4236e5434f8f9ae2f1b12afd81ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcc013f44ab54208bf1180fa996bb89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3b2e07cd3404a41a2dc052790696fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30638e9716104e2bb1d7f260c8c9dbdd",
              "IPY_MODEL_b556dee7feaa4429854622aa0c5db6e2",
              "IPY_MODEL_61ab8fac47aa40e29c1eb153483cfbee"
            ],
            "layout": "IPY_MODEL_5d19e1ec2cbe4db2bdf07d89a942f1db"
          }
        },
        "30638e9716104e2bb1d7f260c8c9dbdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed90a1e2afd64d47ad9513a56f4c57b0",
            "placeholder": "​",
            "style": "IPY_MODEL_29bbe5a8b6b64469809b4243d6a02e05",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "b556dee7feaa4429854622aa0c5db6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dd239e8900644b089bd3b776180b292",
            "max": 4943162336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4b4c43ea99c4593af30d78cdc221353",
            "value": 4943162336
          }
        },
        "61ab8fac47aa40e29c1eb153483cfbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75a212c0201a4c429c2bb5a4881f09de",
            "placeholder": "​",
            "style": "IPY_MODEL_1f9b7744f2714ceeb1d5750691897297",
            "value": " 4.94G/4.94G [00:14&lt;00:00, 241MB/s]"
          }
        },
        "5d19e1ec2cbe4db2bdf07d89a942f1db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed90a1e2afd64d47ad9513a56f4c57b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29bbe5a8b6b64469809b4243d6a02e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dd239e8900644b089bd3b776180b292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b4c43ea99c4593af30d78cdc221353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75a212c0201a4c429c2bb5a4881f09de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9b7744f2714ceeb1d5750691897297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00f4641434994bc8a1bafbcab7c25243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e2b253e8f37475eb4fc94d9c99eef04",
              "IPY_MODEL_974b3aa3c0b64c4abbb79e25560ee3fa",
              "IPY_MODEL_b3a6e3691cc54dc2b1845c3e60c7d3a2"
            ],
            "layout": "IPY_MODEL_70f47297a4204432b5b5faca2131b1f7"
          }
        },
        "6e2b253e8f37475eb4fc94d9c99eef04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45feda5d5a3d4131b9df04d514e4e490",
            "placeholder": "​",
            "style": "IPY_MODEL_97e33f068bd74ad6a009c819836966d5",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "974b3aa3c0b64c4abbb79e25560ee3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9718fb2ef8714fa38aad9ce1ac5e7333",
            "max": 4999819336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37bb3a69e80a48e488e2444710cd3d02",
            "value": 4999819336
          }
        },
        "b3a6e3691cc54dc2b1845c3e60c7d3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23a36e97f3a4081bdb1076a479ba41b",
            "placeholder": "​",
            "style": "IPY_MODEL_2e5ea8daaf374ace9d830ec7e67ff77e",
            "value": " 5.00G/5.00G [00:15&lt;00:00, 267MB/s]"
          }
        },
        "70f47297a4204432b5b5faca2131b1f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45feda5d5a3d4131b9df04d514e4e490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97e33f068bd74ad6a009c819836966d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9718fb2ef8714fa38aad9ce1ac5e7333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37bb3a69e80a48e488e2444710cd3d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e23a36e97f3a4081bdb1076a479ba41b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e5ea8daaf374ace9d830ec7e67ff77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a84fa9a9e754485b9065cce3798adaf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_069cf6eaaf304a9cbd066a8be0f099fb",
              "IPY_MODEL_22d0dfe1ef9f431dbca305377e544732",
              "IPY_MODEL_4bce63da270c406ca763ad5e41003ce8"
            ],
            "layout": "IPY_MODEL_129f83b657784a9cb962413293899596"
          }
        },
        "069cf6eaaf304a9cbd066a8be0f099fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47be0c45efdf4c0cb4982a233efb76eb",
            "placeholder": "​",
            "style": "IPY_MODEL_e3622f312e5e40fa88575643e7922e21",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "22d0dfe1ef9f431dbca305377e544732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d447279827ce4ba5addd7118b35fdb4d",
            "max": 4540516344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cc899e164ad43e9bcda3565828519a2",
            "value": 4540516344
          }
        },
        "4bce63da270c406ca763ad5e41003ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_489305cf029242ddbdcb89855cb9d0cb",
            "placeholder": "​",
            "style": "IPY_MODEL_8a5280ddc7434eebb3662ab2eed093de",
            "value": " 4.54G/4.54G [00:11&lt;00:00, 425MB/s]"
          }
        },
        "129f83b657784a9cb962413293899596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47be0c45efdf4c0cb4982a233efb76eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3622f312e5e40fa88575643e7922e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d447279827ce4ba5addd7118b35fdb4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cc899e164ad43e9bcda3565828519a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "489305cf029242ddbdcb89855cb9d0cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a5280ddc7434eebb3662ab2eed093de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f83a8231acf4a70a03019383a39d8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ab3851540364a359ed50d13c35a0804",
              "IPY_MODEL_d6aac001353949768ebe5e4dc2f6be04",
              "IPY_MODEL_54b8eb53d59642b09679e9d978054a1d"
            ],
            "layout": "IPY_MODEL_b9e970e7700c4478a631d255bddb17b0"
          }
        },
        "3ab3851540364a359ed50d13c35a0804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65179c1c94e546c3ac107905a31d7e6a",
            "placeholder": "​",
            "style": "IPY_MODEL_841ad177ce6145959df327e3c0de5239",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d6aac001353949768ebe5e4dc2f6be04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_968acba969ca44baa9f5c1896d8cec72",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6381ed512b244f26a19686ff3f212fc1",
            "value": 3
          }
        },
        "54b8eb53d59642b09679e9d978054a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a70d4b1ac04d5da4d20d91621fd409",
            "placeholder": "​",
            "style": "IPY_MODEL_e46235015f9240c2bdb91b8f3b15083e",
            "value": " 3/3 [00:10&lt;00:00,  3.37s/it]"
          }
        },
        "b9e970e7700c4478a631d255bddb17b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65179c1c94e546c3ac107905a31d7e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "841ad177ce6145959df327e3c0de5239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "968acba969ca44baa9f5c1896d8cec72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6381ed512b244f26a19686ff3f212fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68a70d4b1ac04d5da4d20d91621fd409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46235015f9240c2bdb91b8f3b15083e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4260d300e454b44b2aec856c06f2d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8136f00eb6a4e9eb47683b9167276ed",
              "IPY_MODEL_d08bde7044f941c29c86f52d36119e6b",
              "IPY_MODEL_0cc914afe03744ec87055accb35e5ff6"
            ],
            "layout": "IPY_MODEL_1e6eeab3610142279edf5b7ae48deb3b"
          }
        },
        "c8136f00eb6a4e9eb47683b9167276ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_051e0ed1bd7f48c2b4a0b144ec342eb2",
            "placeholder": "​",
            "style": "IPY_MODEL_a45b7ddabdc8404c81efdb2d6af91e5e",
            "value": "generation_config.json: 100%"
          }
        },
        "d08bde7044f941c29c86f52d36119e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15785e15b42f45bf8ababe161fe275f9",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_022c8bf135bd40b78302ebc9b3cee5dd",
            "value": 111
          }
        },
        "0cc914afe03744ec87055accb35e5ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ff37ef5d69c4288a96d95db20abf06d",
            "placeholder": "​",
            "style": "IPY_MODEL_6d2a2c33695f4547a407096559b05892",
            "value": " 111/111 [00:00&lt;00:00, 8.79kB/s]"
          }
        },
        "1e6eeab3610142279edf5b7ae48deb3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "051e0ed1bd7f48c2b4a0b144ec342eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a45b7ddabdc8404c81efdb2d6af91e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15785e15b42f45bf8ababe161fe275f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022c8bf135bd40b78302ebc9b3cee5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ff37ef5d69c4288a96d95db20abf06d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d2a2c33695f4547a407096559b05892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10fe092112e543a8bd4275160b3b7fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_668c1e6c9cdc4cf8be450ef4cb7305de",
              "IPY_MODEL_1aea08eec4e84dd89cb36c4b58cd6e59",
              "IPY_MODEL_50e76cbddfef4d67897c71b8aebcee15"
            ],
            "layout": "IPY_MODEL_ea6dd2b0debb48039a1c437841a98a88"
          }
        },
        "668c1e6c9cdc4cf8be450ef4cb7305de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_156cd1918f6349e1b64dd7ce009a6869",
            "placeholder": "​",
            "style": "IPY_MODEL_8c153e0a0b6349cca3983d8cd9532e83",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1aea08eec4e84dd89cb36c4b58cd6e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96b89637fec54272a2256a0d1259f634",
            "max": 1460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52af47cde839423e9e6a8c95c6dea041",
            "value": 1460
          }
        },
        "50e76cbddfef4d67897c71b8aebcee15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5da7af1207e4782a218f24b321bd7b2",
            "placeholder": "​",
            "style": "IPY_MODEL_ea38466cd77a46bf8e63b3a295ca06c5",
            "value": " 1.46k/1.46k [00:00&lt;00:00, 114kB/s]"
          }
        },
        "ea6dd2b0debb48039a1c437841a98a88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "156cd1918f6349e1b64dd7ce009a6869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c153e0a0b6349cca3983d8cd9532e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96b89637fec54272a2256a0d1259f634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52af47cde839423e9e6a8c95c6dea041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5da7af1207e4782a218f24b321bd7b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea38466cd77a46bf8e63b3a295ca06c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d663211fe4404597a46c8bfe7ffe8c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d91429834d4c487e9f4f106eabb619f9",
              "IPY_MODEL_d4fe8d158f5144b7b80b41838afa08e0",
              "IPY_MODEL_adeb9c5efdc846289fb79945af5d720f"
            ],
            "layout": "IPY_MODEL_5198506dc5a64ab18927760c1d55ca2c"
          }
        },
        "d91429834d4c487e9f4f106eabb619f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_937ed855afe74933b9acebad6cb5ccdd",
            "placeholder": "​",
            "style": "IPY_MODEL_8acad6ebfcce4298972041e14a8b8044",
            "value": "tokenizer.model: 100%"
          }
        },
        "d4fe8d158f5144b7b80b41838afa08e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d5f325808ae4c99a9b8f31665e0e185",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_500f878234d84104b04632dc12602678",
            "value": 493443
          }
        },
        "adeb9c5efdc846289fb79945af5d720f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff59a661339c45299e8299148345e31b",
            "placeholder": "​",
            "style": "IPY_MODEL_529c185ce1114fef923f35e4c76acb07",
            "value": " 493k/493k [00:00&lt;00:00, 32.5MB/s]"
          }
        },
        "5198506dc5a64ab18927760c1d55ca2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "937ed855afe74933b9acebad6cb5ccdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8acad6ebfcce4298972041e14a8b8044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d5f325808ae4c99a9b8f31665e0e185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "500f878234d84104b04632dc12602678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff59a661339c45299e8299148345e31b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529c185ce1114fef923f35e4c76acb07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08c93057e17444e596b98e4102e824a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_241b893bb6f9448da201995368167a29",
              "IPY_MODEL_c46116a4b53c45b291211c6000946e41",
              "IPY_MODEL_a97687f24e7749ba8dcfe59b9ebe51de"
            ],
            "layout": "IPY_MODEL_8764a2a1bf474ede9612f0b4033cf50f"
          }
        },
        "241b893bb6f9448da201995368167a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3617acdec674200b14eb2b7d3dcaaa5",
            "placeholder": "​",
            "style": "IPY_MODEL_7403f70a7e094da3b5ca4bd991e47aaf",
            "value": "tokenizer.json: 100%"
          }
        },
        "c46116a4b53c45b291211c6000946e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1c21831a8074c47b68adbbbedc2c6cc",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6112e893c9654dabaef0a439e14d72cf",
            "value": 1795303
          }
        },
        "a97687f24e7749ba8dcfe59b9ebe51de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aff7bff425c745de82574b42bd4125a4",
            "placeholder": "​",
            "style": "IPY_MODEL_6964c0ad56774775b1907f7972ab1870",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 1.96MB/s]"
          }
        },
        "8764a2a1bf474ede9612f0b4033cf50f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3617acdec674200b14eb2b7d3dcaaa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7403f70a7e094da3b5ca4bd991e47aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1c21831a8074c47b68adbbbedc2c6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6112e893c9654dabaef0a439e14d72cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aff7bff425c745de82574b42bd4125a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6964c0ad56774775b1907f7972ab1870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ea65d35c7924b2e89dd088c82290805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75f7af5e48c249e898d545034e4ccf12",
              "IPY_MODEL_a8a050ea7988478fb0aa5ca0953f04f4",
              "IPY_MODEL_aeaf298fcef3403bb8c8ec6d410f5714"
            ],
            "layout": "IPY_MODEL_86771cebb0a4496bbd797c5a2fc8e9b9"
          }
        },
        "75f7af5e48c249e898d545034e4ccf12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32f0833440fc4e77a229e03896732d57",
            "placeholder": "​",
            "style": "IPY_MODEL_71b8dbc8e1694b7dbfcb1ca6536bcbf2",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a8a050ea7988478fb0aa5ca0953f04f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8637e2bed59047a492ded210d0c3447b",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73c7194bf313484d95e5a7e296ad65b0",
            "value": 72
          }
        },
        "aeaf298fcef3403bb8c8ec6d410f5714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edb666808ee2406e819fa39f67a71fb7",
            "placeholder": "​",
            "style": "IPY_MODEL_1fc5a0dfd19a49dcaaf61cba8b825477",
            "value": " 72.0/72.0 [00:00&lt;00:00, 4.85kB/s]"
          }
        },
        "86771cebb0a4496bbd797c5a2fc8e9b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32f0833440fc4e77a229e03896732d57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b8dbc8e1694b7dbfcb1ca6536bcbf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8637e2bed59047a492ded210d0c3447b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73c7194bf313484d95e5a7e296ad65b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edb666808ee2406e819fa39f67a71fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fc5a0dfd19a49dcaaf61cba8b825477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Set-up: Google Drive Mounting, NYer Cartoon Dataset Load from Drive\n",
        "\n"
      ],
      "metadata": {
        "id": "BGPRIivcxZ0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TfgOrHjFugZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acfb17c2-9420-4ea5-f55e-dbbe0cf590e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abk4Sv8bqr6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da3d57b-62af-43c5-dc53-76d42d271675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.22.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dset2.save_to_disk('/content/drive/My Drive//NLP Humor Data/ranking_dataset')\n",
        "# dset1.save_to_disk('/content/drive/My Drive//NLP Humor Data/matching_dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "5c2486ab568c48668f9e587d050adbc8",
            "8682670140a84d81a5bc1c63321af38b",
            "3dcc8ad29a06498ba99a7709350dd3d1",
            "1c89e57832fa43a398c1201c44737b81",
            "2ef9c694f12b4947bf29d63cdddc94f0",
            "28f12f97eb3a46f2a4e732d3fa3ee8f8",
            "ca6549fbd75d479a95b7a21c7bba45fc",
            "e4f3d36966774a1780c493a5fd510a76",
            "54591deb5e674a64810de031bb8bc9a1",
            "dbb3c05d5392427a9cb18f3d6e1fadac",
            "ff80cbd812e2449a878743cbaa45047f",
            "20e89c0f6e4a436cb8461b4775cc655f",
            "06749ce4b31443e1887f1adcdb8a6aa5",
            "eb89dce99d644875b636a09c1651e783",
            "bb03df03220a49bb8812dbb8fac5ed0a",
            "67d3d38e4e494279b0ec604842333135",
            "298500e6de0048599d79e74f19864d73",
            "a389a824c2f34b389a332101987fe2e0",
            "027a6d82c2a9434fbe89073d49e62849",
            "856c5040f14e4f6189e4de47c5d78dc8",
            "a686c6f461b144699ce64c37752fd218",
            "57a914b9c92a4cabafe15621c60c0a71",
            "65047322e629450eb4bc74457b51570f",
            "c1bc8def9ad64e89ab737f998dc64d8a",
            "169d346a9d1b452da85eb313186275b4",
            "fe918761c26849ebbf932e6be094290c",
            "fafd747a4f564675b3c7c37650e6e65b",
            "2a5c906a63ef4effb4d4fe9b641abf82",
            "cd3731c3ca654db68371c84220455491",
            "1ab6b99f62734a139282b4d503254136",
            "f902e34a0fb24c9992022a354295c46b",
            "371830efaef346a989ccbf032b237979",
            "d33ebb6320ee4c0a818d98209cb9ef21",
            "70668bcb7889461fa8c98b7d5115469c",
            "7e4c54cb68a943aabe0ef60cfd0859d8",
            "54cfedb2de084c9886b0a1c4f7cce872",
            "5275aa15b6c74bdc8bc864779577471c",
            "bfd483664f674b709bcd56723372a200",
            "57af0820e1114beebd1616e1df7df806",
            "8d61fab0248d4d9bb16391dbb0d22103",
            "3acc1037b7ba4b34aec9eaab195083ce",
            "2d0565d893ed4fceb861411fa428855a",
            "609d83d6e3ba4b6da9304a75f87ebf1d",
            "54a450d316dc4bec9ffe46167715cc16",
            "fbe9c6ae4b434892836fee2c6cc5e759",
            "8f09344fac484d5eaf6df9bdb6ab005e",
            "3cf57d56281045ac9719120a850bc553",
            "e0e3a1ad977f4124ad750c4abc2aa3ee",
            "348188e0b1b547aeb7bc3fb985aff206",
            "34b73dc8bf8d41e994f7d1e99694ddef",
            "b5a38db529d744839517bfbbf883ab91",
            "f7c1a582ecd74af2ac3ed68cdced5437",
            "cb2b2f0cf66e4db083bcd7a5dc074c3b",
            "8f991b13c8ea4acd97bc9bbc325b70c8",
            "d407e5df32fe44a2aebf333b76805a2a",
            "cbe1c6762ced443181e44c3c1e00e4f6",
            "49b7b1b2ef474a5395a7a48a533a3956",
            "6f14bc587ea540e0bf6983acb9d77149",
            "0db9632448654af6a657a9da5285ad87",
            "8bf3eb214604482b8d0e06bca58e7bee",
            "34bb8648b3994413917ca8aef56179b7",
            "11687c41e34c434a9e997a7a11d19732",
            "3e9b870046334b079084510181fd1b0b",
            "8c5073a128ba479988256328bbea22ef",
            "e965742554ed45e183708df4c7b93ab7",
            "e4efb56e05df435a88eae907419fdac4"
          ]
        },
        "id": "_Pt8Tnm8xim6",
        "outputId": "43042afa-63ac-4c30-eebd-e778e8de7a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/2 shards):   0%|          | 0/9576 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c2486ab568c48668f9e587d050adbc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/507 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20e89c0f6e4a436cb8461b4775cc655f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/513 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65047322e629450eb4bc74457b51570f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/2 shards):   0%|          | 0/9792 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70668bcb7889461fa8c98b7d5115469c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/531 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbe9c6ae4b434892836fee2c6cc5e759"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/528 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbe1c6762ced443181e44c3c1e00e4f6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "ranking = load_from_disk('/content/drive/My Drive/NLP Humor/NLP Humor Data/ranking_dataset')\n",
        "\n",
        "matching = load_from_disk('/content/drive/My Drive/NLP Humor/NLP Humor Data/matching_dataset')\n"
      ],
      "metadata": {
        "id": "nQZ4W09vAi1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "ranking_train = pd.DataFrame(ranking['train'])\n",
        "\n",
        "matching_train = pd.DataFrame(matching['train'])"
      ],
      "metadata": {
        "id": "DpEN1nl6qv7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_train.head()"
      ],
      "metadata": {
        "id": "LY5Ku-gRrfg0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "feace490-cc37-42b8-af99-3a611f6c1c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                             image  \\\n",
              "0                    <PIL.Image.Image image mode=L size=647x500 at 0x7C0AF0662020>   \n",
              "1  <PIL.JpegImagePlugin.JpegImageFile image mode=L size=465x362 at 0x7C0AACA26950>   \n",
              "2  <PIL.JpegImagePlugin.JpegImageFile image mode=L size=375x303 at 0x7C0AACA26200>   \n",
              "3  <PIL.JpegImagePlugin.JpegImageFile image mode=L size=800x532 at 0x7C0AACA27A90>   \n",
              "4                    <PIL.Image.Image image mode=L size=600x495 at 0x7C0AACA27040>   \n",
              "\n",
              "   contest_number  image_location  \\\n",
              "0             566  a sailing ship   \n",
              "1             186     mount sinai   \n",
              "2             571      restaurant   \n",
              "3             704        elevator   \n",
              "4             542     a community   \n",
              "\n",
              "                                                                                                                                                                                                                                                                  image_description  \\\n",
              "0                                                                                A man in a suit and top hat is sitting on what appears to be a pirate ship, petting a cat.  Two pirates are standing off to the side, speaking with each other and looking at the man with the cat   \n",
              "1                                                                                                                                                                                            Moses is holding up a tablet with Chinese characters on it. People are staring at him.   \n",
              "2                                                                                                                                                                                              There is a huge anchor in a cafe. People are staring at it. A pirate is the cashier.   \n",
              "3  A man stands in front of an open elevator and there are two men inside. The two men inside the elevator are wearing suits and have large tuba instruments wrapped around their body. One of the two men wearing a tuba has glasses and the other has a worried look on his face.   \n",
              "4                                                                                                                                                                                 Two old fashioned gentleman are staring at a woman outside. She has a huge frill around her neck.   \n",
              "\n",
              "                                                                                       image_uncanny_description  \\\n",
              "0                        One would not normally expect to find a well-dressed man petting a cat on a pirate ship   \n",
              "1              There are Chinese characters on the tablet (10 Commandments). That is not supposed to be Chinese.   \n",
              "2                                                               There is a pirate and huge anchor inside a cafe.   \n",
              "3  Tuba instruments are large and you don't see people carrying them around their waists as they ride elevators.   \n",
              "4                                                  A lady's dress frill is not that large, and is very ungainly.   \n",
              "\n",
              "                                                                                                                          entities  \\\n",
              "0                                                   [https://en.wikipedia.org/wiki/Cat, https://en.wikipedia.org/wiki/Deck_(ship)]   \n",
              "1  [https://en.wikipedia.org/wiki/Moses, https://en.wikipedia.org/wiki/Written_Chinese, https://en.wikipedia.org/wiki/Clay_tablet]   \n",
              "2                                                     [https://en.wikipedia.org/wiki/Pirate, https://en.wikipedia.org/wiki/Anchor]   \n",
              "3                                                        [https://en.wikipedia.org/wiki/Tuba, https://en.wikipedia.org/wiki/Muzak]   \n",
              "4                                     [https://en.wikipedia.org/wiki/Ruff_(clothing), https://en.wikipedia.org/wiki/Victorian_era]   \n",
              "\n",
              "                                                             questions  \\\n",
              "0    [Why is there a well-dressed man petting a cat on a pirate ship?]   \n",
              "1  [Why are there Chinese characters on the tablet (10 Commandments)?]   \n",
              "2                              [Why is there a huge anchor in a cafe?]   \n",
              "3                                 [Why are the men wearing the tubas?]   \n",
              "4                                          [Why is her frill so huge?]   \n",
              "\n",
              "                                                                                                                                                                                        caption_choices  \\\n",
              "0                                                                                                                                                   [Thus, he gave up the spear., He calls it Ishmeow.]   \n",
              "1  [Well, I was out of tablets, so I had to carve on the back of this one that I found under my door..., And commandments Eleven to Twenty are the same as one to ten, just with tofu instead of meat.]   \n",
              "2                                                                                                          [You should feel lucky - my ex got the ship., Or you could just move the damn coffee maker.]   \n",
              "3                                  [I don't think that's what the boss meant when he said the company's hit a low note., Neither one of us plays, but we find they keep people at least six feet away.]   \n",
              "4                                                                                                                                    [I know her but we were never close., All that to cover a pimple?]   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               from_description  \\\n",
              "0                                                                                                                                                                                                             scene: a sailing ship description: A man in a suit and top hat is sitting on what appears to be a pirate ship, petting a cat. Two pirates are standing off to the side, speaking with each other and looking at the man with the cat uncanny: One would not normally expect to find a well-dressed man petting a cat on a pirate ship entities: Cat, Deck_(ship). choices: A: Thus, he gave up the spear. B: He calls it Ishmeow.   \n",
              "1                                                                                                                                             scene: mount sinai description: Moses is holding up a tablet with Chinese characters on it. People are staring at him. uncanny: There are Chinese characters on the tablet (10 Commandments). That is not supposed to be Chinese. entities: Moses, Written_Chinese, Clay_tablet. choices: A: Well, I was out of tablets, so I had to carve on the back of this one that I found under my door... B: And commandments Eleven to Twenty are the same as one to ten, just with tofu instead of meat.   \n",
              "2                                                                                                                                                                                                                                                                                                                              scene: restaurant description: There is a huge anchor in a cafe. People are staring at it. A pirate is the cashier. uncanny: There is a pirate and huge anchor inside a cafe. entities: Pirate, Anchor. choices: A: You should feel lucky - my ex got the ship. B: Or you could just move the damn coffee maker.   \n",
              "3  scene: elevator description: A man stands in front of an open elevator and there are two men inside. The two men inside the elevator are wearing suits and have large tuba instruments wrapped around their body. One of the two men wearing a tuba has glasses and the other has a worried look on his face. uncanny: Tuba instruments are large and you don't see people carrying them around their waists as they ride elevators. entities: Tuba, Muzak. choices: A: I don't think that's what the boss meant when he said the company's hit a low note. B: Neither one of us plays, but we find they keep people at least six feet away.   \n",
              "4                                                                                                                                                                                                                                                                                                             scene: a community description: Two old fashioned gentleman are staring at a woman outside. She has a huge frill around her neck. uncanny: A lady's dress frill is not that large, and is very ungainly. entities: Ruff_(clothing), Victorian_era. choices: A: I know her but we were never close. B: All that to cover a pimple?   \n",
              "\n",
              "     winner_source label  n_tokens_label                       instance_id  \n",
              "0  official_winner     B               1  ef0ae63207e26f3f7d4e35ff6a0bdefa  \n",
              "1  official_winner     B               1  0f114bd41c0fd5e86e56f083f646edb5  \n",
              "2  official_winner     B               1  43230c9a29b0c34f1170c80f9b03d90d  \n",
              "3     crowd_winner     B               1  b0c8b60724647c2dab06ca9afb5372ea  \n",
              "4  official_winner     A               1  19d15089fc38f9f0c2db8e6d99b123d7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f93ecbeb-103c-4491-a008-56963aebc93a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>contest_number</th>\n",
              "      <th>image_location</th>\n",
              "      <th>image_description</th>\n",
              "      <th>image_uncanny_description</th>\n",
              "      <th>entities</th>\n",
              "      <th>questions</th>\n",
              "      <th>caption_choices</th>\n",
              "      <th>from_description</th>\n",
              "      <th>winner_source</th>\n",
              "      <th>label</th>\n",
              "      <th>n_tokens_label</th>\n",
              "      <th>instance_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;PIL.Image.Image image mode=L size=647x500 at 0x7C0AF0662020&gt;</td>\n",
              "      <td>566</td>\n",
              "      <td>a sailing ship</td>\n",
              "      <td>A man in a suit and top hat is sitting on what appears to be a pirate ship, petting a cat.  Two pirates are standing off to the side, speaking with each other and looking at the man with the cat</td>\n",
              "      <td>One would not normally expect to find a well-dressed man petting a cat on a pirate ship</td>\n",
              "      <td>[https://en.wikipedia.org/wiki/Cat, https://en.wikipedia.org/wiki/Deck_(ship)]</td>\n",
              "      <td>[Why is there a well-dressed man petting a cat on a pirate ship?]</td>\n",
              "      <td>[Thus, he gave up the spear., He calls it Ishmeow.]</td>\n",
              "      <td>scene: a sailing ship description: A man in a suit and top hat is sitting on what appears to be a pirate ship, petting a cat. Two pirates are standing off to the side, speaking with each other and looking at the man with the cat uncanny: One would not normally expect to find a well-dressed man petting a cat on a pirate ship entities: Cat, Deck_(ship). choices: A: Thus, he gave up the spear. B: He calls it Ishmeow.</td>\n",
              "      <td>official_winner</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>ef0ae63207e26f3f7d4e35ff6a0bdefa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=L size=465x362 at 0x7C0AACA26950&gt;</td>\n",
              "      <td>186</td>\n",
              "      <td>mount sinai</td>\n",
              "      <td>Moses is holding up a tablet with Chinese characters on it. People are staring at him.</td>\n",
              "      <td>There are Chinese characters on the tablet (10 Commandments). That is not supposed to be Chinese.</td>\n",
              "      <td>[https://en.wikipedia.org/wiki/Moses, https://en.wikipedia.org/wiki/Written_Chinese, https://en.wikipedia.org/wiki/Clay_tablet]</td>\n",
              "      <td>[Why are there Chinese characters on the tablet (10 Commandments)?]</td>\n",
              "      <td>[Well, I was out of tablets, so I had to carve on the back of this one that I found under my door..., And commandments Eleven to Twenty are the same as one to ten, just with tofu instead of meat.]</td>\n",
              "      <td>scene: mount sinai description: Moses is holding up a tablet with Chinese characters on it. People are staring at him. uncanny: There are Chinese characters on the tablet (10 Commandments). That is not supposed to be Chinese. entities: Moses, Written_Chinese, Clay_tablet. choices: A: Well, I was out of tablets, so I had to carve on the back of this one that I found under my door... B: And commandments Eleven to Twenty are the same as one to ten, just with tofu instead of meat.</td>\n",
              "      <td>official_winner</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0f114bd41c0fd5e86e56f083f646edb5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=L size=375x303 at 0x7C0AACA26200&gt;</td>\n",
              "      <td>571</td>\n",
              "      <td>restaurant</td>\n",
              "      <td>There is a huge anchor in a cafe. People are staring at it. A pirate is the cashier.</td>\n",
              "      <td>There is a pirate and huge anchor inside a cafe.</td>\n",
              "      <td>[https://en.wikipedia.org/wiki/Pirate, https://en.wikipedia.org/wiki/Anchor]</td>\n",
              "      <td>[Why is there a huge anchor in a cafe?]</td>\n",
              "      <td>[You should feel lucky - my ex got the ship., Or you could just move the damn coffee maker.]</td>\n",
              "      <td>scene: restaurant description: There is a huge anchor in a cafe. People are staring at it. A pirate is the cashier. uncanny: There is a pirate and huge anchor inside a cafe. entities: Pirate, Anchor. choices: A: You should feel lucky - my ex got the ship. B: Or you could just move the damn coffee maker.</td>\n",
              "      <td>official_winner</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>43230c9a29b0c34f1170c80f9b03d90d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=L size=800x532 at 0x7C0AACA27A90&gt;</td>\n",
              "      <td>704</td>\n",
              "      <td>elevator</td>\n",
              "      <td>A man stands in front of an open elevator and there are two men inside. The two men inside the elevator are wearing suits and have large tuba instruments wrapped around their body. One of the two men wearing a tuba has glasses and the other has a worried look on his face.</td>\n",
              "      <td>Tuba instruments are large and you don't see people carrying them around their waists as they ride elevators.</td>\n",
              "      <td>[https://en.wikipedia.org/wiki/Tuba, https://en.wikipedia.org/wiki/Muzak]</td>\n",
              "      <td>[Why are the men wearing the tubas?]</td>\n",
              "      <td>[I don't think that's what the boss meant when he said the company's hit a low note., Neither one of us plays, but we find they keep people at least six feet away.]</td>\n",
              "      <td>scene: elevator description: A man stands in front of an open elevator and there are two men inside. The two men inside the elevator are wearing suits and have large tuba instruments wrapped around their body. One of the two men wearing a tuba has glasses and the other has a worried look on his face. uncanny: Tuba instruments are large and you don't see people carrying them around their waists as they ride elevators. entities: Tuba, Muzak. choices: A: I don't think that's what the boss meant when he said the company's hit a low note. B: Neither one of us plays, but we find they keep people at least six feet away.</td>\n",
              "      <td>crowd_winner</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>b0c8b60724647c2dab06ca9afb5372ea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;PIL.Image.Image image mode=L size=600x495 at 0x7C0AACA27040&gt;</td>\n",
              "      <td>542</td>\n",
              "      <td>a community</td>\n",
              "      <td>Two old fashioned gentleman are staring at a woman outside. She has a huge frill around her neck.</td>\n",
              "      <td>A lady's dress frill is not that large, and is very ungainly.</td>\n",
              "      <td>[https://en.wikipedia.org/wiki/Ruff_(clothing), https://en.wikipedia.org/wiki/Victorian_era]</td>\n",
              "      <td>[Why is her frill so huge?]</td>\n",
              "      <td>[I know her but we were never close., All that to cover a pimple?]</td>\n",
              "      <td>scene: a community description: Two old fashioned gentleman are staring at a woman outside. She has a huge frill around her neck. uncanny: A lady's dress frill is not that large, and is very ungainly. entities: Ruff_(clothing), Victorian_era. choices: A: I know her but we were never close. B: All that to cover a pimple?</td>\n",
              "      <td>official_winner</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>19d15089fc38f9f0c2db8e6d99b123d7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f93ecbeb-103c-4491-a008-56963aebc93a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f93ecbeb-103c-4491-a008-56963aebc93a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f93ecbeb-103c-4491-a008-56963aebc93a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-09d0dc77-a06f-4ab4-b514-ade19fbfc3f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09d0dc77-a06f-4ab4-b514-ade19fbfc3f0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-09d0dc77-a06f-4ab4-b514-ade19fbfc3f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ranking_train",
              "summary": "{\n  \"name\": \"ranking_train\",\n  \"rows\": 9576,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contest_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 222,\n        \"min\": 2,\n        \"max\": 763,\n        \"num_unique_values\": 410,\n        \"samples\": [\n          512,\n          511,\n          335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 389,\n        \"samples\": [\n          \"a park bench\",\n          \"a public park\",\n          \"ancient volcano\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1230,\n        \"samples\": [\n          \"A mouse is conducting a hamster wheel experiment with other mice. The mouse is also talking to a turtle .\",\n          \"A caveman is sitting in the mouth of his cave. A couple more caveman are standing in a  hole in the ground outside.\",\n          \"A man resembling a biblical figure is holding a large Chinese menu that resembles old stone slabs. He holds it up in front of people as if he is worshiping it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_uncanny_description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1229,\n        \"samples\": [\n          \"Mice do not conduct experiments. Mice are known to be tested on.\",\n          \"You shouldn't be able to see celestial bodies that close.\",\n          \"Chinese menus were not around during biblical times.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entities\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questions\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_choices\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"from_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9414,\n        \"samples\": [\n          \"scene: a mountain ridge. description: A man and a woman are standing on top of a sloping hill that over looks a pine forest. They're holding glasses of wine and looking up at the moon, which is smiling and winking at them. uncanny: While friendly, the moon, as a large orbiting piece of rock, doesn't tend to have any face, nor any facial expressions. Additionally, the moon seldom takes any personal interest in the affairs of humans, refraining to wink or smile at them at all. entities: Man_in_the_Moon, Wink. choices: A: I think he's been drinking the same stuff we have. B: Remind me to close the curtains tonight.\",\n          \"scene: the pool description: A couple is playing with a beach ball at a pool. A cat is on the beach ball. uncanny: There is a cat on the beach ball. A beachball could not hold that cat. entities: Cat, Beach_ball. choices: A: It was times like these that Mr. Snuffles most regretted being declawed. B: Relax dear. Dr. Schr\\u00f6dinger has reassured me that his cat is used to experiments.\",\n          \"scene: hamster cage description: A mouse is conducting a hamster wheel experiment with other mice. The mouse is also talking to a turtle . uncanny: Mice do not conduct experiments. Mice are known to be tested on. entities: Hamster_wheel, Turtle. choices: A: You're cold blooded. You belong in upper management. B: As mentioned, we're transitioning to a hybrid model.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"crowd_winner\",\n          \"official_winner\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"A\",\n          \"B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_tokens_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instance_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9576,\n        \"samples\": [\n          \"133e07d933bc1018c7324af896b79473\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Set-up: Model Loading / Downloading"
      ],
      "metadata": {
        "id": "0mfiY9U-rfwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To Download Model from Hugging Face to Drive"
      ],
      "metadata": {
        "id": "WVpLwK0Ks9lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate"
      ],
      "metadata": {
        "id": "bIwyNPDQyV9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd411780-97f5-4aff-e8db-b8f59bbcadd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Model from Hugging Face\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# model_name = \"mistralai/Mistral-7B-v0.1\"\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, low_cpu_mem_usage=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "-DiuuORE6mHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saves Model to Drive\n",
        "\n",
        "model_save_path = '/content/drive/My Drive/NLP Humor/Mistral7b_Model'\n",
        "\n",
        "model.save_pretrained(model_save_path)"
      ],
      "metadata": {
        "id": "PGrlCjwCFVFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantize Model with BitsandBytes\n",
        "\n",
        "Using this as guide: https://medium.com/@vishnuchirukandathramesh/how-to-run-mistral-7b-on-free-version-of-google-colab-e0effd9c6a12"
      ],
      "metadata": {
        "id": "wqeJndOKcpS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6MCiPDqcyLr",
        "outputId": "a18c28bc-b39c-4f36-ed8d-8c8dc55c9d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ],
      "metadata": {
        "id": "_xr1d38TeIGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")"
      ],
      "metadata": {
        "id": "kBz9K9EEcyTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "563137ff15024e9583c539a18c79214a",
            "e479392627c34241a3df06714660d22a",
            "49270bb5fb8a458a987940251933b4b6",
            "4ba9fa0053024eada40e7f526db9fc71",
            "4c0217545a9a4b6394e7619682cebc17",
            "7cc39e103c3541a880c60fd79b006192",
            "5b709cf4b1ae4782b5384f562ad92b82",
            "ef790356ca074f4088f329de112f72d1",
            "ac3f876d723d4b6a8784f68b291ab1eb",
            "b2300af3983443df937b777fee04e7eb",
            "7c3af8e0734c429c835d771658885f1d",
            "854e4cc6f5c24ecf881c8d17fdb4f4ad",
            "9fa91ceb315346ad95b4d24055bf64c8",
            "85a5b6012645487fbf8c77f219a18567",
            "fafbf783fe894ac897c0d9ea49aafd56",
            "c450a68f8ce246d986d53bf206681e63",
            "3660dada3c0743c09c4c10a9d630374e",
            "4ea63e1bd95d4cfbb6ffaaaebdb4f8bd",
            "cc473da4e09c40de8947671da1180631",
            "3829e16b464745da8113ac2c35a316cc",
            "9efcc99f29434126888ad25b729133e6",
            "4bde4134aab740eb9de8aa5a1c68a277",
            "7287a8ddb30b486a83f8c37b8f61b2c8",
            "1ab0381f5ff4464f882632bac6e2fbb4",
            "4d8fdd8c6de947c8b135e04aac6da32a",
            "110ac94a36c1418eb2c0efd58bb957be",
            "985209f20a3841a99a5064fce809e588",
            "1f22876faac447ae8ad07d60b1b825f1",
            "c98b3ba18b3e4931b2b51ca19b878bd1",
            "b4f21d4ba99f4408ae5b1153945356a4",
            "fe2705903cb24fa0b56624ef70e9cc24",
            "1abb1466ed124ecda32a2de4c83b630b"
          ]
        },
        "id": "o8FKjP32OhBs",
        "outputId": "930ba500-ed24-43ad-c3ac-5eb35e97316f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "563137ff15024e9583c539a18c79214a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name = \"mistralai/Mistral-7B-v0.1\"\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "model_4bit = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", low_cpu_mem_usage=True, quantization_config=quantization_config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "iz-CnY1yehLh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "d423c815a6f14cb88cb0675f9dd737dc",
            "10feffe0d442411b98ae122de57de471",
            "d5e1515d9bc9488fb3a35da5e57e6423",
            "efe4c4fc13604097931bb64145adbf5f",
            "7daaecf1cf3f44f198e56ebdfcd9ebcd",
            "8e1ecf3a31e24d1eae094c109e66cf36",
            "7f1e06efe91c4df8a35dd6a1594a6eb7",
            "2e58be1cce5145f2b8506d1e6526cb5a",
            "401ad267d8a648c5ac7765f34d576498",
            "370df8d917c6419fa2fb4355a5aba79a",
            "fcc7cc9d25104a9c8d93db20af4b826a",
            "53fa0672af804a9a9055f81a12e74c59",
            "a96d5283337e474e83d32207fcdc287f",
            "d6ba7162c5ea497193abb478b813a4ab",
            "f6b5836b328449a99dea9518b3579003",
            "bc62137bc9b1476296ed08757ddf0509",
            "56ec430fc3504ec8bd474c1a8defac09",
            "5aef0abb07cd4846a216597dbb1d6d45",
            "f923007f5dd74f3a9257cdc95ac22e02",
            "ffa829aff807408e8ae4a25d627c5767",
            "2be5680d533c49bd96b8d5194ec675fa",
            "61dc0bb2bc404c32b50daa7158e6506b",
            "0bd3bd95af4040f588eb68898679245d",
            "aa572e76a5804f829c58c54e037f3bae",
            "fcd4d8045c13450c8bc1a9b340727904",
            "17c0c54fb7a14284bd09591a9861c379",
            "b766520ef0224597b2916c8a580e8e25",
            "afdf7843a79f4e9f8009b7d5ffd93cb0",
            "82c6dcf3393146b9a6207e3c52c9b248",
            "674a51787adb4536b285c21202aef178",
            "7286782384834e3aa9c6f23c7295fe71",
            "b86f4236e5434f8f9ae2f1b12afd81ce",
            "bcc013f44ab54208bf1180fa996bb89d",
            "c3b2e07cd3404a41a2dc052790696fa9",
            "30638e9716104e2bb1d7f260c8c9dbdd",
            "b556dee7feaa4429854622aa0c5db6e2",
            "61ab8fac47aa40e29c1eb153483cfbee",
            "5d19e1ec2cbe4db2bdf07d89a942f1db",
            "ed90a1e2afd64d47ad9513a56f4c57b0",
            "29bbe5a8b6b64469809b4243d6a02e05",
            "6dd239e8900644b089bd3b776180b292",
            "a4b4c43ea99c4593af30d78cdc221353",
            "75a212c0201a4c429c2bb5a4881f09de",
            "1f9b7744f2714ceeb1d5750691897297",
            "00f4641434994bc8a1bafbcab7c25243",
            "6e2b253e8f37475eb4fc94d9c99eef04",
            "974b3aa3c0b64c4abbb79e25560ee3fa",
            "b3a6e3691cc54dc2b1845c3e60c7d3a2",
            "70f47297a4204432b5b5faca2131b1f7",
            "45feda5d5a3d4131b9df04d514e4e490",
            "97e33f068bd74ad6a009c819836966d5",
            "9718fb2ef8714fa38aad9ce1ac5e7333",
            "37bb3a69e80a48e488e2444710cd3d02",
            "e23a36e97f3a4081bdb1076a479ba41b",
            "2e5ea8daaf374ace9d830ec7e67ff77e",
            "a84fa9a9e754485b9065cce3798adaf0",
            "069cf6eaaf304a9cbd066a8be0f099fb",
            "22d0dfe1ef9f431dbca305377e544732",
            "4bce63da270c406ca763ad5e41003ce8",
            "129f83b657784a9cb962413293899596",
            "47be0c45efdf4c0cb4982a233efb76eb",
            "e3622f312e5e40fa88575643e7922e21",
            "d447279827ce4ba5addd7118b35fdb4d",
            "4cc899e164ad43e9bcda3565828519a2",
            "489305cf029242ddbdcb89855cb9d0cb",
            "8a5280ddc7434eebb3662ab2eed093de",
            "6f83a8231acf4a70a03019383a39d8fc",
            "3ab3851540364a359ed50d13c35a0804",
            "d6aac001353949768ebe5e4dc2f6be04",
            "54b8eb53d59642b09679e9d978054a1d",
            "b9e970e7700c4478a631d255bddb17b0",
            "65179c1c94e546c3ac107905a31d7e6a",
            "841ad177ce6145959df327e3c0de5239",
            "968acba969ca44baa9f5c1896d8cec72",
            "6381ed512b244f26a19686ff3f212fc1",
            "68a70d4b1ac04d5da4d20d91621fd409",
            "e46235015f9240c2bdb91b8f3b15083e",
            "e4260d300e454b44b2aec856c06f2d21",
            "c8136f00eb6a4e9eb47683b9167276ed",
            "d08bde7044f941c29c86f52d36119e6b",
            "0cc914afe03744ec87055accb35e5ff6",
            "1e6eeab3610142279edf5b7ae48deb3b",
            "051e0ed1bd7f48c2b4a0b144ec342eb2",
            "a45b7ddabdc8404c81efdb2d6af91e5e",
            "15785e15b42f45bf8ababe161fe275f9",
            "022c8bf135bd40b78302ebc9b3cee5dd",
            "2ff37ef5d69c4288a96d95db20abf06d",
            "6d2a2c33695f4547a407096559b05892",
            "10fe092112e543a8bd4275160b3b7fbc",
            "668c1e6c9cdc4cf8be450ef4cb7305de",
            "1aea08eec4e84dd89cb36c4b58cd6e59",
            "50e76cbddfef4d67897c71b8aebcee15",
            "ea6dd2b0debb48039a1c437841a98a88",
            "156cd1918f6349e1b64dd7ce009a6869",
            "8c153e0a0b6349cca3983d8cd9532e83",
            "96b89637fec54272a2256a0d1259f634",
            "52af47cde839423e9e6a8c95c6dea041",
            "a5da7af1207e4782a218f24b321bd7b2",
            "ea38466cd77a46bf8e63b3a295ca06c5",
            "d663211fe4404597a46c8bfe7ffe8c3d",
            "d91429834d4c487e9f4f106eabb619f9",
            "d4fe8d158f5144b7b80b41838afa08e0",
            "adeb9c5efdc846289fb79945af5d720f",
            "5198506dc5a64ab18927760c1d55ca2c",
            "937ed855afe74933b9acebad6cb5ccdd",
            "8acad6ebfcce4298972041e14a8b8044",
            "2d5f325808ae4c99a9b8f31665e0e185",
            "500f878234d84104b04632dc12602678",
            "ff59a661339c45299e8299148345e31b",
            "529c185ce1114fef923f35e4c76acb07",
            "08c93057e17444e596b98e4102e824a6",
            "241b893bb6f9448da201995368167a29",
            "c46116a4b53c45b291211c6000946e41",
            "a97687f24e7749ba8dcfe59b9ebe51de",
            "8764a2a1bf474ede9612f0b4033cf50f",
            "f3617acdec674200b14eb2b7d3dcaaa5",
            "7403f70a7e094da3b5ca4bd991e47aaf",
            "d1c21831a8074c47b68adbbbedc2c6cc",
            "6112e893c9654dabaef0a439e14d72cf",
            "aff7bff425c745de82574b42bd4125a4",
            "6964c0ad56774775b1907f7972ab1870",
            "6ea65d35c7924b2e89dd088c82290805",
            "75f7af5e48c249e898d545034e4ccf12",
            "a8a050ea7988478fb0aa5ca0953f04f4",
            "aeaf298fcef3403bb8c8ec6d410f5714",
            "86771cebb0a4496bbd797c5a2fc8e9b9",
            "32f0833440fc4e77a229e03896732d57",
            "71b8dbc8e1694b7dbfcb1ca6536bcbf2",
            "8637e2bed59047a492ded210d0c3447b",
            "73c7194bf313484d95e5a7e296ad65b0",
            "edb666808ee2406e819fa39f67a71fb7",
            "1fc5a0dfd19a49dcaaf61cba8b825477"
          ]
        },
        "outputId": "d1523b57-d548-4846-89f7-91b58bbb97c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d423c815a6f14cb88cb0675f9dd737dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53fa0672af804a9a9055f81a12e74c59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bd3bd95af4040f588eb68898679245d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3b2e07cd3404a41a2dc052790696fa9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00f4641434994bc8a1bafbcab7c25243"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a84fa9a9e754485b9065cce3798adaf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f83a8231acf4a70a03019383a39d8fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4260d300e454b44b2aec856c06f2d21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10fe092112e543a8bd4275160b3b7fbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d663211fe4404597a46c8bfe7ffe8c3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08c93057e17444e596b98e4102e824a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ea65d35c7924b2e89dd088c82290805"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saves Model to Drive\n",
        "\n",
        "model_save_path = '/content/drive/My Drive/NLP Humor/Instruct_Mistral7b_Quantized_4bit'\n",
        "\n",
        "model_4bit.save_pretrained(model_save_path)"
      ],
      "metadata": {
        "id": "-M7ldYocfpQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To Load Model in From Drive"
      ],
      "metadata": {
        "id": "UEjmNVP-tF83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/My Drive/NLP Humor/Instruct_Mistral7b_Quantized_4bit'\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_4bit = AutoModelForCausalLM.from_pretrained(model_save_path)\n",
        "\n",
        "print(model_4bit.config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljwF6MFrs66n",
        "outputId": "6581a508-af4e-4452-b856-b0d6da2af902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MistralConfig {\n",
            "  \"_name_or_path\": \"/content/drive/My Drive/NLP Humor/Mistral7b_Quantized_4bit\",\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": true,\n",
            "    \"_load_in_8bit\": false,\n",
            "    \"bnb_4bit_compute_dtype\": \"float16\",\n",
            "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.40.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Sequence Classification Instead, Try LATER\n",
        "\n",
        "model_save_path = '/content/drive/My Drive/NLP Humor/Mistral7b_Quantized_4bit'\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model_4bit = AutoModelForSequenceClassification.from_pretrained(model_save_path)\n",
        "\n",
        "print(model.config)"
      ],
      "metadata": {
        "id": "LcJHa4eH7YmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch"
      ],
      "metadata": {
        "id": "rATJKf0c3EaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Task Set-Up"
      ],
      "metadata": {
        "id": "EAAQSuQc3kE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "UVK_czTK4_Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_train = matching_train.sample(n=500, random_state=42)"
      ],
      "metadata": {
        "id": "IxQDAPUm8Kfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_train_rank = ranking_train.sample(n=500, random_state=42)"
      ],
      "metadata": {
        "id": "AadgjBYGW2fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column Names:\")\n",
        "print(sample_train.columns.tolist())\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"\\nFirst Row:\")\n",
        "print(sample_train.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiqtBlEQxE3f",
        "outputId": "035850f7-5668-4e53-b77f-354f5c10534e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names:\n",
            "['image', 'contest_number', 'image_location', 'image_description', 'image_uncanny_description', 'entities', 'questions', 'caption_choices', 'from_description', 'label', 'n_tokens_label', 'instance_id']\n",
            "\n",
            "First Row:\n",
            "image                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <PIL.JpegImagePlugin.JpegImageFile image mode=L size=323x228 at 0x7C0ABA64F460>\n",
            "contest_number                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          13\n",
            "image_location                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   a bedroom\n",
            "image_description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             A woman is sitting suggestively on-top of her husband in bed; the man looks a bit confused. The man is wearing a football helmet, as a fly swatter sits to the side. The woman is wearing a set of bug ears.\n",
            "image_uncanny_description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       It's unusual because the implication is that the woman has a sexual fetish for pretending to be an insect. This sort of taboo subject is rarely discussed.\n",
            "entities                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [https://en.wikipedia.org/wiki/Sexual_fetishism, https://en.wikipedia.org/wiki/Fly-killing_device]\n",
            "questions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [What is the woman's interest/fetish, and why does she have it?]\n",
            "caption_choices                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [I think we need a new sex therapist., This is the exact moment Susan realized she may be an accomplice and not a magician's assistant..., Try to look housebroken., You realize a seven-foot diary is fair game., I'm losing confidence in Google Maps too.]\n",
            "from_description             scene: a bedroom description: A woman is sitting suggestively on-top of her husband in bed; the man looks a bit confused. The man is wearing a football helmet, as a fly swatter sits to the side. The woman is wearing a set of bug ears. uncanny: It's unusual because the implication is that the woman has a sexual fetish for pretending to be an insect. This sort of taboo subject is rarely discussed. entities: Sexual_fetishism, Fly-killing_device. choices A: I think we need a new sex therapist. B: This is the exact moment Susan realized she may be an accomplice and not a magician's assistant... C: Try to look housebroken. D: You realize a seven-foot diary is fair game. E: I'm losing confidence in Google Maps too.\n",
            "label                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    A\n",
            "n_tokens_label                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1\n",
            "instance_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               d4d0df311393bde85f309c0a60a6d7ce\n",
            "Name: 6555, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column Names:\")\n",
        "print(sample_train_rank.columns.tolist())\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"\\nFirst Row:\")\n",
        "print(sample_train_rank.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om651upGW_Ud",
        "outputId": "57a86987-8935-4f66-8f86-b5c8186a73ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names:\n",
            "['image', 'contest_number', 'image_location', 'image_description', 'image_uncanny_description', 'entities', 'questions', 'caption_choices', 'from_description', 'winner_source', 'label', 'n_tokens_label', 'instance_id']\n",
            "\n",
            "First Row:\n",
            "image                                                                                                                                                                                                                                   <PIL.Image.Image image mode=RGB size=695x495 at 0x7C0AA4BD05E0>\n",
            "contest_number                                                                                                                                                                                                                                                                                      509\n",
            "image_location                                                                                                                                                                                                                                                                                  a river\n",
            "image_description                                                                                                                                                                                                           A bear is standing in a river. Some fish are trying to jump up a waterfall.\n",
            "image_uncanny_description                                                                                                                                                                                                     Nothing looks unusual. This is a standard thing for bears and fish to do.\n",
            "entities                                                                                                                                                                                                                     [https://en.wikipedia.org/wiki/Salmon, https://en.wikipedia.org/wiki/Bear]\n",
            "questions                                                                                                                                                                                                                                                               [Does the bear catch the fish?]\n",
            "caption_choices                                                                                                                                                                                                                                             [Take my wife, please!, Heaven... or hell?]\n",
            "from_description             scene: a river description: A bear is standing in a river. Some fish are trying to jump up a waterfall. uncanny: Nothing looks unusual. This is a standard thing for bears and fish to do. entities: Salmon, Bear. choices: A: Take my wife, please! B: Heaven... or hell?\n",
            "winner_source                                                                                                                                                                                                                                                                              crowd_winner\n",
            "label                                                                                                                                                                                                                                                                                                 A\n",
            "n_tokens_label                                                                                                                                                                                                                                                                                        1\n",
            "instance_id                                                                                                                                                                                                                                                            133e07d933bc1018c7324af896b79473\n",
            "Name: 7355, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_train_rank.iloc[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9wC_0GePpMe",
        "outputId": "01542193-0471-4eac-f422-ff765db8f592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "image                                                                                                                                                                                                                                                                                                <PIL.JpegImagePlugin.JpegImageFile image mode=L size=800x592 at 0x7C0AA4AB5660>\n",
              "contest_number                                                                                                                                                                                                                                                                                                                                                                   680\n",
              "image_location                                                                                                                                                                                                                                                                                                                                                          a restaurant\n",
              "image_description                                                                                                                                                                                                                                               A man is sitting at a table in a restaurant. He is reading a menu while a bear stands in front of him, dripping wet.\n",
              "image_uncanny_description                                                                                                                                                                                                                                                                                        There is a bear inside a restaurant when he should be in the woods.\n",
              "entities                                                                                                                                                                                                                                                                                                     [https://en.wikipedia.org/wiki/Bear, https://en.wikipedia.org/wiki/Fur]\n",
              "questions                                                                                                                                                                                                                                                                                                       [Why is the bear so wet?, What is the bear doing in the restaurant?]\n",
              "caption_choices                                                                                                                                                                                                                                                                                  [I was looking for something a little drier., Aren't you going to write this down?]\n",
              "from_description             scene: a restaurant description: A man is sitting at a table in a restaurant. He is reading a menu while a bear stands in front of him, dripping wet. uncanny: There is a bear inside a restaurant when he should be in the woods. entities: Bear, Fur. choices: A: I was looking for something a little drier. B: Aren't you going to write this down?\n",
              "winner_source                                                                                                                                                                                                                                                                                                                                                        official_winner\n",
              "label                                                                                                                                                                                                                                                                                                                                                                              B\n",
              "n_tokens_label                                                                                                                                                                                                                                                                                                                                                                     1\n",
              "instance_id                                                                                                                                                                                                                                                                                                                                         27709f8c1bf9a12b5602b1ef3ab31f48\n",
              "Name: 7582, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def evaluate_caption(dataframe_row):\n",
        "\n",
        "    # example prompt from Mistral Model Card = \"<s>[INST] What is your favourite condiment? [/INST]\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "    <s>[INST]\n",
        "\n",
        "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
        "    You will be provided with a description of a New Yorker cartoon.\n",
        "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
        "\n",
        "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
        "\n",
        "    Cartoon Description:\n",
        "    Location: {dataframe_row['image_location']}\n",
        "    Description: {dataframe_row['image_description']}\n",
        "    Uncanny Aspect: {dataframe_row['image_uncanny_description']}\n",
        "    Question: {dataframe_row['questions']}\n",
        "    Additional Details: {dataframe_row['from_description']}\n",
        "\n",
        "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
        "\n",
        "    Caption Choices:\n",
        "    \"\"\"\n",
        "\n",
        "    # Adding caption choices\n",
        "    captions = dataframe_row['caption_choices']\n",
        "    for index, caption in enumerate(captions):\n",
        "        prompt += f\"{chr(65 + index)}: {caption}\\n\"\n",
        "\n",
        "    prompt += \"\\nCaption = [/INST]\"\n",
        "    # prompt += \"\\nWhich letter best describes the caption for the cartoon? Choose A, B, C, D, or E.\"\n",
        "    # prompt += \"\\nChoose A, B, C, D, or E based on the description above: \"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    print(\"Number of Input Tokens:  \", inputs.input_ids.size(1))    #prints number of input tokens as check for context length\n",
        "\n",
        "    generated_ids = model_4bit.generate(**inputs, max_new_tokens=100, num_return_sequences=1, do_sample=True)\n",
        "    output_text = tokenizer.batch_decode(generated_ids)[0]\n",
        "\n",
        "    print(output_text)\n",
        "\n",
        "    match = re.search(r\"Caption = \\[/INST\\] ([A-E])\", output_text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return \"No valid prediction found\"\n",
        "\n",
        "\n",
        "predicted_caption = evaluate_caption(sample_train.iloc[10])\n",
        "print(\"The model predicts caption:\", predicted_caption)"
      ],
      "metadata": {
        "id": "9E6EXNEdySFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0ec338-b2a4-463d-ac7f-1b41c98a658f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Input Tokens:   498\n",
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: easter island\n",
            "    Description: There are giant, carved Easter Island stones scattered on a beach. All are identical and resemble a regular man but with a combed back hairstyle. In the foreground a tour guide is talking to a single male tourist who has a camera hanging around his neck.\n",
            "    Uncanny Aspect: It is unusual to see Easter Island stones which resemble a regular man.\n",
            "    Question: ['Who was the inspiration for the stones?', 'What is the tour guide saying to the tourist?']\n",
            "    Additional Details: scene: easter island description: There are giant, carved Easter Island stones scattered on a beach. All are identical and resemble a regular man but with a combed back hairstyle. In the foreground a tour guide is talking to a single male tourist who has a camera hanging around his neck. uncanny: It is unusual to see Easter Island stones which resemble a regular man. entities: Moai, Tourism. choices A: Don't be fooled. He has a dark side. B: I only like you as a friend, weapon, and means of travel. C: You're not supposed to mix Ambien and Quadrophenia. D: Not everything is about you. E: They keep watch on the offshore accounts.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Don't be fooled. He has a dark side.\n",
            "B: I only like you as a friend, weapon, and means of travel.\n",
            "C: You're not supposed to mix Ambien and Quadrophenia.\n",
            "D: Not everything is about you.\n",
            "E: They keep watch on the offshore accounts.\n",
            "\n",
            "Caption = [/INST] D: Not everything is about you.\n",
            "\n",
            "Explanation:\n",
            "The cartoon description does not provide any information that would suggest A, B, C, or E as possible correct answers. However, based on the context of the situation depicted in the cartoon, option D fits best as it is the most logical response for what the tour guide could be saying to the tourist, given the normal tourist inquiry about the origins or significance of the Easter Island statues. Additionally, none of\n",
            "The model predicts caption: D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "template = \"\"\"<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not.\n",
        "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
        "\n",
        "Context: {context}\n",
        "Dialogue: {dialogue}\n",
        "[/INST] </s>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "HX22dgrvT3eO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Matching Task Execution: Baseline + Wiki Summary Context"
      ],
      "metadata": {
        "id": "3QElBxryul_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline, No Context"
      ],
      "metadata": {
        "id": "FX2PV9LWzAhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate_model_accuracy(sample_train, num_rows):\n",
        "    correct_predictions = 0\n",
        "    true_labels = []\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_rows):\n",
        "        predicted_caption = evaluate_caption(sample_train.iloc[i])\n",
        "        correct_choice = sample_train.iloc[i]['label']\n",
        "\n",
        "        true_labels.append(correct_choice)\n",
        "        predictions.append(predicted_caption)\n",
        "\n",
        "        if predicted_caption == correct_choice:\n",
        "            correct_predictions += 1\n",
        "\n",
        "        accuracy = (correct_predictions / (i + 1)) * 100\n",
        "        running_f1 = f1_score(true_labels, predictions, average='weighted', labels=['A', 'B', 'C', 'D', 'E'])\n",
        "\n",
        "        print(f\"Row {i+1}: Predicted - {predicted_caption}, Correct - {correct_choice}, \"f\"Running Accuracy: {accuracy:.2f}%, Running F1 Score: {running_f1:.4f}\")\n",
        "\n",
        "    final_accuracy = (correct_predictions / num_rows) * 100\n",
        "    final_f1_score = f1_score(true_labels, predictions, average='weighted', labels=['A', 'B', 'C', 'D', 'E'])\n",
        "\n",
        "    return final_accuracy, final_f1_score\n",
        "\n",
        "\n",
        "accuracy, f1_score = evaluate_model_accuracy(sample_train, 100)\n",
        "print(f\"Final Accuracy: {accuracy:.4f}%\")\n",
        "print(f\"Final F1 Score: {f1_score:.4f}\")"
      ],
      "metadata": {
        "id": "VefmtigIv6zq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc1e869-2268-4f0e-9c72-8104a4dcb790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Input Tokens:   536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a bedroom\n",
            "    Description: A woman is sitting suggestively on-top of her husband in bed; the man looks a bit confused. The man is wearing a football helmet, as a fly swatter sits to the side. The woman is wearing a set of bug ears.\n",
            "    Uncanny Aspect: It's unusual because the implication is that the woman has a sexual fetish for pretending to be an insect. This sort of taboo subject is rarely discussed.\n",
            "    Question: [\"What is the woman's interest/fetish, and why does she have it?\"]\n",
            "    Additional Details: scene: a bedroom description: A woman is sitting suggestively on-top of her husband in bed; the man looks a bit confused. The man is wearing a football helmet, as a fly swatter sits to the side. The woman is wearing a set of bug ears. uncanny: It's unusual because the implication is that the woman has a sexual fetish for pretending to be an insect. This sort of taboo subject is rarely discussed. entities: Sexual_fetishism, Fly-killing_device. choices A: I think we need a new sex therapist. B: This is the exact moment Susan realized she may be an accomplice and not a magician's assistant... C: Try to look housebroken. D: You realize a seven-foot diary is fair game. E: I'm losing confidence in Google Maps too.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I think we need a new sex therapist.\n",
            "B: This is the exact moment Susan realized she may be an accomplice and not a magician's assistant...\n",
            "C: Try to look housebroken.\n",
            "D: You realize a seven-foot diary is fair game.\n",
            "E: I'm losing confidence in Google Maps too.\n",
            "\n",
            "Caption = [/INST] A: I think we need a new sex therapist.</s>\n",
            "Row 1: Predicted - A, Correct - A, Running Accuracy: 100.00%, Running F1 Score: 1.0000\n",
            "Number of Input Tokens:   450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a bar\n",
            "    Description: A bartender is on the telephone. A man looks on as two other men and a rabbi enter the bar.\n",
            "    Uncanny Aspect: Rabbis don't tend to frequent bars.\n",
            "    Question: ['Who is the bartender calling?']\n",
            "    Additional Details: scene: a bar description: A bartender is on the telephone. A man looks on as two other men and a rabbi enter the bar. uncanny: Rabbis don't tend to frequent bars. entities: Telephone_call, Businessperson. choices A: Sorry...I was texting. B: They've been in love since 1992. I know. Their initials are carved in my ass. C: I thought I told you to stop sending me jokes at work. D: Beat it, Buddy. We're out of chalk. E: When you're best in show, you can have nice clothes, too.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Sorry...I was texting.\n",
            "B: They've been in love since 1992. I know. Their initials are carved in my ass.\n",
            "C: I thought I told you to stop sending me jokes at work.\n",
            "D: Beat it, Buddy. We're out of chalk.\n",
            "E: When you're best in show, you can have nice clothes, too.\n",
            "\n",
            "Caption = [/INST] C. I thought I told you to stop sending me jokes at work.\n",
            "\n",
            "Explanation:\n",
            "Based on the information provided, there's no indication that the telephone call is related to texting. Therefore, option A is a red herring. The cartoon description does mention that one of the men looks on, and the presence of the rabbi in an unlikely bar setting is uncanny, leading us to suspect that the scene may involve some kind of social transgression or\n",
            "Row 2: Predicted - C, Correct - C, Running Accuracy: 100.00%, Running F1 Score: 1.0000\n",
            "Number of Input Tokens:   375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a room\n",
            "    Description: A man and a woman are dancing. They are in a dance hall and the man's leg is odd.\n",
            "    Uncanny Aspect: The man's leg is long and twisty.\n",
            "    Question: ['Why is his leg like that?']\n",
            "    Additional Details: scene: a room description: A man and a woman are dancing. They are in a dance hall and the man's leg is odd. uncanny: The man's leg is long and twisty. entities: Dance, Human_leg. choices A: They keep watch on the offshore accounts. B: That won't fly in here. C: Another nasty hokeypokey injury! D: I recommend the trout. E: Stay back! They may have gluten!\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: They keep watch on the offshore accounts.\n",
            "B: That won't fly in here.\n",
            "C: Another nasty hokeypokey injury!\n",
            "D: I recommend the trout.\n",
            "E: Stay back! They may have gluten!\n",
            "\n",
            "Caption = [/INST] C: Another nasty hokeypokey injury!\n",
            "\n",
            "Explanation: Based on the provided cartoon description and uncanny aspect, it's reasonable to infer that the man's long and twisty leg is a result of an injury. The term \"nasty hokeypokey injury\" is a playful and fitting caption for the scene, evoking the idea of an unexpected and perhaps awkward dance mishap. none of the other options seem to fit the\n",
            "Row 3: Predicted - C, Correct - C, Running Accuracy: 100.00%, Running F1 Score: 1.0000\n",
            "Number of Input Tokens:   434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a field\n",
            "    Description: A bunch of angry sheep are angry at two wolves in suits. These animals are standing up right like humans.\n",
            "    Uncanny Aspect: Animals do not stand up or wear suits.\n",
            "    Question: ['Why are the sheep are angry at the wolves?']\n",
            "    Additional Details: scene: a field description: A bunch of angry sheep are angry at two wolves in suits. These animals are standing up right like humans. uncanny: Animals do not stand up or wear suits. entities: Sheep, Wolf. choices A: He's the advertising executive. Let him come up with a caption. B: I let my mother-in-law move in with us. C: This is my first mirage à trois, too. D: It seems you promised them herd immunity, Sir. E: Can't you just ignore the polls on this one and go with your instinct?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: He's the advertising executive. Let him come up with a caption.\n",
            "B: I let my mother-in-law move in with us.\n",
            "C: This is my first mirage à trois, too.\n",
            "D: It seems you promised them herd immunity, Sir.\n",
            "E: Can't you just ignore the polls on this one and go with your instinct?\n",
            "\n",
            "Caption = [/INST] D: It seems you promised them herd immunity, Sir.</s>\n",
            "Row 4: Predicted - D, Correct - D, Running Accuracy: 100.00%, Running F1 Score: 1.0000\n",
            "Number of Input Tokens:   416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the road\n",
            "    Description: Two people are riding bikes in the city. A man is wearing a knight's costume. A woman stares at him.\n",
            "    Uncanny Aspect: A man on a bike is dressed as a knight.\n",
            "    Question: ['Why is there a knight on a bike in modern times?']\n",
            "    Additional Details: scene: the road description: Two people are riding bikes in the city. A man is wearing a knight's costume. A woman stares at him. uncanny: A man on a bike is dressed as a knight. entities: Cycling, Armour, Helmet. choices A: I want a raise. B: I always said I'd take up cycling when I hit the middle ages. C: Let's not mistake his confidence for leadership. D: Stop me if you've heard this one. E: I'm not a big cat person.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I want a raise.\n",
            "B: I always said I'd take up cycling when I hit the middle ages.\n",
            "C: Let's not mistake his confidence for leadership.\n",
            "D: Stop me if you've heard this one.\n",
            "E: I'm not a big cat person.\n",
            "\n",
            "Caption = [/INST] C: Let's not mistake his confidence for leadership.\n",
            "\n",
            "Explanation:\n",
            "The cartoon description indicates that there is a man on a bike dressed as a knight, and a woman is staring at him. The uncanny aspect is that a man is riding a bike wearing a knight's costume. There is no indication in the description that either of the people mentioned is making a request for a raise or talking about cycling, cats, or telling a joke. Therefore\n",
            "Row 5: Predicted - C, Correct - B, Running Accuracy: 80.00%, Running F1 Score: 0.7200\n",
            "Number of Input Tokens:   472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a cave dwelling\n",
            "    Description: A caveman is sitting in the mouth of his cave. A couple more caveman are standing in a  hole in the ground outside.\n",
            "    Uncanny Aspect: People don't normally live in holes.\n",
            "    Question: ['Why are they in the hole?']\n",
            "    Additional Details: scene: a cave dwelling description: A caveman is sitting in the mouth of his cave. A couple more caveman are standing in a hole in the ground outside. uncanny: People don't normally live in holes. entities: Caveman, Paleolithic. choices A: How soon can you start? B: No need to panic: a reptile dysfunction is common for men of your age. C: It says here that service is not included. D: Just remember to keep away from Fletcher's wife, and Davidson's daughter, and Harris's iPod. E: That's Bob Mankoff. He used to be the cartoon editor of the New Yorker.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: How soon can you start?\n",
            "B: No need to panic: a reptile dysfunction is common for men of your age.\n",
            "C: It says here that service is not included.\n",
            "D: Just remember to keep away from Fletcher's wife, and Davidson's daughter, and Harris's iPod.\n",
            "E: That's Bob Mankoff. He used to be the cartoon editor of the New Yorker.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and the given caption choices, the most unlikely caption choice for this scene would be:\n",
            "\n",
            "C: It says here that service is not included.\n",
            "\n",
            "The cartoon description specifically mentions that the cavemen are \"standing in a hole in the ground outside,\" indicating that they are outdoors, and thus not in a position to offer or provide any \"service.\"\n",
            "\n",
            "Therefore, the most plausible caption choice for this cartoon\n",
            "Row 6: Predicted - B, Correct - E, Running Accuracy: 66.67%, Running F1 Score: 0.6000\n",
            "Number of Input Tokens:   425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a mountain ridge.\n",
            "    Description: Two people are having drinks outside. They're staring up at the moon together.\n",
            "    Uncanny Aspect: The moon looks like an emoticon.\n",
            "    Question: ['Why is the moon winking?']\n",
            "    Additional Details: scene: a mountain ridge. description: Two people are having drinks outside. They're staring up at the moon together. uncanny: The moon looks like an emoticon. entities: Man_in_the_Moon, Wink. choices A: The consensus of your wise men is: move the chair. B: Wow, it's a rare full-of-himself moon. C: Five hundred billion galaxies and nothing’s on. D: Keep going—it's starting to turn me on. E: For God's sake, Dave, you're thirty-five—just use the stairs.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: The consensus of your wise men is: move the chair.\n",
            "B: Wow, it's a rare full-of-himself moon.\n",
            "C: Five hundred billion galaxies and nothing’s on.\n",
            "D: Keep going—it's starting to turn me on.\n",
            "E: For God's sake, Dave, you're thirty-five—just use the stairs.\n",
            "\n",
            "Caption = [/INST] B: Wow, it's a rare full-of-himself moon. (Explanation: The cartoon description does not provide any information about chair movement or stairs, and the people are simply looking at the moon, which fits better with option B's observation about the moon being \"full-of-itself\" or \"fancying itself,\" a common expression for being conceited. Thus, option B seems the best fit.)</s>\n",
            "Row 7: Predicted - B, Correct - B, Running Accuracy: 71.43%, Running F1 Score: 0.6571\n",
            "Number of Input Tokens:   431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the pool\n",
            "    Description: Two people are in a pool. They are playing with a beachball. A cat sits atop it.\n",
            "    Uncanny Aspect: The cat is way too calm about this.\n",
            "    Question: [\"Why isn't the cat jumping off?\"]\n",
            "    Additional Details: scene: the pool description: Two people are in a pool. They are playing with a beachball. A cat sits atop it. uncanny: The cat is way too calm about this. entities: Cat, Beach_ball. choices A: At that moment Willow was consumed with three thoughts: she couldn't swim,they were on their third drink,and she was on her ninth life. B: You border patrol are good. C: A better question is, why aren't YOU wearing a mask? D: You’ve been randomly selected for additional screening. E: It was a very hostile takeover.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: At that moment Willow was consumed with three thoughts: she couldn't swim,they were on their third drink,and she was on her ninth life.\n",
            "B: You border patrol are good.\n",
            "C: A better question is, why aren't YOU wearing a mask?\n",
            "D: You’ve been randomly selected for additional screening.\n",
            "E: It was a very hostile takeover.\n",
            "\n",
            "Caption = [/INST] A. \"At that moment Willow was consumed with three thoughts: she couldn't swim, they were on their third drink, and she was on her ninth life.\" (This captions plays with the unexpected behavior of the cat being calm on a beachball in a pool, and the thought of the cat possibly being a cat with nine lives is an amusing hypothesis.)</s>\n",
            "Row 8: Predicted - A, Correct - A, Running Accuracy: 75.00%, Running F1 Score: 0.7000\n",
            "Number of Input Tokens:   406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: mountains\n",
            "    Description: A man kicks a fish while naked. The Fish goes flying in the air.\n",
            "    Uncanny Aspect: People don't kick fish while naked.\n",
            "    Question: ['Why is he kicking the fish naked?']\n",
            "    Additional Details: scene: mountains description: A man kicks a fish while naked. The Fish goes flying in the air. uncanny: People don't kick fish while naked. entities: Fish, Nudity. choices A: Tell me about a difficult situation you've been in and what you did to get out of it. B: Now that I met your family, I want you to meet mine. C: You know, everyone laughed at Noah, too. D: I think you just ate the spare. E: You shouldn't have opened that can of worms.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Tell me about a difficult situation you've been in and what you did to get out of it.\n",
            "B: Now that I met your family, I want you to meet mine.\n",
            "C: You know, everyone laughed at Noah, too.\n",
            "D: I think you just ate the spare.\n",
            "E: You shouldn't have opened that can of worms.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description provided, none of the given caption options (A, B, C, D, E) fit the scene. Therefore, we cannot determine the correct caption with the given information alone. The description of a man kicking a fish naked in a mountain scene is unusual, and none of the provided captions describe a scene involving kicking a fish naked.</s>\n",
            "Row 9: Predicted - B, Correct - B, Running Accuracy: 77.78%, Running F1 Score: 0.7333\n",
            "Number of Input Tokens:   432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: living room\n",
            "    Description: Two people are sitting down in the living room. There are a bunch of snowmen outside looking in the window.\n",
            "    Uncanny Aspect: Snowmen are not alive, but a bunch of them appear to be peeping in.\n",
            "    Question: ['Why are the snowmen there?']\n",
            "    Additional Details: scene: living room description: Two people are sitting down in the living room. There are a bunch of snowmen outside looking in the window. uncanny: Snowmen are not alive, but a bunch of them appear to be peeping in. entities: Snowman, Window. choices A: I got your message. How can I help? B: Do you ever get the feeling that we’re purely decorative? C: Yeah, they're great cars, but you don't want to see how they get made. D: I'm not a big cat person. E: See? Now they ALL want scarves.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I got your message. How can I help?\n",
            "B: Do you ever get the feeling that we’re purely decorative?\n",
            "C: Yeah, they're great cars, but you don't want to see how they get made.\n",
            "D: I'm not a big cat person.\n",
            "E: See? Now they ALL want scarves.\n",
            "\n",
            "Caption = [/INST] E: See? Now they ALL want scarves.\n",
            "\n",
            "Explanation: Based on the description provided, the snowmen are depicted as looking into the window, indicating that they are aware of the people inside and perhaps even desiring something from them. The caption option \"E: See? Now they ALL want scarves\" is the one that best fits this interpretation as it suggests that the snowmen are behaving like anthropomorphic beings with desires and needs, while also introducing an\n",
            "Row 10: Predicted - E, Correct - E, Running Accuracy: 80.00%, Running F1 Score: 0.7933\n",
            "Number of Input Tokens:   498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: easter island\n",
            "    Description: There are giant, carved Easter Island stones scattered on a beach. All are identical and resemble a regular man but with a combed back hairstyle. In the foreground a tour guide is talking to a single male tourist who has a camera hanging around his neck.\n",
            "    Uncanny Aspect: It is unusual to see Easter Island stones which resemble a regular man.\n",
            "    Question: ['Who was the inspiration for the stones?', 'What is the tour guide saying to the tourist?']\n",
            "    Additional Details: scene: easter island description: There are giant, carved Easter Island stones scattered on a beach. All are identical and resemble a regular man but with a combed back hairstyle. In the foreground a tour guide is talking to a single male tourist who has a camera hanging around his neck. uncanny: It is unusual to see Easter Island stones which resemble a regular man. entities: Moai, Tourism. choices A: Don't be fooled. He has a dark side. B: I only like you as a friend, weapon, and means of travel. C: You're not supposed to mix Ambien and Quadrophenia. D: Not everything is about you. E: They keep watch on the offshore accounts.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Don't be fooled. He has a dark side.\n",
            "B: I only like you as a friend, weapon, and means of travel.\n",
            "C: You're not supposed to mix Ambien and Quadrophenia.\n",
            "D: Not everything is about you.\n",
            "E: They keep watch on the offshore accounts.\n",
            "\n",
            "Caption = [/INST] D: Not everything is about you.\n",
            "\n",
            "Explanation: The context of the cartoon description does not provide any information that would suggest A, B, C, or E as plausible captions for the given situation. The Moai statues on Easter Island do not possess any inherent dark sides, nor are they presented as friends, weapons, or means of travel, or offshore account keepers. The tour guide's dialogue isn't given in the description,\n",
            "Row 11: Predicted - D, Correct - E, Running Accuracy: 72.73%, Running F1 Score: 0.7061\n",
            "Number of Input Tokens:   435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a living room\n",
            "    Description: Two giraffes are in a house. One is on the couch watching TV.\n",
            "    Uncanny Aspect: Giraffes are doing human things.\n",
            "    Question: ['What are they talking about?']\n",
            "    Additional Details: scene: a living room description: Two giraffes are in a house. One is on the couch watching TV. uncanny: Giraffes are doing human things. entities: Giraffe, Television. choices A: When the moon's in the sky like a big winking eye, that's emoji. B: I don't need therapy, I just need the remote! C: This your last chance to come clean. D: Let's stay in tonight. It's a zoo out there. E: My conditioner said it would give me extra body, but I didn't expect it to be yours.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: When the moon's in the sky like a big winking eye, that's emoji.\n",
            "B: I don't need therapy, I just need the remote!\n",
            "C: This your last chance to come clean.\n",
            "D: Let's stay in tonight. It's a zoo out there.\n",
            "E: My conditioner said it would give me extra body, but I didn't expect it to be yours.\n",
            "\n",
            "Caption = [/INST] A: When the moon's in the sky like a big winking eye, that's emoji. (This caption fits best as it mentions watching TV, which is an activity humans do, and the giraffes in the cartoon are depicted doing something similar, making a reference to an emoji which is a human cultural concept, all while maintaining the uncanny aspect of giraffes doing human things.)</s>\n",
            "Row 12: Predicted - A, Correct - D, Running Accuracy: 66.67%, Running F1 Score: 0.6417\n",
            "Number of Input Tokens:   413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the kitchen\n",
            "    Description: Two people are in a kitchen. One of them is in a hazmat suit and cooking.\n",
            "    Uncanny Aspect: You don't need a hazmat suit in the kitchen.\n",
            "    Question: ['What is she cooking?']\n",
            "    Additional Details: scene: the kitchen description: Two people are in a kitchen. One of them is in a hazmat suit and cooking. uncanny: You don't need a hazmat suit in the kitchen. entities: Cooking, Hazmat_suit. choices A: You won't have to drive to this clinic. Just wait in your cornfield. B: I think I like the French maid outfit better. C: He won't last long. D: I listed our freezer on Airbnb. E: I'm sorry I couldn't get more for you in the divorce settlement.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You won't have to drive to this clinic. Just wait in your cornfield.\n",
            "B: I think I like the French maid outfit better.\n",
            "C: He won't last long.\n",
            "D: I listed our freezer on Airbnb.\n",
            "E: I'm sorry I couldn't get more for you in the divorce settlement.\n",
            "\n",
            "Caption = [/INST] A: You won't have to drive to this clinic. Just wait in your cornfield.\n",
            "\n",
            "Explanation: The description clearly states that the person in the hazmat suit is cooking in the kitchen, but it's uncanny because hazmat suits are not necessary in a kitchen. The choice A suggests a possible reason for the person wearing the hazmat suit, such as a mobile lab or clinic. Therefore, it is the best match for the cartoon.</s>\n",
            "Row 13: Predicted - A, Correct - B, Running Accuracy: 61.54%, Running F1 Score: 0.5938\n",
            "Number of Input Tokens:   435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an office\n",
            "    Description: A man uses a sandbox in his cubicle at work. He is digging and adding post its all around the sandbox as two men walk by.\n",
            "    Uncanny Aspect: Using a sandbox at work is messy and unorganized.\n",
            "    Question: ['Why is he using a sandbox?']\n",
            "    Additional Details: scene: an office description: A man uses a sandbox in his cubicle at work. He is digging and adding post its all around the sandbox as two men walk by. uncanny: Using a sandbox at work is messy and unorganized. entities: Sandpit, Post-it_Note. choices A: It autocorrected to \"hula\". B: Under pre-existing conditions, why did you write 'Frog'? C: Let’s see how sustainable his job is. D: Don't worry. We know how to conduct ourselves. E: On second thought let's skip the play.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It autocorrected to \"hula\".\n",
            "B: Under pre-existing conditions, why did you write 'Frog'?\n",
            "C: Let’s see how sustainable his job is.\n",
            "D: Don't worry. We know how to conduct ourselves.\n",
            "E: On second thought let's skip the play.\n",
            "\n",
            "Caption = [/INST] C: Let’s see how sustainable his job is.\n",
            "\n",
            "Explanation: The cartoon description mentions that using a sandbox at work is messy and unorganized, making it an unusual sight. The caption option C acknowledges the unconventional behavior of the man using the sandbox and raises a question about the sustainability of his actions in a professional setting. This option best fits the cartoon as it directly relates to the office environment and the unexpected\n",
            "Row 14: Predicted - C, Correct - C, Running Accuracy: 64.29%, Running F1 Score: 0.6207\n",
            "Number of Input Tokens:   421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the outdoors\n",
            "    Description: A woman is being attacked by human-sized mosquitoes. A man stares at her. They are outside.\n",
            "    Uncanny Aspect: There are gigantic mosquitoes carrying the woman away. Mosquitoes are tiny in real life.\n",
            "    Question: ['Why are the mosquitoes so huge?']\n",
            "    Additional Details: scene: the outdoors description: A woman is being attacked by human-sized mosquitoes. A man stares at her. They are outside. uncanny: There are gigantic mosquitoes carrying the woman away. Mosquitoes are tiny in real life. entities: Mosquito, Gigantism. choices A: Botox. B: To be fair, Martha, you did just kill one of their kids. C: If they were seeking peace, they would have sent olive branches. D: Regime change is never easy, dear. E: The Chair has the floor.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Botox.\n",
            "B: To be fair, Martha, you did just kill one of their kids.\n",
            "C: If they were seeking peace, they would have sent olive branches.\n",
            "D: Regime change is never easy, dear.\n",
            "E: The Chair has the floor.\n",
            "\n",
            "Caption = [/INST] C. If they were seeking peace, they would have sent olive branches.\n",
            "\n",
            "This caption is the least related to the unusual size of the mosquitoes and more focused on the actions of the mosquitoes, which could be interpreted as seeking \"regime change\" for the woman. The other options do not fit the scenario presented in the cartoon description.</s>\n",
            "Row 15: Predicted - C, Correct - B, Running Accuracy: 60.00%, Running F1 Score: 0.5722\n",
            "Number of Input Tokens:   446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a zombie apocalypse\n",
            "    Description: A man and a woman are surrounded by zombies. They are making a last stand.\n",
            "    Uncanny Aspect: The man has a plate of cookies.\n",
            "    Question: ['Is he going to offer the zombies a cookie?']\n",
            "    Additional Details: scene: a zombie apocalypse description: A man and a woman are surrounded by zombies. They are making a last stand. uncanny: The man has a plate of cookies. entities: Zombie, Cookie, Shotgun. choices A: We asked the flooring company for red tiles, but it autocorrected to rep-tiles. B: But first, an amuse-bouche? C: The time is 11:59. You have one minute to check out. D: Okay, okay. Fine, I'll fill out the census. E: Growth has exceeded our projections.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: We asked the flooring company for red tiles, but it autocorrected to rep-tiles.\n",
            "B: But first, an amuse-bouche?\n",
            "C: The time is 11:59. You have one minute to check out.\n",
            "D: Okay, okay. Fine, I'll fill out the census.\n",
            "E: Growth has exceeded our projections.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and the provided caption choices, choice B: \"But first, an amuse-bouche?\" is the least likely to match the cartoon. In a zombie apocalypse scenario, offering food to the zombies is unlikely and would not be a priority for a man in a last stand situation. Therefore, this option can be eliminated.\n",
            "\n",
            "Among the remaining choices, the option C: \"The time is 11:5\n",
            "Row 16: Predicted - B, Correct - B, Running Accuracy: 62.50%, Running F1 Score: 0.6052\n",
            "Number of Input Tokens:   500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: airplane\n",
            "    Description: Several people are seated on an airplane. Among the people is human sized germ that is also buckled into its seat. The man next to the germ is angrily pointing towards the germ.\n",
            "    Uncanny Aspect: There is a human sized germ when in reality germs and bacteria are only microscopic.\n",
            "    Question: [\"Why is the germ flying on the plane like it's a person?\"]\n",
            "    Additional Details: scene: airplane description: Several people are seated on an airplane. Among the people is human sized germ that is also buckled into its seat. The man next to the germ is angrily pointing towards the germ. uncanny: There is a human sized germ when in reality germs and bacteria are only microscopic. entities: Bacteria, Aisle. choices A: Yeah, well your profile wasn't exactly honest either. B: Take three thousand Tylenol and call me in the morning. C: Have you tried turning it off and back on again? D: I don't care if he's single-celled, he should have bought two seats. E: Don't look at me that way—I wanted a giant cat.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Yeah, well your profile wasn't exactly honest either.\n",
            "B: Take three thousand Tylenol and call me in the morning.\n",
            "C: Have you tried turning it off and back on again?\n",
            "D: I don't care if he's single-celled, he should have bought two seats.\n",
            "E: Don't look at me that way—I wanted a giant cat.\n",
            "\n",
            "Caption = [/INST] D: I don't care if he's single-celled, he should have bought two seats.</s>\n",
            "Row 17: Predicted - D, Correct - D, Running Accuracy: 64.71%, Running F1 Score: 0.6284\n",
            "Number of Input Tokens:   486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: outside of a home\n",
            "    Description: Inside of a For Sale house, a devil is torturing a bunch of people inside with lots of fire. A couple with a realtor is watching from outside.\n",
            "    Uncanny Aspect: If a fire happened inside of a house then there would be smoke and there is none.\n",
            "    Question: ['Why is there hell inside the house?']\n",
            "    Additional Details: scene: outside of a home description: Inside of a For Sale house, a devil is torturing a bunch of people inside with lots of fire. A couple with a realtor is watching from outside. uncanny: If a fire happened inside of a house then there would be smoke and there is none. entities: Real_estate_agent, Marriage. choices A: I strongly recommend you read the fine print on this one. B: I thought you said it wouldn't need much attention. C: O.K., now we'd like to see No. 4 in the tutu. D: I could go digital, but I love the old fashioned feel of paper. E: It's Kansas, m'am. Evolution is a crime.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I strongly recommend you read the fine print on this one.\n",
            "B: I thought you said it wouldn't need much attention.\n",
            "C: O.K., now we'd like to see No. 4 in the tutu.\n",
            "D: I could go digital, but I love the old fashioned feel of paper.\n",
            "E: It's Kansas, m'am. Evolution is a crime.\n",
            "\n",
            "Caption = [/INST] A: I strongly recommend you read the fine print on this one. (Explanation: The couple and the realtor are outside of a house where a devil is torturing people with fire inside, indicating that something is not right with the house they are trying to buy. The absence of smoke despite a fire is an uncanny aspect that further highlights the unusual situation. The phrase \"read the fine print\" is a common suggestion for buyers to be aware of hidden details or conditions, making option\n",
            "Row 18: Predicted - A, Correct - A, Running Accuracy: 66.67%, Running F1 Score: 0.6444\n",
            "Number of Input Tokens:   462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an office space\n",
            "    Description: Men and women are playing in a sandbox in an office. Two men stare at them from the doorway.\n",
            "    Uncanny Aspect: A huge sandbox is in an office. Sandboxes are for kids.\n",
            "    Question: ['Why is there a sandbox in an office?']\n",
            "    Additional Details: scene: an office space description: Men and women are playing in a sandbox in an office. Two men stare at them from the doorway. uncanny: A huge sandbox is in an office. Sandboxes are for kids. entities: Sandpit, Recess_(break). choices A: It's a little creepy how Williams just sits there on the edge, watching. B: Indian casino. I'd say Comanche. C: You can advocate for wind power all you want, Randy, but you're not going to escape your fossil fuel destiny. D: And for you goats—thou shalt not marry a dragon or ox. E: I'm pregnant.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It's a little creepy how Williams just sits there on the edge, watching.\n",
            "B: Indian casino. I'd say Comanche.\n",
            "C: You can advocate for wind power all you want, Randy, but you're not going to escape your fossil fuel destiny.\n",
            "D: And for you goats—thou shalt not marry a dragon or ox.\n",
            "E: I'm pregnant.\n",
            "\n",
            "Caption = [/INST] A: It's a little creepy how Williams just sits there on the edge, watching.\n",
            "\n",
            "Explanation:\n",
            "The given cartoon description does not include any elements related to casinos, wind power, goats, or pregnancy. Therefore, options B, C, D, and E can be eliminated as the possible captions for the given cartoon description.\n",
            "\n",
            "The description states that there are men and women playing in a sandbox in an office. The uncanny\n",
            "Row 19: Predicted - A, Correct - A, Running Accuracy: 68.42%, Running F1 Score: 0.6605\n",
            "Number of Input Tokens:   440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: room\n",
            "    Description: A man is climbing up a wall of nothing. Another man watches from below.\n",
            "    Uncanny Aspect: There is no wall or cliff that the man is climbing.\n",
            "    Question: ['How is he suspended in the air?']\n",
            "    Additional Details: scene: room description: A man is climbing up a wall of nothing. Another man watches from below. uncanny: There is no wall or cliff that the man is climbing. entities: Climbing_wall, Mountaineering. choices A: Wow, you student loan people really know how to track someone down. B: We probably should have done something about this last year when it was still three blocks away. C: It's easy once you realize there's nothing to it. D: Just once I'd like to hallucinate a guy who does air conditioning. E: See? A real pirate would have cannonballed.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Wow, you student loan people really know how to track someone down.\n",
            "B: We probably should have done something about this last year when it was still three blocks away.\n",
            "C: It's easy once you realize there's nothing to it.\n",
            "D: Just once I'd like to hallucinate a guy who does air conditioning.\n",
            "E: See? A real pirate would have cannonballed.\n",
            "\n",
            "Caption = [/INST] C: It's easy once you realize there's nothing to it.</s>\n",
            "Row 20: Predicted - C, Correct - C, Running Accuracy: 70.00%, Running F1 Score: 0.6750\n",
            "Number of Input Tokens:   452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a restaurant\n",
            "    Description: There is a man carrying a garbage can in a restaurant. He is bringing it to a table with another waiter, who is talking to some customers.\n",
            "    Uncanny Aspect: A waiter is carrying a garbage can to a table at a restaurant?\n",
            "    Question: ['Why is the waiter bringing a garbage can to the table in the restaurant?']\n",
            "    Additional Details: scene: a restaurant description: There is a man carrying a garbage can in a restaurant. He is bringing it to a table with another waiter, who is talking to some customers. uncanny: A waiter is carrying a garbage can to a table at a restaurant? entities: Waste_container, Waiting_staff. choices A: Yeah, they're great cars, but you don't want to see how they get made. B: Wait, the GPS is recalculating C: Define fresh. D: This is why I don't need cable TV. E: You should see how excited he gets when I pick him up at baggage claim.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Yeah, they're great cars, but you don't want to see how they get made.\n",
            "B: Wait, the GPS is recalculating\n",
            "C: Define fresh.\n",
            "D: This is why I don't need cable TV.\n",
            "E: You should see how excited he gets when I pick him up at baggage claim.\n",
            "\n",
            "Caption = [/INST] D: This is why I don't need cable TV.\n",
            "\n",
            "Explanation: The scene describes a waiter carrying a garbage can to a table in a restaurant. This behavior is unusual and uncanny, as waiters typically do not bring garbage cans to tables. The choices provided do not match the scene. However, option D is a humorous and unrelated statement that would not affect the scene, making it a plausible caption for this cartoon. The other\n",
            "Row 21: Predicted - D, Correct - C, Running Accuracy: 66.67%, Running F1 Score: 0.6500\n",
            "Number of Input Tokens:   470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a mountain\n",
            "    Description: A man is pushing a bounder up a hill. A woman in a dress is sitting down watching him drinking alcohol. The man is wearing hardly anything.\n",
            "    Uncanny Aspect: The woman in the dress doesn't fit the time period.\n",
            "    Question: ['Why is the woman in the dress here drinking and watching this poor man?']\n",
            "    Additional Details: scene: a mountain description: A man is pushing a bounder up a hill. A woman in a dress is sitting down watching him drinking alcohol. The man is wearing hardly anything. uncanny: The woman in the dress doesn't fit the time period. entities: Boulder, Types_of_restaurants#Casual_dining. choices A: The blind date site stated you are \"Strong, upwardly mobile and persistent\" which sounded good at the time. B: I'm beginning to see what you mean. C: He'll never survive the primaries. D: I'm afraid we've found a problem with the Crown Jewels. E: He needs to start drinking outside the box.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: The blind date site stated you are \"Strong, upwardly mobile and persistent\" which sounded good at the time.\n",
            "B: I'm beginning to see what you mean.\n",
            "C: He'll never survive the primaries.\n",
            "D: I'm afraid we've found a problem with the Crown Jewels.\n",
            "E: He needs to start drinking outside the box.\n",
            "\n",
            "Caption = [/INST] Based on the description provided, it is not clear why the woman in the dress is watching the man pushing the boulder and drinking alcohol. The cartoon description does not provide any context or explanation for their interaction, and the woman's anachronistic dress does not necessarily indicate that she is on a date or that this is a romantic scene. Additionally, the cartoon description does not mention anything related to politics or primaries, so caption C is not a good fit.\n",
            "\n",
            "Row 22: Predicted - B, Correct - A, Running Accuracy: 63.64%, Running F1 Score: 0.6254\n",
            "Number of Input Tokens:   425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: mount sinai\n",
            "    Description: Moses is holding up a tablet with Chinese characters on it. People are staring at him.\n",
            "    Uncanny Aspect: There are Chinese characters on the tablet (10 Commandments). That is not supposed to be Chinese.\n",
            "    Question: ['Why are there Chinese characters on the tablet (10 Commandments)?']\n",
            "    Additional Details: scene: mount sinai description: Moses is holding up a tablet with Chinese characters on it. People are staring at him. uncanny: There are Chinese characters on the tablet (10 Commandments). That is not supposed to be Chinese. entities: Moses, Written_Chinese, Clay_tablet. choices A: I've never been snookered so properly before. B: I'm more of a pop psychologist. C: We're gonna need a bigger spear. D: Read quickly. These are really heavy. E: Call security and tell them to circle the wagons!\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I've never been snookered so properly before.\n",
            "B: I'm more of a pop psychologist.\n",
            "C: We're gonna need a bigger spear.\n",
            "D: Read quickly. These are really heavy.\n",
            "E: Call security and tell them to circle the wagons!\n",
            "\n",
            "Caption = [/INST] C. \"We're gonna need a bigger spear.\"\n",
            "\n",
            "Explanation:\n",
            "The description of the cartoon indicates that there are Chinese characters on the tablet that Moses is holding, which is an uncanny aspect since the 10 Commandments are not supposed to be in Chinese. Therefore, the people are staring at him in confusion. The caption option \"We're gonna need a bigger spear\" does not directly address the Chinese characters on the tablet but rather suggests\n",
            "Row 23: Predicted - C, Correct - D, Running Accuracy: 60.87%, Running F1 Score: 0.5975\n",
            "Number of Input Tokens:   448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an alleyway\n",
            "    Description: In an alley, a man and woman are walking. An elderly couple are holding them up with a gun.\n",
            "    Uncanny Aspect: The man looks happy for some reason even though he's being robbed.\n",
            "    Question: ['Why are they robbing him?']\n",
            "    Additional Details: scene: an alleyway description: In an alley, a man and woman are walking. An elderly couple are holding them up with a gun. uncanny: The man looks happy for some reason even though he's being robbed. entities: Robbery, Old_age. choices A: Isn't it great how so many their age are pursuing second careers? B: I usually don't say this to men.....How far apart are the contractions? C: Good Samaritan? I was a GREAT Samaritan. D: A Citation? Is it for bravery? E: Mom said you were supposed to take me to the game.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Isn't it great how so many their age are pursuing second careers?\n",
            "B: I usually don't say this to men.....How far apart are the contractions?\n",
            "C: Good Samaritan? I was a GREAT Samaritan.\n",
            "D: A Citation? Is it for bravery?\n",
            "E: Mom said you were supposed to take me to the game.\n",
            "\n",
            "Caption = [/INST] A. \"Isn't it great how so many their age are pursuing second careers?\" (This caption could explain the unexpected smile on the man's face during the robbery, as he might find the situation exciting or amusing as if it was part of a new adventure)</s>\n",
            "Row 24: Predicted - A, Correct - A, Running Accuracy: 62.50%, Running F1 Score: 0.6134\n",
            "Number of Input Tokens:   455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a living room apartment\n",
            "    Description: A man is looking into a giant barrel of monkeys. Someone just delivered it.\n",
            "    Uncanny Aspect: There is a huge barrel of monkeys. Normally this is a kid's game and very small.\n",
            "    Question: ['Why is the barrel of monkeys so huge?']\n",
            "    Additional Details: scene: a living room apartment description: A man is looking into a giant barrel of monkeys. Someone just delivered it. uncanny: There is a huge barrel of monkeys. Normally this is a kid's game and very small. entities: Barrel_of_Monkeys, Moving_company. choices A: Personally, I think Prozac is a lot easier. B: He's telling his friends it's not deep. So be patient. C: So, this is fine but you're scared of the vacuum cleaner? D: Duck? No, I ordered roast beef. E: So you're the bug that's been going around.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Personally, I think Prozac is a lot easier.\n",
            "B: He's telling his friends it's not deep. So be patient.\n",
            "C: So, this is fine but you're scared of the vacuum cleaner?\n",
            "D: Duck? No, I ordered roast beef.\n",
            "E: So you're the bug that's been going around.\n",
            "\n",
            "Caption = [/INST] The description does not provide any information related to any of the given caption choices. Therefore, it is impossible to determine which caption is the best match for the cartoon based on the information provided. The cartoon description solely mentions the presence of a giant barrel of monkeys in a living room, and there is no context given about the man's conversation or any potential misunderstandings. Each caption choices seem to be unrelated to the cartoon and do not provide any obvious\n",
            "Row 25: Predicted - No valid prediction found, Correct - A, Running Accuracy: 60.00%, Running F1 Score: 0.6042\n",
            "Number of Input Tokens:   425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an island\n",
            "    Description: A dominatrix is on an island with a clown. the island is small with one palm tree.\n",
            "    Uncanny Aspect: It is unusual to see a clown and a dominatrix together on one island alone.\n",
            "    Question: ['Why are they on the island together?']\n",
            "    Additional Details: scene: an island description: A dominatrix is on an island with a clown. the island is small with one palm tree. uncanny: It is unusual to see a clown and a dominatrix together on one island alone. entities: Clown, Dominatrix. choices A: It seems you promised them herd immunity, Sir. B: Well maybe once, back in clown college. C: Now that's what I call a dinner jacket. D: I wear the pants but my wife controls them. E: To illustrate how couples come to look alike, this is my wife.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It seems you promised them herd immunity, Sir.\n",
            "B: Well maybe once, back in clown college.\n",
            "C: Now that's what I call a dinner jacket.\n",
            "D: I wear the pants but my wife controls them.\n",
            "E: To illustrate how couples come to look alike, this is my wife.\n",
            "\n",
            "Caption = [/INST] A: It seems you promised them herd immunity, Sir.\n",
            "\n",
            "Explanation:\n",
            "Given the description and the uncanny aspect of the scene, it is not likely that the given caption choices are the original captions for the cartoon. However, among the given choices, option A is the most plausible explanation for why a dominatrix and a clown would be on an isolated island together. This option introduces a third entity, who may have brought\n",
            "Row 26: Predicted - A, Correct - B, Running Accuracy: 57.69%, Running F1 Score: 0.5769\n",
            "Number of Input Tokens:   409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a living room\n",
            "    Description: A woman is sitting on a couch reading. A man is entering the room naked, with only a briefcase covering him.\n",
            "    Uncanny Aspect: There is a naked man who was walking around in public.\n",
            "    Question: [\"Why doesn't he have any clothes on?\"]\n",
            "    Additional Details: scene: a living room description: A woman is sitting on a couch reading. A man is entering the room naked, with only a briefcase covering him. uncanny: There is a naked man who was walking around in public. entities: Nudity, Businessperson. choices A: Why yes, I always do dress to kill. B: Just tell Dad it's a staff job with a leadership position. C: Forgot my underwear, shirt, suit, belt, tie, and watch. D: I look like five bucks. E: Move the car.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Why yes, I always do dress to kill.\n",
            "B: Just tell Dad it's a staff job with a leadership position.\n",
            "C: Forgot my underwear, shirt, suit, belt, tie, and watch.\n",
            "D: I look like five bucks.\n",
            "E: Move the car.\n",
            "\n",
            "Caption = [/INST] C: Forgot my underwear, shirt, suit, belt, tie, and watch.</s>\n",
            "Row 27: Predicted - C, Correct - C, Running Accuracy: 59.26%, Running F1 Score: 0.5908\n",
            "Number of Input Tokens:   389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: restaurant\n",
            "    Description: An alligator is coming out of the floor. Two people stare at it. A waiter points at it.\n",
            "    Uncanny Aspect: There is an alligator coming out of the floor.\n",
            "    Question: ['Why is an alligator in a restaurant?']\n",
            "    Additional Details: scene: restaurant description: An alligator is coming out of the floor. Two people stare at it. A waiter points at it. uncanny: There is an alligator coming out of the floor. entities: Alligator, Waiting_staff. choices A: I don't care whether or not it ties the room together. B: We demand blanket immunity. C: We never get out anymore. D: We have them between all tables, it encourages social distancing. E: Quick, stroll for cover.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I don't care whether or not it ties the room together.\n",
            "B: We demand blanket immunity.\n",
            "C: We never get out anymore.\n",
            "D: We have them between all tables, it encourages social distancing.\n",
            "E: Quick, stroll for cover.\n",
            "\n",
            "Caption = [/INST] E: Quick, stroll for cover.</s>\n",
            "Row 28: Predicted - E, Correct - D, Running Accuracy: 57.14%, Running F1 Score: 0.5670\n",
            "Number of Input Tokens:   394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: kingdom\n",
            "    Description: A king sits on a thone positioned between to cacti.  Facing him is a knight in full armor\n",
            "    Uncanny Aspect: It's unusual to see a throne placed next to cacti\n",
            "    Question: ['Why are there cacti next to that throne?']\n",
            "    Additional Details: scene: kingdom description: A king sits on a thone positioned between to cacti. Facing him is a knight in full armor uncanny: It's unusual to see a throne placed next to cacti entities: Cactus, King. choices A: It's curb to table. B: You have any small bills? C: If their dog starts humping your leg - let it finish. D: Oh, you said assemble the caucus... E: We had meth on Tuesday.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It's curb to table.\n",
            "B: You have any small bills?\n",
            "C: If their dog starts humping your leg - let it finish.\n",
            "D: Oh, you said assemble the caucus...\n",
            "E: We had meth on Tuesday.\n",
            "\n",
            "Caption = [/INST] A: It's unusual to see a throne placed next to cacti. This choice does not provide a direct response to the question, but it acknowledges the unusual aspect of the scene, making it a valid option. However, based on the context and the information given, none of the options A through E perfectly fit the cartoon description. If more context were provided, or if the cartoon contained text or other visual elements that hinted at a specific caption, then a more\n",
            "Row 29: Predicted - A, Correct - D, Running Accuracy: 55.17%, Running F1 Score: 0.5435\n",
            "Number of Input Tokens:   462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a corporate meeting room\n",
            "    Description: A bunch of executives are around a board room table. Another man in a suit is doing a cannonball onto the table.\n",
            "    Uncanny Aspect: The man is cannonballing like he is at a pool.\n",
            "    Question: ['Why is he jumping on the table like that?']\n",
            "    Additional Details: scene: a corporate meeting room description: A bunch of executives are around a board room table. Another man in a suit is doing a cannonball onto the table. uncanny: The man is cannonballing like he is at a pool. entities: Cannonball_(diving), Businessperson, Meeting. choices A: It's Karma !! But who'da thunk the hamsters would inherit the earth? B: Please! I have a wife and two thousand kids! C: Neither the time nor the place, Doug! D: He thinks you push people away. E: Three yea's, six ney's, and Anderson is still up in the air on this one.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It's Karma !! But who'da thunk the hamsters would inherit the earth?\n",
            "B: Please! I have a wife and two thousand kids!\n",
            "C: Neither the time nor the place, Doug!\n",
            "D: He thinks you push people away.\n",
            "E: Three yea's, six ney's, and Anderson is still up in the air on this one.\n",
            "\n",
            "Caption = [/INST] E: Three yea's, six ney's, and Anderson is still up in the air on this one.\n",
            "\n",
            "The other captions do not fit well with the context of the cartoon, as there's no indication of karma, imminent children or wives, or pushing people away. The cartoon presents an unexpected situation that could be explained by a caption that refers to a deliberation or decision-making process within the corporate meeting, like \"Three\n",
            "Row 30: Predicted - E, Correct - E, Running Accuracy: 56.67%, Running F1 Score: 0.5615\n",
            "Number of Input Tokens:   404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a restaurant\n",
            "    Description: People are looking at menus at a restaurant. Their table is a stove where they cook their own meals.\n",
            "    Uncanny Aspect: Restaurants do not usually have home stoves where people cook their own food. A chef prepares the food in the kitchen.\n",
            "    Question: ['Why are the tables stoves?']\n",
            "    Additional Details: scene: a restaurant description: People are looking at menus at a restaurant. Their table is a stove where they cook their own meals. uncanny: Restaurants do not usually have home stoves where people cook their own food. A chef prepares the food in the kitchen. entities: Kitchen_stove, Menu. choices A: Put it down slowly, the mothers are very protective of their young B: Free will is overrated. C: Worst internship ever. D: I'm allergic to down. E: The sign said home style cooking.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Put it down slowly, the mothers are very protective of their young\n",
            "B: Free will is overrated.\n",
            "C: Worst internship ever.\n",
            "D: I'm allergic to down.\n",
            "E: The sign said home style cooking.\n",
            "\n",
            "Caption = [/INST] E: The sign said home style cooking.\n",
            "\n",
            "Explanation: Based on thecartoon description and the context provided, the answer is E. The cartoon describes a scene in a restaurant where people are cooking their own meals at their table, which is unusual as it's not how restaurants typically operate. The additional details also confirm that this is an unusual setup. The caption choice E, \"The sign said home style cooking,\" fits well with the scene as it explains why people\n",
            "Row 31: Predicted - E, Correct - E, Running Accuracy: 58.06%, Running F1 Score: 0.5772\n",
            "Number of Input Tokens:   431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a corporate office\n",
            "    Description: Someone has created a pool in their office and are about to jump in it. A man in suit and tie walks in as soon as the person is about to dive.\n",
            "    Uncanny Aspect: A pool in an office room is absurd.\n",
            "    Question: ['Why did the person build a pool in their office?']\n",
            "    Additional Details: scene: a corporate office description: Someone has created a pool in their office and are about to jump in it. A man in suit and tie walks in as soon as the person is about to dive. uncanny: A pool in an office room is absurd. entities: Swimming_pool, Break_(work). choices A: Why not? We defy every other law. B: My wife won't let me put one in the back yard. C: Must be valuable, they spend hours collecting them! D: Well, what did you think a labrapotamus was? E: Treat me like the White House.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Why not? We defy every other law.\n",
            "B: My wife won't let me put one in the back yard.\n",
            "C: Must be valuable, they spend hours collecting them!\n",
            "D: Well, what did you think a labrapotamus was?\n",
            "E: Treat me like the White House.\n",
            "\n",
            "Caption = [/INST] A: Why not? We defy every other law.</s>\n",
            "Row 32: Predicted - A, Correct - B, Running Accuracy: 56.25%, Running F1 Score: 0.5572\n",
            "Number of Input Tokens:   538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a graveyard\n",
            "    Description: There is a graveyard with two coffins at the front of the image, both underground.  One has a man making an odd expression, seemingly alive inside the coffin.  The other has a skeleton sitting up and waving.\n",
            "    Uncanny Aspect: It's unusual to find both a living being inside a coffin in a cemetery, as well as seeing a skeleton moving of its own accord.\n",
            "    Question: ['Why is there a moving skeleton?']\n",
            "    Additional Details: scene: a graveyard description: There is a graveyard with two coffins at the front of the image, both underground. One has a man making an odd expression, seemingly alive inside the coffin. The other has a skeleton sitting up and waving. uncanny: It's unusual to find both a living being inside a coffin in a cemetery, as well as seeing a skeleton moving of its own accord. entities: Coffin, Skeleton, Headstone. choices A: ...and here come the bees. B: Finally—a faith-based initiative I can embrace. C: He's the cutest little thing, and when you get tired of him you just flush him down the toilet. D: Our chef trained at the Paris Metro. E: Of all the skeletons in all the world, I get stuck next to the one from my closet.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: ...and here come the bees.\n",
            "B: Finally—a faith-based initiative I can embrace.\n",
            "C: He's the cutest little thing, and when you get tired of him you just flush him down the toilet.\n",
            "D: Our chef trained at the Paris Metro.\n",
            "E: Of all the skeletons in all the world, I get stuck next to the one from my closet.\n",
            "\n",
            "Caption = [/INST] E: Of all the skeletons in all the world, I get stuck next to the one from my closet.</s>\n",
            "Row 33: Predicted - E, Correct - E, Running Accuracy: 57.58%, Running F1 Score: 0.5715\n",
            "Number of Input Tokens:   422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the hills\n",
            "    Description: Two giraffes are in the desert. Their necks are locked together and tied up.\n",
            "    Uncanny Aspect: Giraffe necks are not this long and would not get entangled like this.\n",
            "    Question: ['Why are the giraffes tangled up like this?']\n",
            "    Additional Details: scene: the hills description: Two giraffes are in the desert. Their necks are locked together and tied up. uncanny: Giraffe necks are not this long and would not get entangled like this. entities: Giraffe, Neck. choices A: I always knew we'd wind up together. B: He's pro-gun, but I like his stance on migration. C: You know, pumpkins are in season, too. D: Beat it, Buddy. We're out of chalk. E: This town ain’t big enough for anyone.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I always knew we'd wind up together.\n",
            "B: He's pro-gun, but I like his stance on migration.\n",
            "C: You know, pumpkins are in season, too.\n",
            "D: Beat it, Buddy. We're out of chalk.\n",
            "E: This town ain’t big enough for anyone.\n",
            "\n",
            "Caption = [/INST] Based on the description provided, none of the given captions (A, B, C, D, E) appear to fit the cartoon well. The cartoon description mentions \"Two giraffes are in the desert. Their necks are locked together and tied up.\" with an uncanny aspect stating that \"Giraffe necks are not this long and would not get entangled like this.\" The cartoon description does not mention any human interaction or dialogue, which is suggested by\n",
            "Row 34: Predicted - B, Correct - A, Running Accuracy: 55.88%, Running F1 Score: 0.5565\n",
            "Number of Input Tokens:   408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a river\n",
            "    Description: A man kicks a fish while naked. The Fish goes flying in the air.\n",
            "    Uncanny Aspect: People don't kick fish while naked.\n",
            "    Question: ['Why is he kicking the fish naked?']\n",
            "    Additional Details: scene: a river description: A man kicks a fish while naked. The Fish goes flying in the air. uncanny: People don't kick fish while naked. entities: Fish, Nudity. choices A: Tell me about a difficult situation you've been in and what you did to get out of it. B: Now that I met your family, I want you to meet mine. C: You know, everyone laughed at Noah, too. D: I think you just ate the spare. E: You shouldn't have opened that can of worms.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Tell me about a difficult situation you've been in and what you did to get out of it.\n",
            "B: Now that I met your family, I want you to meet mine.\n",
            "C: You know, everyone laughed at Noah, too.\n",
            "D: I think you just ate the spare.\n",
            "E: You shouldn't have opened that can of worms.\n",
            "\n",
            "Caption = [/INST] This is a challenging cartoon description as none of the provided captions seem to fit the situation described in the cartoon. The cartoon description and question indicate an unusual behavior of a man kicking a fish naked, which is an uncanny aspect and makes it different from the given caption choices. None of the given captions contain any context about kicking a fish or nudity. Therefore, none of them are the correct answer.\n",
            "\n",
            "However, if we were to engage in a play\n",
            "Row 35: Predicted - No valid prediction found, Correct - B, Running Accuracy: 54.29%, Running F1 Score: 0.5455\n",
            "Number of Input Tokens:   514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a corporate meeting room\n",
            "    Description: There is a boardroom with several people sitting at a conference table.  On one side of the table are several men seated with hands on the table.  On the other side, and at the head of the table, are several women with one hand raised.\n",
            "    Uncanny Aspect: Only women in the scene are raising their hands, while the men are watching, seemingly confused.\n",
            "    Question: ['Why are only women raising their hands?']\n",
            "    Additional Details: scene: a corporate meeting room description: There is a boardroom with several people sitting at a conference table. On one side of the table are several men seated with hands on the table. On the other side, and at the head of the table, are several women with one hand raised. uncanny: Only women in the scene are raising their hands, while the men are watching, seemingly confused. entities: Meeting, Businessperson, Voting. choices A: Good news. We found a match. B: As an icebreaker, let's all share one interesting thing about ourselves. I'll start. C: Well, then, it's unanimous. D: My insurance doesn't cover prehistoric conditions. E: \" I can only make out : ' ... is required IMMEDIATELY ' .\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Good news. We found a match.\n",
            "B: As an icebreaker, let's all share one interesting thing about ourselves. I'll start.\n",
            "C: Well, then, it's unanimous.\n",
            "D: My insurance doesn't cover prehistoric conditions.\n",
            "E: \" I can only make out : ' ... is required IMMEDIATELY ' .\n",
            "\n",
            "Caption = [/INST] C: Well, then, it's unanimous.\n",
            "\n",
            "Explanation: The cartoon description indicates that the women are raising their hands, suggesting that they are making a decision or agreeing on something. The options suggest a few different scenarios that could be taking place, but option C seems to fit best with the information provided. The other options do not fit the context of the cartoon as described. Additionally, the uncanny aspect of the cartoon indicates that there is something\n",
            "Row 36: Predicted - C, Correct - C, Running Accuracy: 55.56%, Running F1 Score: 0.5572\n",
            "Number of Input Tokens:   442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a kitchen\n",
            "    Description: This takes place in a kitchen where everything is locked up tight, including the refrigerator and cupboards. There are traps and spikes covering the floor. Two people look on with inquisitive expressions.\n",
            "    Uncanny Aspect: People do not lock and set up traps in their kitchen.\n",
            "    Question: ['Why did the people decided to trap and lock their kitchen?']\n",
            "    Additional Details: scene: a kitchen description: This takes place in a kitchen where everything is locked up tight, including the refrigerator and cupboards. There are traps and spikes covering the floor. Two people look on with inquisitive expressions. uncanny: People do not lock and set up traps in their kitchen. entities: Trapping, Booby_trap, Dieting. choices A: Just lean in. B: Exhibits inability to understand maze exercise. C: I see our time is almost up. D: Damn. Now I'm kinda hungry. E: Well, there he goes—the first casualty of the War on Easter.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Just lean in.\n",
            "B: Exhibits inability to understand maze exercise.\n",
            "C: I see our time is almost up.\n",
            "D: Damn. Now I'm kinda hungry.\n",
            "E: Well, there he goes—the first casualty of the War on Easter.\n",
            "\n",
            "Caption = [/INST] D: Damn. Now I'm kinda hungry.\n",
            "\n",
            "Explanation: The cartoon description and uncanny aspect suggest that something unusual is going on in the kitchen, but it does not provide any indication that the people are on a diet or participating in a maze exercise (as suggested in options B and E), nor does it indicate a sense of imminent time limit or conflict (as suggested in options C and A). Option D, however, fits well with the scene\n",
            "Row 37: Predicted - D, Correct - D, Running Accuracy: 56.76%, Running F1 Score: 0.5718\n",
            "Number of Input Tokens:   411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: ocean\n",
            "    Description: Two sharks are facing each other in the ocean. One shark has a retail store wardrobe dummy in its mouth while the other watches.\n",
            "    Uncanny Aspect: It is unusual for a shark to have a wardrobe dummy in its mouth.\n",
            "    Question: ['Why does the shark have a dummy in its mouth.', 'What is the other shark who is watching thinking?']\n",
            "    Additional Details: scene: ocean description: Two sharks are facing each other in the ocean. One shark has a retail store wardrobe dummy in its mouth while the other watches. uncanny: It is unusual for a shark to have a wardrobe dummy in its mouth. entities: Shark, Mannequin. choices A: Look busy. B: Fine, but no flash photography. C: I miss the screaming. D: More legroom than I would have guessed. E: Stop fighting it, kid—everyone eventually sings in the shower.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Look busy.\n",
            "B: Fine, but no flash photography.\n",
            "C: I miss the screaming.\n",
            "D: More legroom than I would have guessed.\n",
            "E: Stop fighting it, kid—everyone eventually sings in the shower.\n",
            "\n",
            "Caption = [/INST] A: Look busy.\n",
            "\n",
            "Explanation:\n",
            "The unusual behavior of the shark having a wardrobe dummy in its mouth, along with the fact that the other shark is watching, suggests that this is a display or presentation of some kind. The phrase \"Look busy\" implies a performance or show put on to deceive or impress another. This fits the scene well as the shark seems to be attempting to impress or distract the other shark with the dummy in its mouth.\n",
            "Row 38: Predicted - A, Correct - C, Running Accuracy: 55.26%, Running F1 Score: 0.5611\n",
            "Number of Input Tokens:   420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a ship\n",
            "    Description: Two sailors are talking on the deck of a ship. Another man is sitting in a chair stroking a cat.\n",
            "    Uncanny Aspect: Nothing is out of place that I can see.\n",
            "    Question: ['Where are they sailing to?']\n",
            "    Additional Details: scene: a ship description: Two sailors are talking on the deck of a ship. Another man is sitting in a chair stroking a cat. uncanny: Nothing is out of place that I can see. entities: Abraham_Lincoln, Cat. choices A: You always get like this when there's a full Earth. B: We'll see how affectionate he is when he finds out who ate his parrot. C: You knew your wife might remarry. D: It says Martha Stewart once lived here. E: Kinda puts going to the vet in perspective, doesn't it?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You always get like this when there's a full Earth.\n",
            "B: We'll see how affectionate he is when he finds out who ate his parrot.\n",
            "C: You knew your wife might remarry.\n",
            "D: It says Martha Stewart once lived here.\n",
            "E: Kinda puts going to the vet in perspective, doesn't it?\n",
            "\n",
            "Caption = [/INST] E: Kinda puts going to the vet in perspective, doesn't it?\n",
            "\n",
            "Explanation: The scene depicts a peaceful setting on a ship with two sailors conversing and a man leisurely stroking a cat. The uncanny aspect suggests no unusual happenings in the scene. The cartoon does not provide enough context to answer the question \"Where are they sailing to?\" and there is no reference to any specific entities such as Abraham Lincoln or Martha Stewart in\n",
            "Row 39: Predicted - E, Correct - B, Running Accuracy: 53.85%, Running F1 Score: 0.5412\n",
            "Number of Input Tokens:   456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: beach\n",
            "    Description: A man and woman are sitting on the beach on a sunny day. They are nearly chest deep in ocean water though. They both have concerned expressions on their faces.\n",
            "    Uncanny Aspect: The couple is sitting in deep water rather than being on the sand.\n",
            "    Question: ['What caused the beach to be flooded?', \"Why isn't the couple moving out of the water?\"]\n",
            "    Additional Details: scene: beach description: A man and woman are sitting on the beach on a sunny day. They are nearly chest deep in ocean water though. They both have concerned expressions on their faces. uncanny: The couple is sitting in deep water rather than being on the sand. entities: Tide_table, Parasol_(disambiguation). choices A: I clearly recall choosing hell over high water. B: At least the hard part's over. C: Sometimes I wish you would keep your performance targets to yourself. D: I'm off to Walmart. Do you need anything? E: Good news! We have a solid lead on who stole your liver.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I clearly recall choosing hell over high water.\n",
            "B: At least the hard part's over.\n",
            "C: Sometimes I wish you would keep your performance targets to yourself.\n",
            "D: I'm off to Walmart. Do you need anything?\n",
            "E: Good news! We have a solid lead on who stole your liver.\n",
            "\n",
            "Caption = [/INST] A: I clearly recall choosing hell over high water. (This caption best matches the cartoon as the concerned expressions on the couple's faces and their unexpected position in deep water suggest they have found themselves in a difficult or unfamiliar situation that they may have regretted entering).</s>\n",
            "Row 40: Predicted - A, Correct - A, Running Accuracy: 55.00%, Running F1 Score: 0.5510\n",
            "Number of Input Tokens:   476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a field\n",
            "    Description: Two turkeys are standing facing each other in a coop. One turkey has fishnet stalkings and high heels on its legs and is talking to the other turkey.\n",
            "    Uncanny Aspect: It is unusual for a turkey to be wearing high heels and stockings.\n",
            "    Question: ['What is the turkey saying?', 'Why is the turkey wearing ladies accessories?']\n",
            "    Additional Details: scene: a field description: Two turkeys are standing facing each other in a coop. One turkey has fishnet stalkings and high heels on its legs and is talking to the other turkey. uncanny: It is unusual for a turkey to be wearing high heels and stockings. entities: Turkey_(bird), Prostitution. choices A: Don’t laugh, it got my uncle out of the army. B: Carry on. I'll just be a fly on the wall. C: Don't blame me—I voted for the other thing. D: I’m from the oversight committee. E: Are you gonna talk, or am I gonna have to flush the toilet again?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Don’t laugh, it got my uncle out of the army.\n",
            "B: Carry on. I'll just be a fly on the wall.\n",
            "C: Don't blame me—I voted for the other thing.\n",
            "D: I’m from the oversight committee.\n",
            "E: Are you gonna talk, or am I gonna have to flush the toilet again?\n",
            "\n",
            "Caption = [/INST] E: Are you gonna talk, or am I gonna have to flush the toilet again?\n",
            "\n",
            "Explanation:\n",
            "The cartoon description indicates that the turkey with high heels and stockings is talking to the other turkey, creating a context of a conversation. The options A, C, and D do not fit this context. Option B is unrelated to the scene. Option E provides a plausible conversation starter in the context of the cartoon, making it the most\n",
            "Row 41: Predicted - E, Correct - A, Running Accuracy: 53.66%, Running F1 Score: 0.5377\n",
            "Number of Input Tokens:   424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the gates of heaven\n",
            "    Description: A man in a beard is at a gate. He is writing something on a paper. There are barbed wires on the gate.\n",
            "    Uncanny Aspect: There are barbed wires on the gate to Heaven.\n",
            "    Question: ['Why are there barbed wires on the Gate to Heaven?']\n",
            "    Additional Details: scene: the gates of heaven description: A man in a beard is at a gate. He is writing something on a paper. There are barbed wires on the gate. uncanny: There are barbed wires on the gate to Heaven. entities: Heaven, Barbed_wire. choices A: Anything to declare? B: Because they don't need to be nailed to my feet, that's why. C: Did you just order 100 cheese pizzas? D: It’s my extended family. E: The doctor said it will eventually just go extinct.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Anything to declare?\n",
            "B: Because they don't need to be nailed to my feet, that's why.\n",
            "C: Did you just order 100 cheese pizzas?\n",
            "D: It’s my extended family.\n",
            "E: The doctor said it will eventually just go extinct.\n",
            "\n",
            "Caption = [/INST] A: Anything to declare? (This caption fits well with the scene of a man being questioned at a gate, even though the unexpected addition of barbed wires doesn't have an explicit explanation in this cartoon description, but it is a common trope in literature and media for there being barriers or inspections at gates to the afterlife.)</s>\n",
            "Row 42: Predicted - A, Correct - A, Running Accuracy: 54.76%, Running F1 Score: 0.5478\n",
            "Number of Input Tokens:   536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a tv show set\n",
            "    Description: A woman is sitting on recliner speaking to a man wearing a suit, sitting behind a desk. There is a microphone on the desk and two cameras pointed at them, implying this is a talk show. Behind the people are two windows showing a city scape, with bars over the windows.\n",
            "    Uncanny Aspect: It's unusual to see bars over windows looking out over the city on TV.\n",
            "    Question: ['Why are there metal bars over the windows?']\n",
            "    Additional Details: scene: a tv show set description: A woman is sitting on recliner speaking to a man wearing a suit, sitting behind a desk. There is a microphone on the desk and two cameras pointed at them, implying this is a talk show. Behind the people are two windows showing a city scape, with bars over the windows. uncanny: It's unusual to see bars over windows looking out over the city on TV. entities: Television_presenter, Guest_appearance. choices A: Noah, trust me. Its over. B: This is fancy role-playing for a conjugal visit. C: Have you considered writing this story in the third monkey rather than the first monkey? D: Surprise, surprise. The new manager is a fat white guy with no pants. E: If you see the cartoonist have him drop me a line.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Noah, trust me. Its over.\n",
            "B: This is fancy role-playing for a conjugal visit.\n",
            "C: Have you considered writing this story in the third monkey rather than the first monkey?\n",
            "D: Surprise, surprise. The new manager is a fat white guy with no pants.\n",
            "E: If you see the cartoonist have him drop me a line.\n",
            "\n",
            "Caption = [/INST] A: [\"Why are there metal bars over the windows?\"]\n",
            "A: Noah, trust me. It's over.\n",
            "\n",
            "This caption is the most likely answer because it directly addresses the question posed in the description and fits the tone of the scenario described in the cartoon. The other options do not directly relate to the situation in the cartoon.</s>\n",
            "Row 43: Predicted - A, Correct - B, Running Accuracy: 53.49%, Running F1 Score: 0.5321\n",
            "Number of Input Tokens:   416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the airport\n",
            "    Description: Two women are walking through an airport. They have their babies stored in their luggage.\n",
            "    Uncanny Aspect: Babies are usually put in strollers.\n",
            "    Question: ['Is that legal?']\n",
            "    Additional Details: scene: the airport description: Two women are walking through an airport. They have their babies stored in their luggage. uncanny: Babies are usually put in strollers. entities: Hand_luggage, Stowaway. choices A: A friendly gesture can make first contact go a lot better. B: We are going to go with Noah, but thanks. C: I'm not comfortable discussing that in front of my fish. D: Actually, I did leave my bag unattended for a few minutes. Why? E: This new M.B.A. crop is so hard to break.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: A friendly gesture can make first contact go a lot better.\n",
            "B: We are going to go with Noah, but thanks.\n",
            "C: I'm not comfortable discussing that in front of my fish.\n",
            "D: Actually, I did leave my bag unattended for a few minutes. Why?\n",
            "E: This new M.B.A. crop is so hard to break.\n",
            "\n",
            "Caption = [/INST] Based on the descriptions provided above, the best match for the given cartoon description is option D: \"Actually, I did leave my bag unattended for a few minutes. Why?\"\n",
            "\n",
            "The reason being, the description states that the babies are \"stored in their luggage.\" This, along with the scene taking place at the airport, implies that the women are traveling. Traveling with babies often requires the use of strollers to make moving around easier. The uncanny aspect\n",
            "Row 44: Predicted - B, Correct - D, Running Accuracy: 52.27%, Running F1 Score: 0.5195\n",
            "Number of Input Tokens:   381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: clouds\n",
            "    Description: Zeus and a man are standing on clouds. The man is about to chuck a lightning bolt.\n",
            "    Uncanny Aspect: Men don't usually get the powers of gods.\n",
            "    Question: ['Who is he throwing lightning at?']\n",
            "    Additional Details: scene: clouds description: Zeus and a man are standing on clouds. The man is about to chuck a lightning bolt. uncanny: Men don't usually get the powers of gods. entities: God, Lightning_strike. choices A: Boss is makin' us work from home now. B: I like that we’re not trapped in traditional gender roles. C: We’re tabling the motion. D: You knew your wife might remarry. E: There's water everywhere\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Boss is makin' us work from home now.\n",
            "B: I like that we’re not trapped in traditional gender roles.\n",
            "C: We’re tabling the motion.\n",
            "D: You knew your wife might remarry.\n",
            "E: There's water everywhere\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and information provided, the best matching caption would be E: \"There's water everywhere\" as there is no indication in the description that the man is throwing the lightning bolt at anyone or anything specific, and the uncanny aspect does not apply to this situation as it is a depiction of a mythological event. The other choices do not fit the given scenario.</s>\n",
            "Row 45: Predicted - B, Correct - D, Running Accuracy: 51.11%, Running F1 Score: 0.5073\n",
            "Number of Input Tokens:   500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: meeting room\n",
            "    Description: A group of businesspeople are sitting around a table. One of the people has a head that looks like a gumball machine or lightbulb.\n",
            "    Uncanny Aspect: It is odd to see a gumball machine or lightbulb on a human's body, especially since it seems to be participating in the meeting.\n",
            "    Question: ['What are they meeting about.']\n",
            "    Additional Details: scene: meeting room description: A group of businesspeople are sitting around a table. One of the people has a head that looks like a gumball machine or lightbulb. uncanny: It is odd to see a gumball machine or lightbulb on a human's body, especially since it seems to be participating in the meeting. entities: Electric_light, Meeting. choices A: Yes, Officer, they say he was about six feet four, with pointy ears and abnormally short arms. B: I hate our therapist. C: Oh, hey, I almost didn't recognize you outside of work. D: It looks like Ted is out of gumballs...meeting adjourned. E: I am telling you this guy is a micromanager.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Yes, Officer, they say he was about six feet four, with pointy ears and abnormally short arms.\n",
            "B: I hate our therapist.\n",
            "C: Oh, hey, I almost didn't recognize you outside of work.\n",
            "D: It looks like Ted is out of gumballs...meeting adjourned.\n",
            "E: I am telling you this guy is a micromanager.\n",
            "\n",
            "Caption = [/INST] D: It looks like Ted is out of gumballs...meeting adjourned.\n",
            "\n",
            "Explanation:\n",
            "The cartoon description states that one of the businesspeople has a head that looks like a gumball machine. This suggests that the man in question might be running out of ideas or inspiration during the meeting, leading to the caption \"It looks like Ted is out of gumballs...meeting adjourned\" which is a common phrase used in\n",
            "Row 46: Predicted - D, Correct - D, Running Accuracy: 52.17%, Running F1 Score: 0.5212\n",
            "Number of Input Tokens:   490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: beach\n",
            "    Description: Everyone except one person is up to their neck in sand. They all look up at the man above ground as he looks down sadly at them.\n",
            "    Uncanny Aspect: It is weird to have so many people be buried up to their neck in sand.\n",
            "    Question: ['Why are the people buried in sand?']\n",
            "    Additional Details: scene: beach description: Everyone except one person is up to their neck in sand. They all look up at the man above ground as he looks down sadly at them. uncanny: It is weird to have so many people be buried up to their neck in sand. entities: Swimsuit, Sand. choices A: In the end, Ed, most of us are carried along by our delusions. B: put me back in the hat, man, I hate seeing them in cages like this C: I don't know about you, but I'd be willing to pitch in for a new contact lens. D: If their dog starts humping your leg - let it finish. E: Run! The kid with the little red shovel is coming back!\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: In the end, Ed, most of us are carried along by our delusions.\n",
            "B: put me back in the hat, man, I hate seeing them in cages like this\n",
            "C: I don't know about you, but I'd be willing to pitch in for a new contact lens.\n",
            "D: If their dog starts humping your leg - let it finish.\n",
            "E: Run! The kid with the little red shovel is coming back!\n",
            "\n",
            "Caption = [/INST] Based on the provided cartoon description and the given captions, the best match for the cartoon would be E: Run! The kid with the little red shovel is coming back!\n",
            "\n",
            "The reason for this is that the description states \"Everyone except one person is up to their neck in sand. They all look up at the man above ground as he looks down sadly at them,\" which suggests that something is causing the people to end up in the sand. The uncanny aspect\n",
            "Row 47: Predicted - B, Correct - E, Running Accuracy: 51.06%, Running F1 Score: 0.5129\n",
            "Number of Input Tokens:   501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a counter\n",
            "    Description: There is a man in a tuxedo who is frowning while looking at a cake which is topped with figurines of a marrying couple. The cake also shows a face on the bottom tier which is looking at the man and talking.\n",
            "    Uncanny Aspect: It is unusual for a cake to have a face on the side which can talk.\n",
            "    Question: ['What is the cake saying to the frowning man?']\n",
            "    Additional Details: scene: a counter description: There is a man in a tuxedo who is frowning while looking at a cake which is topped with figurines of a marrying couple. The cake also shows a face on the bottom tier which is looking at the man and talking. uncanny: It is unusual for a cake to have a face on the side which can talk. entities: Wedding_cake, Anthropomorphism. choices A: Great wedding—what's for dessert? B: You think Alcatraz can hold me? C: Ok you can go down one more time but then you have to save me D: See? Foreclosure's not all bad. E: You know how it is—first you buy the giant-screen television, then nothing else seems to match.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Great wedding—what's for dessert?\n",
            "B: You think Alcatraz can hold me?\n",
            "C: Ok you can go down one more time but then you have to save me\n",
            "D: See? Foreclosure's not all bad.\n",
            "E: You know how it is—first you buy the giant-screen television, then nothing else seems to match.\n",
            "\n",
            "Caption = [/INST] D: See? Foreclosure's not all bad.\n",
            "\n",
            "Explanation: The cartoon's description mentions that the man in a tuxedo is frowning, suggesting that he may be feeling down or unhappy. The talking cake's statement, \"See? Foreclosure's not all bad,\" fits well with this mood and adds a comedic twist to the situation by personifying the cake and making it offer a consoling remark. The other options do not\n",
            "Row 48: Predicted - D, Correct - A, Running Accuracy: 50.00%, Running F1 Score: 0.5024\n",
            "Number of Input Tokens:   467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an alleyway\n",
            "    Description: Devils are herding people in the middle of a street. A manhole is open and there is fire below.\n",
            "    Uncanny Aspect: Devils in the middle of a city are pretty out of place, and hell being in the sewers is too.\n",
            "    Question: ['Are these people still alive?']\n",
            "    Additional Details: scene: an alleyway description: Devils are herding people in the middle of a street. A manhole is open and there is fire below. uncanny: Devils in the middle of a city are pretty out of place, and hell being in the sewers is too. entities: Portal_(architecture), Hell, Manhole. choices A: I see Wall Street is hiring again! B: I'm thinking now I probably should have just trained them to get help. C: He's the advertising executive. Let him come up with a caption. D: What happens on Vega stays on Vega. E: Oddly enough, it's the Capri pants that I hear about the most.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I see Wall Street is hiring again!\n",
            "B: I'm thinking now I probably should have just trained them to get help.\n",
            "C: He's the advertising executive. Let him come up with a caption.\n",
            "D: What happens on Vega stays on Vega.\n",
            "E: Oddly enough, it's the Capri pants that I hear about the most.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and the unconventional nature of the scene, option C: \"He's the advertising executive. Let him come up with a caption\" seems like the most fitting choice. This option adds a layer of surrealism and humor to the already unusual scene, making it a perfect fit for The New Yorker's style of cartooning.</s>\n",
            "Row 49: Predicted - B, Correct - A, Running Accuracy: 48.98%, Running F1 Score: 0.4946\n",
            "Number of Input Tokens:   522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a living room\n",
            "    Description: A man and woman are relaxing in their living room on the couch. The woman is reading a book and the man is watching TV. In the corner of the room there is a food truck with a man working inside of it.\n",
            "    Uncanny Aspect: There is a food truck in the middle of someones home rather than being out on the street where more people are.\n",
            "    Question: [\"Why would the food truck choose to do business in this family's home?\"]\n",
            "    Additional Details: scene: a living room description: A man and woman are relaxing in their living room on the couch. The woman is reading a book and the man is watching TV. In the corner of the room there is a food truck with a man working inside of it. uncanny: There is a food truck in the middle of someones home rather than being out on the street where more people are. entities: Ice_cream_van, Food_booth. choices A: Ice fishing and skydiving—who says they don't go together? B: Sorry, my roommate's working from home today. C: It's the swimming portion that I am most concerned with. D: Barb was telling me there's been a rash of azalea thefts. E: Well of course they don't exist. Now.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Ice fishing and skydiving—who says they don't go together?\n",
            "B: Sorry, my roommate's working from home today.\n",
            "C: It's the swimming portion that I am most concerned with.\n",
            "D: Barb was telling me there's been a rash of azalea thefts.\n",
            "E: Well of course they don't exist. Now.\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description, the best-matching caption for this New Yorker cartoon would be: D. \"Barb was telling me there's been a rash of azalea thefts.\"\n",
            "\n",
            "The reason for this is that the scene in the cartoon depicts a food truck in the corner of a living room. None of the other options directly relate to a food truck or a living room setting. Option D, however, does\n",
            "Row 50: Predicted - B, Correct - B, Running Accuracy: 50.00%, Running F1 Score: 0.5054\n",
            "Number of Input Tokens:   462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the doctor's office\n",
            "    Description: A doctor is examining a patient in his office. He has a giant magnifying glass.\n",
            "    Uncanny Aspect: The magnifying glass is huge.\n",
            "    Question: ['Why does the doctor need that?']\n",
            "    Additional Details: scene: the doctor's office description: A doctor is examining a patient in his office. He has a giant magnifying glass. uncanny: The magnifying glass is huge. entities: Magnifying_glass, Doctor. choices A: Instead of an expensive, invasive procedure, we've decided to beat it out of you. B: I'm beginning to see what you mean. C: The rear-facing camera let's him know I'm here. D: I keep telling him, 'For God’s sake, put down the whip, she has a learning disability.’ E: In order to truly master the art of fetch, you must understand every element of the process.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Instead of an expensive, invasive procedure, we've decided to beat it out of you.\n",
            "B: I'm beginning to see what you mean.\n",
            "C: The rear-facing camera let's him know I'm here.\n",
            "D: I keep telling him, 'For God’s sake, put down the whip, she has a learning disability.’\n",
            "E: In order to truly master the art of fetch, you must understand every element of the process.\n",
            "\n",
            "Caption = [/INST] A: Instead of an expensive, invasive procedure, we've decided to beat it out of you. (This caption is the least likely to fit the cartoon as there is no indication in the description that the doctor is trying to extract anything from the patient or that an expensive, invasive procedure is being discussed. The giant magnifying glass is an unusual but harmless tool in the context given.)</s>\n",
            "Row 51: Predicted - A, Correct - B, Running Accuracy: 49.02%, Running F1 Score: 0.4938\n",
            "Number of Input Tokens:   419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: forest\n",
            "    Description: A hunter walks around with a gun over his shoulder. Two birds look on as another bird is on the hunters gun.\n",
            "    Uncanny Aspect: Birds would be too scared to stay on the gun.\n",
            "    Question: ['Why is the bird on the gun?']\n",
            "    Additional Details: scene: forest description: A hunter walks around with a gun over his shoulder. Two birds look on as another bird is on the hunters gun. uncanny: Birds would be too scared to stay on the gun. entities: Hunting, Shotgun_shell. choices A: Yeah, well, these are my obsession now. B: ‘How many accountants does it take to sharpen a pencil?’ you ask? In this case five. C: It must be great to be endangered. D: It was in international waters. E: I'm working from home.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Yeah, well, these are my obsession now.\n",
            "B: ‘How many accountants does it take to sharpen a pencil?’ you ask? In this case five.\n",
            "C: It must be great to be endangered.\n",
            "D: It was in international waters.\n",
            "E: I'm working from home.\n",
            "\n",
            "Caption = [/INST] C. It must be great to be endangered.\n",
            "\n",
            "Explanation: The description of the cartoon indicates that there is a hunter in the forest with a gun, and two birds are looking on as another bird is on the hunter's gun. The uncanny aspect suggests that something unusual is happening in the scene, but it does not eliminate any of the given options. The question asks why the bird is on the gun. None of the options directly answer the question\n",
            "Row 52: Predicted - C, Correct - C, Running Accuracy: 50.00%, Running F1 Score: 0.5033\n",
            "Number of Input Tokens:   465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: living room\n",
            "    Description: A man is standing next to the table and calling someone on the phone. Man looks concerned and there is a knife stabbed on this back with couple pieces of paper.\n",
            "    Uncanny Aspect: Man taking on the phone with a knife stabbed on this back is unusual.\n",
            "    Question: ['Why did someone stab the knife on his back?']\n",
            "    Additional Details: scene: living room description: A man is standing next to the table and calling someone on the phone. Man looks concerned and there is a knife stabbed on this back with couple pieces of paper. uncanny: Man taking on the phone with a knife stabbed on this back is unusual. entities: Ninety-five_Theses, Telephone. choices A: No, my wife served the papers personally. B: I'm trying to see it from your point of view. C: Armstrong? No, though I do get mistaken for Lance a lot. D: How long you been with the club? E: He may be my best friend, but you will always be the reason mom and I got married.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: No, my wife served the papers personally.\n",
            "B: I'm trying to see it from your point of view.\n",
            "C: Armstrong? No, though I do get mistaken for Lance a lot.\n",
            "D: How long you been with the club?\n",
            "E: He may be my best friend, but you will always be the reason mom and I got married.\n",
            "\n",
            "Caption = [/INST] Based on the description provided, the most unusual aspect of the cartoon is the man holding a knife with papers on his back while on the phone. This behavior is not typical, and it suggests that something out of the ordinary is happening. Given this context, option E is the least likely to fit the scene as it does not mention anything about a knife or a strange behavior while on the phone. Therefore, the other options, A, B, C, and D, are potential candidates.\n",
            "\n",
            "Row 53: Predicted - B, Correct - A, Running Accuracy: 49.06%, Running F1 Score: 0.4954\n",
            "Number of Input Tokens:   406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: Living Room\n",
            "    Description: A taxi car enters a fancy building by taking the stairs. People look on in shock.\n",
            "    Uncanny Aspect: Driving inside buildings is usually destructive and can harm people inside.\n",
            "    Question: ['Why did the person drive inside the building?']\n",
            "    Additional Details: scene: Living Room description: A taxi car enters a fancy building by taking the stairs. People look on in shock. uncanny: Driving inside buildings is usually destructive and can harm people inside. entities: Convertible, Meeting. choices A: Robin totalled the Batmobile—again! B: Read quickly. These are really heavy. C: Why can't he take a limo like the rest of us? D: I'm really more of a painter-gatherer. E: I'm sorry. I've been burned too many times.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Robin totalled the Batmobile—again!\n",
            "B: Read quickly. These are really heavy.\n",
            "C: Why can't he take a limo like the rest of us?\n",
            "D: I'm really more of a painter-gatherer.\n",
            "E: I'm sorry. I've been burned too many times.\n",
            "\n",
            "Caption = [/INST] A: \"Robin totalled the Batmobile—again!\"\n",
            "\n",
            "Explanation: The cartoon description mentions a taxi entering a building, which is an unlikely and unexpected action. This uncanny occurrence is reminiscent of Batman's nemesis Robin crashing the Batmobile, making option A the best fit. While options B, C, D, and E may also be humorous, none of them directly relate to a taxi driving inside a building. Additionally,\n",
            "Row 54: Predicted - A, Correct - C, Running Accuracy: 48.15%, Running F1 Score: 0.4889\n",
            "Number of Input Tokens:   443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a ranch\n",
            "    Description: A cowboy is on a ranch. He is looking at a horse.\n",
            "    Uncanny Aspect: The horse is wearing human shoes.\n",
            "    Question: ['Why are only the shoes in color?']\n",
            "    Additional Details: scene: a ranch description: A cowboy is on a ranch. He is looking at a horse. uncanny: The horse is wearing human shoes. entities: Shoe, Horse. choices A: I'd love to come, but you know the old ball and chain. B: That's Bob Mankoff. He used to be the cartoon editor of the New Yorker. C: It's a lot to digest. D: If you can remove it... it means your heart is pure. But you can no longer work in sales. E: Because they don't need to be nailed to my feet, that's why.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I'd love to come, but you know the old ball and chain.\n",
            "B: That's Bob Mankoff. He used to be the cartoon editor of the New Yorker.\n",
            "C: It's a lot to digest.\n",
            "D: If you can remove it... it means your heart is pure. But you can no longer work in sales.\n",
            "E: Because they don't need to be nailed to my feet, that's why.\n",
            "\n",
            "Caption = [/INST] E: Because they don't need to be nailed to my feet, that's why.\n",
            "\n",
            "Explanation:\n",
            "Given the description of a cowboy looking at a horse with human shoes, the most fitting caption would be the one that addresses the unusual aspect of the horse wearing shoes. Option E directly references the shoes and offers an explanation for their presence. While the other options do not relate to the shown scenario.</s>\n",
            "Row 55: Predicted - E, Correct - E, Running Accuracy: 49.09%, Running F1 Score: 0.4982\n",
            "Number of Input Tokens:   508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a kingdom\n",
            "    Description: There is a king leaning back in his throne who is listening to a scribe who stands in front of him. The scribe is reading from a piece of rolled parchment. Above the king hangs a giant sword which stretches across the entire width of the room.\n",
            "    Uncanny Aspect: It is unusual for a sword to be this size and for it to be hung directly above the king's throne.\n",
            "    Question: ['Why is the sword so big?', 'What is the scribe reading to the king?']\n",
            "    Additional Details: scene: a kingdom description: There is a king leaning back in his throne who is listening to a scribe who stands in front of him. The scribe is reading from a piece of rolled parchment. Above the king hangs a giant sword which stretches across the entire width of the room. uncanny: It is unusual for a sword to be this size and for it to be hung directly above the king's throne. entities: Dagger, King. choices A: Your overhead is going to kill you. B: No, no! We don't test on animals. C: He's not as bad as the last manager. That one was abominable. D: Business school changed you, Son. E: Poor guy. Thought he signed up for pilates.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Your overhead is going to kill you.\n",
            "B: No, no! We don't test on animals.\n",
            "C: He's not as bad as the last manager. That one was abominable.\n",
            "D: Business school changed you, Son.\n",
            "E: Poor guy. Thought he signed up for pilates.\n",
            "\n",
            "Caption = [/INST] A: Your overhead is going to kill you. (The size of the sword could be interpreted as an \"overhead\" issue for the king)</s>\n",
            "Row 56: Predicted - A, Correct - A, Running Accuracy: 50.00%, Running F1 Score: 0.5065\n",
            "Number of Input Tokens:   451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: woods\n",
            "    Description: A boy is standing next to a tree with a cherry on his head. A man is standing away from him with a bow.\n",
            "    Uncanny Aspect: The cherry is the only thing in color.\n",
            "    Question: ['Why is the cherry colored in?']\n",
            "    Additional Details: scene: woods description: A boy is standing next to a tree with a cherry on his head. A man is standing away from him with a bow. uncanny: The cherry is the only thing in color. entities: Archery, Apple. choices A: I'm afraid this whole experiment is about to go south. B: What do you mean, 'YOU'RE scared you might miss' ? C: I don't think he realizes the gravity of the situation. D: Come on, George. You know he's only going to spend it on more oxygen. E: It's cheaper than coach, and he gets more legroom.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I'm afraid this whole experiment is about to go south.\n",
            "B: What do you mean, 'YOU'RE scared you might miss' ?\n",
            "C: I don't think he realizes the gravity of the situation.\n",
            "D: Come on, George. You know he's only going to spend it on more oxygen.\n",
            "E: It's cheaper than coach, and he gets more legroom.\n",
            "\n",
            "Caption = [/INST] C: I don't think he realizes the gravity of the situation.\n",
            "\n",
            "Explanation:\n",
            "\n",
            "Given the cartoon description and the uncanny aspect, it is not immediately clear why the cherry is colored in. However, the additional details do not provide any explanations for this. Therefore, we cannot rely on the information about the cherry being the only thing in color to help us identify the correct caption.\n",
            "\n",
            "Instead, we should focus on the\n",
            "Row 57: Predicted - C, Correct - B, Running Accuracy: 49.12%, Running F1 Score: 0.4944\n",
            "Number of Input Tokens:   438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: stone age\n",
            "    Description: A caveman couple walk by a tower to see people they recognize. The cavewoman waves at her friend who waves back. The men are expressionless about the encounter.\n",
            "    Uncanny Aspect: The tower is taller than the average height building for its time.\n",
            "    Question: ['How did they manage to build that long tower?']\n",
            "    Additional Details: scene: stone age description: A caveman couple walk by a tower to see people they recognize. The cavewoman waves at her friend who waves back. The men are expressionless about the encounter. uncanny: The tower is taller than the average height building for its time. entities: Caveman, Tower. choices A: Some guys never make it out of the plastic bag. B: Thank God, Fashion Week is over. C: My wife left me for Mr. Peanut. D: You probably meant compote. E: Four-story brownstones? They'll never catch on, not in a million years.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Some guys never make it out of the plastic bag.\n",
            "B: Thank God, Fashion Week is over.\n",
            "C: My wife left me for Mr. Peanut.\n",
            "D: You probably meant compote.\n",
            "E: Four-story brownstones? They'll never catch on, not in a million years.\n",
            "\n",
            "Caption = [/INST] E: Four-story brownstones? They'll never catch on, not in a million years.\n",
            "\n",
            "Explanation:\n",
            "The cartoon description clearly indicates that the scene is set in the stone age, and there's an unusual tower in the background that is taller than typical buildings of that time. With the given options, the only caption that acknowledges the presence and height of the tower is choice E. Therefore, it is the most plausible answer.\n",
            "Row 58: Predicted - E, Correct - E, Running Accuracy: 50.00%, Running F1 Score: 0.5031\n",
            "Number of Input Tokens:   404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a teacup\n",
            "    Description: Two men are sailing in liquid. But they're inside a giant cup.\n",
            "    Uncanny Aspect: The cup is either huge or the men and boat are tiny.\n",
            "    Question: ['What is going on here?']\n",
            "    Additional Details: scene: a teacup description: Two men are sailing in liquid. But they're inside a giant cup. uncanny: The cup is either huge or the men and boat are tiny. entities: Shipwreck, Storm. choices A: Throw us a doughnut! B: How long has the \"Check Condiments\" light been on? C: The answer to number seven? I can't even turn this thing on. D: You always have to be an early adopter. E: I'm trying to see it from your point of view.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Throw us a doughnut!\n",
            "B: How long has the \"Check Condiments\" light been on?\n",
            "C: The answer to number seven? I can't even turn this thing on.\n",
            "D: You always have to be an early adopter.\n",
            "E: I'm trying to see it from your point of view.\n",
            "\n",
            "Caption = [/INST] C. The answer to number seven? I can't even turn this thing on.\n",
            "\n",
            "Explanation: The description states that the two men are sailing in a giant teacup, making it unclear if the cup is huge or the men and boat are tiny. The uncanny aspect makes it seem as though this is an unusual or improbable situation. The given caption option C references a common problem with appliances or devices that can't be turned on or\n",
            "Row 59: Predicted - C, Correct - A, Running Accuracy: 49.15%, Running F1 Score: 0.4938\n",
            "Number of Input Tokens:   482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a living room\n",
            "    Description: A person sits on a couch with their feet propped on an ottoman inside a living room.  The living room is filled with sheep and the person is holding a shepherd's crook\n",
            "    Uncanny Aspect: It's unusual to see sheep inside a living room\n",
            "    Question: ['Why are there sheep in that room?']\n",
            "    Additional Details: scene: a living room description: A person sits on a couch with their feet propped on an ottoman inside a living room. The living room is filled with sheep and the person is holding a shepherd's crook uncanny: It's unusual to see sheep inside a living room entities: Sheep, Shepherd. choices A: It cuts down on the yelling and splashing. B: I'm not sure how many there are. Every time I start counting I fall asleep. C: Geez, it's twenty-five to life already. D: Now, if you wouldn't mind holding on to this while I get the thermometer. E: Harry, the whole point of leaving England was to blend in.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It cuts down on the yelling and splashing.\n",
            "B: I'm not sure how many there are. Every time I start counting I fall asleep.\n",
            "C: Geez, it's twenty-five to life already.\n",
            "D: Now, if you wouldn't mind holding on to this while I get the thermometer.\n",
            "E: Harry, the whole point of leaving England was to blend in.\n",
            "\n",
            "Caption = [/INST] E: Harry, the whole point of leaving England was to blend in. (This caption is the most absurd and unexpected answer, which fits the uncanny aspect of the scene)</s>\n",
            "Row 60: Predicted - E, Correct - B, Running Accuracy: 48.33%, Running F1 Score: 0.4826\n",
            "Number of Input Tokens:   573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a cave\n",
            "    Description: Two cavemen are sitting in a cave in a mountainous region. They are surrounded by what look like stone wheels. One of the cavemen is taking a bite of the wheel, while the other one holds his stomach as if he's already eaten too much.\n",
            "    Uncanny Aspect: We assume that the wheels are made of stone, but actually, they appear to be doughnuts, which have a similar shape, but are edible and made of dough.\n",
            "    Question: ['Why did the cavemen make giant doughnuts instead of carving stone wheels, as we might expect?']\n",
            "    Additional Details: scene: a cave description: Two cavemen are sitting in a cave in a mountainous region. They are surrounded by what look like stone wheels. One of the cavemen is taking a bite of the wheel, while the other one holds his stomach as if he's already eaten too much. uncanny: We assume that the wheels are made of stone, but actually, they appear to be doughnuts, which have a similar shape, but are edible and made of dough. entities: Wheel, Doughnut, Caveman. choices A: I recommend the pigeon. It's locally sourced. B: Home— is there really no place like it? Who’d like to start? C: O.K. I'm at the window. To the right? Your right or my right? D: I'd kill for some cream cheese. E: It made so much more sense in the infomercial.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I recommend the pigeon. It's locally sourced.\n",
            "B: Home— is there really no place like it? Who’d like to start?\n",
            "C: O.K. I'm at the window. To the right? Your right or my right?\n",
            "D: I'd kill for some cream cheese.\n",
            "E: It made so much more sense in the infomercial.\n",
            "\n",
            "Caption = [/INST] D: I'd kill for some cream cheese.\n",
            "\n",
            "Explanation: The cavemen's reactions to the doughnut-wheels suggest that they find them to be a delicious treat, implying that they are surprised to find edible doughnuts instead of the stone wheels they were expecting. The caption option \"I'd kill for some cream cheese\" also implies a desire for a tasty treat, making it the best match for the cartoon. The other options\n",
            "Row 61: Predicted - D, Correct - D, Running Accuracy: 49.18%, Running F1 Score: 0.4924\n",
            "Number of Input Tokens:   443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: sheriff office\n",
            "    Description: A cowboy is in a wooden room. There is a baby and several animals present, and guns on the wall.\n",
            "    Uncanny Aspect: The animals and the baby don't belong in there.\n",
            "    Question: ['Why are all these various elements present?']\n",
            "    Additional Details: scene: sheriff office description: A cowboy is in a wooden room. There is a baby and several animals present, and guns on the wall. uncanny: The animals and the baby don't belong in there. entities: Infant, Raccoon. choices A: Carry on. I'll just be a fly on the wall. B: I liked it better when we just had your people call my people. C: I've got to stop advertising for posses in the classifieds. D: Does this make me the trophy's wife? E: All my co-workers think this is just a virtual Zoom background.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Carry on. I'll just be a fly on the wall.\n",
            "B: I liked it better when we just had your people call my people.\n",
            "C: I've got to stop advertising for posses in the classifieds.\n",
            "D: Does this make me the trophy's wife?\n",
            "E: All my co-workers think this is just a virtual Zoom background.\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description and the uncanny aspect of the scene, the most likely caption is C: \"I've got to stop advertising for posses in the classifieds.\" The presence of the cowboy in a sheriff office with a baby and several animals, which are uncanny elements in the scene, suggests that something unusual or out of place is happening. The caption choice \"I've got to stop advertising for posses in the classified\n",
            "Row 62: Predicted - B, Correct - C, Running Accuracy: 48.39%, Running F1 Score: 0.4873\n",
            "Number of Input Tokens:   485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a baseball game\n",
            "    Description: A caveman with a large club is facing an umpire on a baseball field. The caveman and umpire is on the batter base but the caveman is facing the wrong way.\n",
            "    Uncanny Aspect: A caveman is not a player in the game of baseball. Usually the batter is.\n",
            "    Question: ['Why the caveman not batting?']\n",
            "    Additional Details: scene: a baseball game description: A caveman with a large club is facing an umpire on a baseball field. The caveman and umpire is on the batter base but the caveman is facing the wrong way. uncanny: A caveman is not a player in the game of baseball. Usually the batter is. entities: Caveman, Club_(weapon). choices A: I'd say your timing's a bit off. B: You think this is weird? My sister looks like a soup can. C: Let's go now while there's no line. D: I wasn't laid off—I just decided to pursue other interests. E: There’s a cure—but it’s light-years away.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I'd say your timing's a bit off.\n",
            "B: You think this is weird? My sister looks like a soup can.\n",
            "C: Let's go now while there's no line.\n",
            "D: I wasn't laid off—I just decided to pursue other interests.\n",
            "E: There’s a cure—but it’s light-years away.\n",
            "\n",
            "Caption = [/INST] A: I'd say your timing's a bit off. (This caption acknowledges the caveman's unusual position on the baseball field and could be a possible explanation for why he's not batting.)</s>\n",
            "Row 63: Predicted - A, Correct - A, Running Accuracy: 49.21%, Running F1 Score: 0.4952\n",
            "Number of Input Tokens:   451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a community\n",
            "    Description: This is in England during the Victorian Era. Two men are staring at a woman. The woman has a huge collar around her neck.\n",
            "    Uncanny Aspect: The woman's collar is huge. It covers half her face and is not supposed to be like that.\n",
            "    Question: ['Why is the collar so exaggerated on the woman?']\n",
            "    Additional Details: scene: a community description: This is in England during the Victorian Era. Two men are staring at a woman. The woman has a huge collar around her neck. uncanny: The woman's collar is huge. It covers half her face and is not supposed to be like that. entities: Ruff_(clothing), Victorian_era. choices A: Are there two guys with a couch following me or am I imagining it? B: He's lucky I didn't rear end him. C: Greetings, and let go of my penis. D: Next time we can meet at your office. E: She's the only surviving wife of Henry the VIII.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Are there two guys with a couch following me or am I imagining it?\n",
            "B: He's lucky I didn't rear end him.\n",
            "C: Greetings, and let go of my penis.\n",
            "D: Next time we can meet at your office.\n",
            "E: She's the only surviving wife of Henry the VIII.\n",
            "\n",
            "Caption = [/INST] Based on the description provided, the correct answer is E. The cartoon takes place in England during the Victorian Era, and the woman has an uncanny, oversized collar. This description fits best with the caption \"She's the only surviving wife of Henry the VIII.\" This witty comment refers to the historical fact that many wives of King Henry VIII had large collars for fashion reasons during that era.</s>\n",
            "Row 64: Predicted - B, Correct - E, Running Accuracy: 48.44%, Running F1 Score: 0.4901\n",
            "Number of Input Tokens:   385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: kingdom\n",
            "    Description: A king is sitting on his throne. Various plants surround him. He is addressing a knight.\n",
            "    Uncanny Aspect: Cacti aren't native to anywhere that has had a king.\n",
            "    Question: ['What are the two talking about?']\n",
            "    Additional Details: scene: kingdom description: A king is sitting on his throne. Various plants surround him. He is addressing a knight. uncanny: Cacti aren't native to anywhere that has had a king. entities: Cactus, King. choices A: It's curb to table. B: You have any small bills? C: If their dog starts humping your leg - let it finish. D: Oh, you said assemble the caucus... E: We had meth on Tuesday.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It's curb to table.\n",
            "B: You have any small bills?\n",
            "C: If their dog starts humping your leg - let it finish.\n",
            "D: Oh, you said assemble the caucus...\n",
            "E: We had meth on Tuesday.\n",
            "\n",
            "Caption = [/INST] Based on the descriptions provided above, none of the given captions match the cartoon. The cartoon description indicates that the king is in a kingdom, addressing a knight, and there are various plants present. The uncanny aspect suggests that there is something unexpected or out of place, but the given options do not fit this description. Therefore, no clear answer can be determined with the provided information.</s>\n",
            "Row 65: Predicted - B, Correct - D, Running Accuracy: 47.69%, Running F1 Score: 0.4837\n",
            "Number of Input Tokens:   420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: office\n",
            "    Description: A dirty exhausted man is crawling toward an emergency hotline booth. One of the operators is yelling at him.\n",
            "    Uncanny Aspect: The man is so exhausted but is presumably in the middle of civilization.\n",
            "    Question: ['Why is he being yelled at?']\n",
            "    Additional Details: scene: office description: A dirty exhausted man is crawling toward an emergency hotline booth. One of the operators is yelling at him. uncanny: The man is so exhausted but is presumably in the middle of civilization. entities: Hotline, Emergency, Homeless. choices A: If he's elected, we're going to have a tough time proving we weren't born in Africa. B: Neither the time nor the place, Doug! C: Maybe it would go better in the den. D: Let’s not tell Dad. E: This department has become loyal to a fault.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: If he's elected, we're going to have a tough time proving we weren't born in Africa.\n",
            "B: Neither the time nor the place, Doug!\n",
            "C: Maybe it would go better in the den.\n",
            "D: Let’s not tell Dad.\n",
            "E: This department has become loyal to a fault.\n",
            "\n",
            "Caption = [/INST] Based on the description provided, it is unlikely that the caption is A: \"If he's elected, we're going to have a tough time proving we weren't born in Africa\" as there is no mention of any election or citizenship in the description.\n",
            "\n",
            "B: \"Neither the time nor the place, Doug!\" is also a possible option, but it does not directly relate to the situation in the cartoon as there is no mention of Doug or a\n",
            "Row 66: Predicted - B, Correct - B, Running Accuracy: 48.48%, Running F1 Score: 0.4915\n",
            "Number of Input Tokens:   455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a therapist office\n",
            "    Description: A person stands on a bed in a shrink's office posing while holding flags.  The shrink sits next to him, looking over.\n",
            "    Uncanny Aspect: It's unusual to see a person waving flags in a shrink's office.\n",
            "    Question: ['What is that person doing with the flags?']\n",
            "    Additional Details: scene: a therapist office description: A person stands on a bed in a shrink's office posing while holding flags. The shrink sits next to him, looking over. uncanny: It's unusual to see a person waving flags in a shrink's office. entities: Therapy, Flag_of_Scotland. choices A: This was easier to carry when it was flat. B: I thought you said the cloud was secure. C: Great! Next week we'll work on your fear of Morse code. D: Just be glad I didn't come here when I had a ponytail. E: You think Alcatraz can hold me?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: This was easier to carry when it was flat.\n",
            "B: I thought you said the cloud was secure.\n",
            "C: Great! Next week we'll work on your fear of Morse code.\n",
            "D: Just be glad I didn't come here when I had a ponytail.\n",
            "E: You think Alcatraz can hold me?\n",
            "\n",
            "Caption = [/INST] C. Great! Next week we'll work on your fear of Morse code.\n",
            "\n",
            "Explanation: The description mentions that it's unusual to see a person waving flags in a shrink's office. The caption option C directly relates to the unusual action of waving flags in this context, suggesting a fear or phobia related to Morse code, which could be represented by flags. The other options don't directly pertain to the situation\n",
            "Row 67: Predicted - C, Correct - C, Running Accuracy: 49.25%, Running F1 Score: 0.4988\n",
            "Number of Input Tokens:   459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: office room\n",
            "    Description: Two men are sitting in office. The man behind the desk has a gigantic pencil sharpener on one side of his desk and a cup of gigantic pencils on the other side.\n",
            "    Uncanny Aspect: The pencils and pencil sharpener are both abnormally large.\n",
            "    Question: ['What could this man be doing with pencils that large?']\n",
            "    Additional Details: scene: office room description: Two men are sitting in office. The man behind the desk has a gigantic pencil sharpener on one side of his desk and a cup of gigantic pencils on the other side. uncanny: The pencils and pencil sharpener are both abnormally large. entities: Pencil_sharpener, Pencil. choices A: Congratulations-- it’s a porcupine. B: I think the head's in the wrong place. C: The good news is all the pieces fit. D: But I have to warn you, carpal tunnel here is a bitch. E: Regime change is never easy, dear.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Congratulations-- it’s a porcupine.\n",
            "B: I think the head's in the wrong place.\n",
            "C: The good news is all the pieces fit.\n",
            "D: But I have to warn you, carpal tunnel here is a bitch.\n",
            "E: Regime change is never easy, dear.\n",
            "\n",
            "Caption = [/INST] D: But I have to warn you, carpal tunnel here is a bitch.\n",
            "\n",
            "Explanation:\n",
            "\n",
            "The description explicitly mentions that the pencils and pencil sharpener are abnormally large, and there is no indication of porcupines, heads being in the wrong place, all pieces fitting, or regime change. Therefore, the only caption choice that fits is D, which refers to the potential health issue related to the large pencils and sharpener\n",
            "Row 68: Predicted - D, Correct - D, Running Accuracy: 50.00%, Running F1 Score: 0.5076\n",
            "Number of Input Tokens:   443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an office\n",
            "    Description: A man is sitting at a desk. he's interviewing someone for a job.\n",
            "    Uncanny Aspect: The interviewee is a stick figure.\n",
            "    Question: ['What is the job?']\n",
            "    Additional Details: scene: an office description: A man is sitting at a desk. he's interviewing someone for a job. uncanny: The interviewee is a stick figure. entities: Stick_figure, Job_interview. choices A: Get naked, jump in, and make this marriage work! B: Besides being a stick, what is your greatest weakness? C: Let me remind you of your last review : \"The service is lousy and the food is rubbish\" D: When I said I wanted some concessions, this is not what I had in mind. E: If they were seeking peace, they would have sent olive branches.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Get naked, jump in, and make this marriage work!\n",
            "B: Besides being a stick, what is your greatest weakness?\n",
            "C: Let me remind you of your last review : \"The service is lousy and the food is rubbish\"\n",
            "D: When I said I wanted some concessions, this is not what I had in mind.\n",
            "E: If they were seeking peace, they would have sent olive branches.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description, the uncanny aspect of the interviewee being a stick figure, and the given caption choices, the best match would be:\n",
            "\n",
            "B: Besides being a stick, what is your greatest weakness?\n",
            "\n",
            "This captions' context suits the scene description of a job interview, and the question asked 'What is the job?' suggests a typical employment interview scenario. The choice of captions provided does not appear to relate to marriage, review,\n",
            "Row 69: Predicted - B, Correct - B, Running Accuracy: 50.72%, Running F1 Score: 0.5147\n",
            "Number of Input Tokens:   445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: top of building\n",
            "    Description: A man is crawling across a sandbox. Two kids look on, wanting to play.\n",
            "    Uncanny Aspect: The man is acting like he's crawling weakly through a desert.\n",
            "    Question: ['Is the man mentally ill?']\n",
            "    Additional Details: scene: top of building description: A man is crawling across a sandbox. Two kids look on, wanting to play. uncanny: The man is acting like he's crawling weakly through a desert. entities: Sandbox, Play_(activity). choices A: Cancel the molten lava cake. B: Do you want to go for L-U-N-C-H and maybe a W-A-L-K? C: No, you’ll still be conflicted but you’ll smell better. D: Now you'll probably want a chair. E: Should we tell him we found his car keys 2 hours ago?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Cancel the molten lava cake.\n",
            "B: Do you want to go for L-U-N-C-H and maybe a W-A-L-K?\n",
            "C: No, you’ll still be conflicted but you’ll smell better.\n",
            "D: Now you'll probably want a chair.\n",
            "E: Should we tell him we found his car keys 2 hours ago?\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description and the question, it does not seem that there is enough context to determine if the man is mentally ill. Therefore, none of the provided captions are directly related to the cartoon and thus none of them are the correct answer. The correct answer would be: No caption fits.</s>\n",
            "Row 70: Predicted - B, Correct - E, Running Accuracy: 50.00%, Running F1 Score: 0.5090\n",
            "Number of Input Tokens:   419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the living room\n",
            "    Description: A wrecking ball goes through a house. Everyone inside is not disturbed by it.\n",
            "    Uncanny Aspect: If a wrecking ball went through a house, people would be in shocked but they are not.\n",
            "    Question: ['Why did the wrecking ball go through the house?']\n",
            "    Additional Details: scene: the living room description: A wrecking ball goes through a house. Everyone inside is not disturbed by it. uncanny: If a wrecking ball went through a house, people would be in shocked but they are not. entities: Wrecking_ball, Construction. choices A: Yes, I understand. Many of my patients have difficulty talking about sex. B: The consensus of your wise men is: move the chair. C: You knew your wife might remarry. D: Hold on, I heard a knock. E: The operation went well—you're one tough cookie.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Yes, I understand. Many of my patients have difficulty talking about sex.\n",
            "B: The consensus of your wise men is: move the chair.\n",
            "C: You knew your wife might remarry.\n",
            "D: Hold on, I heard a knock.\n",
            "E: The operation went well—you're one tough cookie.\n",
            "\n",
            "Caption = [/INST] Based on the information provided, none of the given captions are a perfect match for the cartoon description. However, if we consider the uncanny aspect of the scene, which is that the people inside the house are not disturbed by the wrecking ball going through it, it seems that none of the given captions address this aspect directly.\n",
            "\n",
            "Therefore, it's likely that none of the provided captions are the correct answer. A caption that might fit the scene better\n",
            "Row 71: Predicted - B, Correct - D, Running Accuracy: 49.30%, Running F1 Score: 0.5025\n",
            "Number of Input Tokens:   400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: heaven\n",
            "    Description: Some angels are sitting on a cloud. There is a politician angel campaigning on a pulpit.\n",
            "    Uncanny Aspect: There is a pulpit in heaven.\n",
            "    Question: ['What is the politician saying?']\n",
            "    Additional Details: scene: heaven description: Some angels are sitting on a cloud. There is a politician angel campaigning on a pulpit. uncanny: There is a pulpit in heaven. entities: Sermon, Politics, Angel. choices A: I hear he forged his death certificate. B: Don't worry, he's covered by Aflac. C: Can't wait to see the look on his face when we put these back on the tree. D: It’s the new Mustang. E: My pets found out they were adopted.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I hear he forged his death certificate.\n",
            "B: Don't worry, he's covered by Aflac.\n",
            "C: Can't wait to see the look on his face when we put these back on the tree.\n",
            "D: It’s the new Mustang.\n",
            "E: My pets found out they were adopted.\n",
            "\n",
            "Caption = [/INST] A: I hear he forged his death certificate.\n",
            "\n",
            "Explanation:\n",
            "Given the context of the cartoon description, it is unlikely that there would be a pulpit in heaven selling cars or discussing pet adoption (choices D and E). The fact that the angel is campaigning suggests that this is a political scene (choice C is also unlikely in this context). The options A, B, and C all contain statements that could plausibly be made in a political campaign\n",
            "Row 72: Predicted - A, Correct - A, Running Accuracy: 50.00%, Running F1 Score: 0.5093\n",
            "Number of Input Tokens:   406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: street\n",
            "    Description: An angel and a devil have had a collision in their cars. They are observing the damage that was done.\n",
            "    Uncanny Aspect: Angels and devils don't drive cars.\n",
            "    Question: ['Do they have insurance?']\n",
            "    Additional Details: scene: street description: An angel and a devil have had a collision in their cars. They are observing the damage that was done. uncanny: Angels and devils don't drive cars. entities: Devil, Angel, Traffic_collision. choices A: That's a rare medium. Well done. B: They're programmed to be idiots, Higgins. What's your excuse? C: If you can't eat 'em, join 'em. D: Long time no sea. E: Didn’t you see the light?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: That's a rare medium. Well done.\n",
            "B: They're programmed to be idiots, Higgins. What's your excuse?\n",
            "C: If you can't eat 'em, join 'em.\n",
            "D: Long time no sea.\n",
            "E: Didn’t you see the light?\n",
            "\n",
            "Caption = [/INST] E: Didn’t you see the light? (This caption plays on the idea that angels are often portrayed as having a divine or ethereal quality, and the question asks about insurance, which could be a reference to the idea that angels or devils might not have a physical, tangible presence, making the idea of insurance an odd fit. Therefore, the option that references their supposed otherworldliness is the best fit.)</s>\n",
            "Row 73: Predicted - E, Correct - E, Running Accuracy: 50.68%, Running F1 Score: 0.5162\n",
            "Number of Input Tokens:   464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: meeting room\n",
            "    Description: People are gathered at a table in what appears to be a meeting. They each have a giant size cup of tea on the table.\n",
            "    Uncanny Aspect: Cups of tea are not gigantic in size.\n",
            "    Question: ['Why do they have giant cups of tea?']\n",
            "    Additional Details: scene: meeting room description: People are gathered at a table in what appears to be a meeting. They each have a giant size cup of tea on the table. uncanny: Cups of tea are not gigantic in size. entities: Coffee, Board_of_directors. choices A: Oh, great. More office drama. B: I sense there's a lot more below the surface. C: The blind date site stated you are \"Strong, upwardly mobile and persistent\" which sounded good at the time. D: Let me start by welcoming you all to Narcoleptics Anonymous. E: They ignored your first ten. What makes you think you'll do any better with these?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Oh, great. More office drama.\n",
            "B: I sense there's a lot more below the surface.\n",
            "C: The blind date site stated you are \"Strong, upwardly mobile and persistent\" which sounded good at the time.\n",
            "D: Let me start by welcoming you all to Narcoleptics Anonymous.\n",
            "E: They ignored your first ten. What makes you think you'll do any better with these?\n",
            "\n",
            "Caption = [/INST] A: Oh, great. More office drama.\n",
            "\n",
            "Explanation: The description mentions a \"meeting room\" and \"People are gathered at a table in what appears to be a meeting,\" suggesting a business or work setting. The presence of giant-size cups of tea is an unusual and unrealistic detail that could be a sign of workplace drama or tension, making option A the best fit.</s>\n",
            "Row 74: Predicted - A, Correct - D, Running Accuracy: 50.00%, Running F1 Score: 0.5084\n",
            "Number of Input Tokens:   504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a restaurant\n",
            "    Description: There is a man and a woman seated at a restaurant table with soups and drinks in front of them. The man is leaning over towards the woman and tilting his head down to show her a tattoo of a girl on his forehead. The woman looks over at him pleasantly surprised.\n",
            "    Uncanny Aspect: It is unusual for a man to have a tattoo of a girl on his forehead.\n",
            "    Question: ['Who is the girl on his forehead?', 'Why did he tattoo his forehead?']\n",
            "    Additional Details: scene: a restaurant description: There is a man and a woman seated at a restaurant table with soups and drinks in front of them. The man is leaning over towards the woman and tilting his head down to show her a tattoo of a girl on his forehead. The woman looks over at him pleasantly surprised. uncanny: It is unusual for a man to have a tattoo of a girl on his forehead. entities: Forehead, Tattoo. choices A: Well, it's a lovely gesture, but I still think we should start seeing other people. B: Regime change is never easy, dear. C: What happened to your goldfish? D: Our contract has a subordinate Claus. E: You’re in luck! It's cannabis.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Well, it's a lovely gesture, but I still think we should start seeing other people.\n",
            "B: Regime change is never easy, dear.\n",
            "C: What happened to your goldfish?\n",
            "D: Our contract has a subordinate Claus.\n",
            "E: You’re in luck! It's cannabis.\n",
            "\n",
            "Caption = [/INST] A: Well, it's a lovely gesture, but I still think we should start seeing other people.\n",
            "\n",
            "Explanation:\n",
            "The woman's reaction in the cartoon appears to be one of pleasant surprise, implying that this is a new development in their relationship. The man's forehead tattoo of a girl is unusual and the woman seems to be considering this new reveal. The caption option \"A: Well, it's a lovely gesture, but I still think\n",
            "Row 75: Predicted - A, Correct - A, Running Accuracy: 50.67%, Running F1 Score: 0.5147\n",
            "Number of Input Tokens:   469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a cliff\n",
            "    Description: A man is hiking on the side of a cliff. Two hikers watch from above.\n",
            "    Uncanny Aspect: You cannot hike down a steep cliff without plummeting to your death.\n",
            "    Question: ['How is the man able to stay on the cliff and not fall off?']\n",
            "    Additional Details: scene: a cliff description: A man is hiking on the side of a cliff. Two hikers watch from above. uncanny: You cannot hike down a steep cliff without plummeting to your death. entities: Rock_climbing, Walking_stick. choices A: Oddly, this one got the placebo. B: Do you have any experience working in a fast-paced environment? C: I don't think he realizes the gravity of the situation. D: You think this is awkward? Try living a few floors down. E: Just five more seconds and you'll break the record set by Tex and Dolly Rosenberg in Accounting.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Oddly, this one got the placebo.\n",
            "B: Do you have any experience working in a fast-paced environment?\n",
            "C: I don't think he realizes the gravity of the situation.\n",
            "D: You think this is awkward? Try living a few floors down.\n",
            "E: Just five more seconds and you'll break the record set by Tex and Dolly Rosenberg in Accounting.\n",
            "\n",
            "Caption = [/INST] C: I don't think he realizes the gravity of the situation.</s>\n",
            "Row 76: Predicted - C, Correct - C, Running Accuracy: 51.32%, Running F1 Score: 0.5209\n",
            "Number of Input Tokens:   388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a performance room\n",
            "    Description: Two men are entering a room. There are a lot of pianos in the room.\n",
            "    Uncanny Aspect: One room doesn't need more than one piano.\n",
            "    Question: ['Why are so many pianos present?']\n",
            "    Additional Details: scene: a performance room description: Two men are entering a room. There are a lot of pianos in the room. uncanny: One room doesn't need more than one piano. entities: Piano, Painting. choices A: Welcome to Mechanics Anonymous. B: I'm pregnant. C: Let's just say he'll have what you're having. D: I'll leave the room while you get unlocked. E: Well, where did you think baby grands came from?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Welcome to Mechanics Anonymous.\n",
            "B: I'm pregnant.\n",
            "C: Let's just say he'll have what you're having.\n",
            "D: I'll leave the room while you get unlocked.\n",
            "E: Well, where did you think baby grands came from?\n",
            "\n",
            "Caption = [/INST] E: Well, where did you think baby grands came from?</s>\n",
            "Row 77: Predicted - E, Correct - E, Running Accuracy: 51.95%, Running F1 Score: 0.5273\n",
            "Number of Input Tokens:   566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: bedroom\n",
            "    Description: There is a married couple tucked into bed in their bedroom. The woman on the right has her glasses on and is reading a book. The husband on the left is sunk down into the covers with a disgusted look on his face. It is also raining inside the bedroom but only on the man's side of the bed.\n",
            "    Uncanny Aspect: It is unusual that it is raining inside of a bedroom. It's also unusual that it's only raining on the man's side of the bed.\n",
            "    Question: ['Why is it raining in the bedroom?', 'Why is it only raining on one side of the bed.']\n",
            "    Additional Details: scene: bedroom description: There is a married couple tucked into bed in their bedroom. The woman on the right has her glasses on and is reading a book. The husband on the left is sunk down into the covers with a disgusted look on his face. It is also raining inside the bedroom but only on the man's side of the bed. uncanny: It is unusual that it is raining inside of a bedroom. It's also unusual that it's only raining on the man's side of the bed. entities: Rain, Intimate_relationship. choices A: You're voting with your pacemaker again, Hargrove! B: Ten bucks says you can't hit him twice. C: There's really nothing to it. D: An optimist would see the room as half dry. E: You need an agent, not a counsellor.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You're voting with your pacemaker again, Hargrove!\n",
            "B: Ten bucks says you can't hit him twice.\n",
            "C: There's really nothing to it.\n",
            "D: An optimist would see the room as half dry.\n",
            "E: You need an agent, not a counsellor.\n",
            "\n",
            "Caption = [/INST] C. There's really nothing to it.\n",
            "\n",
            "The cartoon description does not provide enough information to suggest that the rain is caused by a pacemaker (A), a fight or attempt at hitting (B), or that the man is an actor in need of an agent (E). It is also unlikely that the woman would make a comment about the room being half dry (D) given her appearance of being engrossed in her book. Therefore, the most neutral and likely option\n",
            "Row 78: Predicted - C, Correct - D, Running Accuracy: 51.28%, Running F1 Score: 0.5189\n",
            "Number of Input Tokens:   502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the bedroom\n",
            "    Description: There is a man sitting on the edge of his bed with a landline phone in hand which is fried both the headset, cord and body. The phone has burned a hole in the wall and is still smoking. The man is looking back at his wife and is talking.\n",
            "    Uncanny Aspect: It is unusual for a phone to burn up and create a hole in the wall.\n",
            "    Question: ['Why did the phone get fried?', 'What is the man saying to his wife?']\n",
            "    Additional Details: scene: the bedroom description: There is a man sitting on the edge of his bed with a landline phone in hand which is fried both the headset, cord and body. The phone has burned a hole in the wall and is still smoking. The man is looking back at his wife and is talking. uncanny: It is unusual for a phone to burn up and create a hole in the wall. entities: Explosion, Telephone_call. choices A: Please use a coaster. B: Please, Mr. Blaine. I do have other patients to attend to. C: Terrormarketer. D: Brittany, I understand you've written Kyle's vows, which he'll now read. E: I have the same exact dog.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Please use a coaster.\n",
            "B: Please, Mr. Blaine. I do have other patients to attend to.\n",
            "C: Terrormarketer.\n",
            "D: Brittany, I understand you've written Kyle's vows, which he'll now read.\n",
            "E: I have the same exact dog.\n",
            "\n",
            "Caption = [/INST] A: It is unlikely that the given situation results in the exchange of the dialogues in any of the options provided, A-E. Therefore, it is important to focus on the actions and scene description to determine the most fitting caption. In the provided cartoon description, the man is shown with a fried landline phone that has caused a hole in the wall, and he is not engaging in a conversation with anyone mentioned in the choices. The situation seems to be an unusual occurrence\n",
            "Row 79: Predicted - A, Correct - C, Running Accuracy: 50.63%, Running F1 Score: 0.5133\n",
            "Number of Input Tokens:   422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a living room\n",
            "    Description: Cats are piled up in a tower formation. A man is on the phone staring at them.\n",
            "    Uncanny Aspect: Cats cannot do tricks like this. They are not smart enough.\n",
            "    Question: ['Why are the cats piled up like this?']\n",
            "    Additional Details: scene: a living room description: Cats are piled up in a tower formation. A man is on the phone staring at them. uncanny: Cats cannot do tricks like this. They are not smart enough. entities: Pet, Totem_pole. choices A: Seriously, you wouldn't believe my seats. B: At home we're not allowed on the furniture. C: If we just ignore it, maybe it'll go away. D: Most people are reassured after three or four. E: Hello, YouTube? I've got something you might be interested in.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Seriously, you wouldn't believe my seats.\n",
            "B: At home we're not allowed on the furniture.\n",
            "C: If we just ignore it, maybe it'll go away.\n",
            "D: Most people are reassured after three or four.\n",
            "E: Hello, YouTube? I've got something you might be interested in.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description, the cats piled up in a tower formation is an unusual and unlikely situation, which aligns with the uncanny aspect that cats cannot do such tricks due to their lack of intelligence. Therefore, the caption that acknowledges the unusual situation or even exploits it would be the most fitting.\n",
            "\n",
            "Option E: \"Hello, YouTube? I've got something you might be interested in\"\n",
            "\n",
            "This caption fits because it acknowledges the unusual scene\n",
            "Row 80: Predicted - B, Correct - E, Running Accuracy: 50.00%, Running F1 Score: 0.5087\n",
            "Number of Input Tokens:   424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: outside\n",
            "    Description: Two people are sitting in chairs outside. The woman is being taken away by giant insects.\n",
            "    Uncanny Aspect: The insects are giant.\n",
            "    Question: ['Why do the insects want to take her?']\n",
            "    Additional Details: scene: outside description: Two people are sitting in chairs outside. The woman is being taken away by giant insects. uncanny: The insects are giant. entities: Mosquito, Kidnapping. choices A: I asked you to go get two MOJITOS!!! B: Do you want it in dog years? C: Let Table Seven know that there will be a slight delay on the risotto. D: It's a textbook case--depending on which state your textbooks are from. E: I told you not to water it. Now it's going to follow us home.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I asked you to go get two MOJITOS!!!\n",
            "B: Do you want it in dog years?\n",
            "C: Let Table Seven know that there will be a slight delay on the risotto.\n",
            "D: It's a textbook case--depending on which state your textbooks are from.\n",
            "E: I told you not to water it. Now it's going to follow us home.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and details provided, the most unlikely caption that matches the scene is:\n",
            "\n",
            "C: Let Table Seven know that there will be a slight delay on the risotto.\n",
            "\n",
            "The other options, such as A, B, D, and E, do not fit the scene as they all refer to human situations unrelated to giant insects taking away a woman.\n",
            "\n",
            "Therefore, the answer is:\n",
            "A, B, C, D, E\n",
            "Row 81: Predicted - B, Correct - A, Running Accuracy: 49.38%, Running F1 Score: 0.5041\n",
            "Number of Input Tokens:   480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a courtroom\n",
            "    Description: A man wearing swimming trunks, a snorkel, and some flippers is in a courtroom. He is being dragged there by soldiers. A judge looks at him.\n",
            "    Uncanny Aspect: There is a man wearing a snorkel and swim trunks in a courtroom.\n",
            "    Question: ['Why is the man wearing swim trunks and a snorkel in the courtroom?']\n",
            "    Additional Details: scene: a courtroom description: A man wearing swimming trunks, a snorkel, and some flippers is in a courtroom. He is being dragged there by soldiers. A judge looks at him. uncanny: There is a man wearing a snorkel and swim trunks in a courtroom. entities: Snorkeling, Security_guard. choices A: It's easy once you realize there's nothing to it. B: It's a park. He's on a leash. What's it to you? C: You think Alcatraz can hold me? D: It's for you honey E: I know I was having trouble finding it, but this is a little extreme.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It's easy once you realize there's nothing to it.\n",
            "B: It's a park. He's on a leash. What's it to you?\n",
            "C: You think Alcatraz can hold me?\n",
            "D: It's for you honey\n",
            "E: I know I was having trouble finding it, but this is a little extreme.\n",
            "\n",
            "Caption = [/INST] C: You think Alcatraz can hold me?</s>\n",
            "Row 82: Predicted - C, Correct - C, Running Accuracy: 50.00%, Running F1 Score: 0.5100\n",
            "Number of Input Tokens:   389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the ground\n",
            "    Description: A man in climbing gear is climbing nothing but air as another man watches on. There is nothing in the back ground or on the ground.\n",
            "    Uncanny Aspect: It is impossible to climb onto nothing.\n",
            "    Question: ['How is the man climbing nothing?']\n",
            "    Additional Details: scene: the ground description: A man in climbing gear is climbing nothing but air as another man watches on. There is nothing in the back ground or on the ground. uncanny: It is impossible to climb onto nothing. entities: Mountaineering, Invisibility. choices A: Both the movie and I will be released this summer. B: Look, damsels say all sorts of things in distress. C: There goes my novel. D: There's really nothing to it. E: We’re tabling the motion.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Both the movie and I will be released this summer.\n",
            "B: Look, damsels say all sorts of things in distress.\n",
            "C: There goes my novel.\n",
            "D: There's really nothing to it.\n",
            "E: We’re tabling the motion.\n",
            "\n",
            "Caption = [/INST] C. \"There's really nothing to it.\"\n",
            "\n",
            "Explanation:\n",
            "\n",
            "The cartoon depicts a man in climbing gear climbing nothing, which is an uncanny situation as there is nothing for him to climb on. The additional details do not provide any context related to movies, novels, or motions being tabled. The caption option \"There's really nothing to it\" makes the most sense as it is a likely response to the absurdity of the situation shown\n",
            "Row 83: Predicted - C, Correct - D, Running Accuracy: 49.40%, Running F1 Score: 0.5022\n",
            "Number of Input Tokens:   561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the ocean\n",
            "    Description: There is a waterski ramp in a lake where two skiers have jumped and are now in mid air. The woman on the left is a traditional waterskier holding a tow rope while the woman on the right is wearing winter wear and is on snow skis. The snow skier is talking to the waterskier.\n",
            "    Uncanny Aspect: It is unusual to see a snow skier jumping a waterski ramp on a lake.\n",
            "    Question: ['How is a snow skier able to ski and jump a ramp on a lake?', 'What is the snow skier saying to the waterskier?']\n",
            "    Additional Details: scene: the ocean description: There is a waterski ramp in a lake where two skiers have jumped and are now in mid air. The woman on the left is a traditional waterskier holding a tow rope while the woman on the right is wearing winter wear and is on snow skis. The snow skier is talking to the waterskier. uncanny: It is unusual to see a snow skier jumping a waterski ramp on a lake. entities: Skiing, Water_skiing. choices A: Our conflict-resolution seminar ended a bit early today. B: Well lets just say Long live the King may be a bit on the optimistic side C: Oh, shit! What if your sister-in-law is also right about God? D: From the ashes, your bill will magically appear. E: I love her. And she can dunk.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Our conflict-resolution seminar ended a bit early today.\n",
            "B: Well lets just say Long live the King may be a bit on the optimistic side\n",
            "C: Oh, shit! What if your sister-in-law is also right about God?\n",
            "D: From the ashes, your bill will magically appear.\n",
            "E: I love her. And she can dunk.\n",
            "\n",
            "Caption = [/INST] C. \"Oh, shit! What if your sister-in-law is also right about God?\"\n",
            "\n",
            "Although none of the given captions directly relate to the cartoon's content, option C is the one that comes closest to expressing surprise or uncertainty, which might be a response from the snow skier when encountering the unusual scene of a snow skier jumping a waterski ramp on a lake.</s>\n",
            "Row 84: Predicted - C, Correct - C, Running Accuracy: 50.00%, Running F1 Score: 0.5078\n",
            "Number of Input Tokens:   549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an empty room\n",
            "    Description: There is a man in a t-shirt and jeans who is holding hands with his son on the left and a dog wearing human clothes on the right. The dog is standing straight up and looking at the little boy who looks angry. The man is talking to the little boy.\n",
            "    Uncanny Aspect: It is unusual that a man is holding hands with a dog who is wearing clothes and walking upright.\n",
            "    Question: ['Why is the dog walking and wearing clothes like a person?', 'What is the man saying to the little boy?']\n",
            "    Additional Details: scene: an empty room description: There is a man in a t-shirt and jeans who is holding hands with his son on the left and a dog wearing human clothes on the right. The dog is standing straight up and looking at the little boy who looks angry. The man is talking to the little boy. uncanny: It is unusual that a man is holding hands with a dog who is wearing clothes and walking upright. entities: Dog, Son, Dog_fashion. choices A: Looks like Sammy wins the \"bring your pet to work\" contest. He ate all of the other entries! B: Of course we wanted a son. But we also wanted unconditional love. C: I hear he forged his death certificate. D: Some guys never make it out of the plastic bag. E: Don't look at me that way—I wanted a giant cat.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Looks like Sammy wins the \"bring your pet to work\" contest. He ate all of the other entries!\n",
            "B: Of course we wanted a son. But we also wanted unconditional love.\n",
            "C: I hear he forged his death certificate.\n",
            "D: Some guys never make it out of the plastic bag.\n",
            "E: Don't look at me that way—I wanted a giant cat.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and the uncanny aspect, none of the provided captions seem to fit perfectly. However, the caption C: \"I hear he forged his death certificate\" is the most intriguing one, as it introduces the possibility that the dog may be a reanimated or otherwise unusual creature. However, given the information provided, there's no clear indication that the dog is deceased or has forged any documents, so this caption is likely\n",
            "Row 85: Predicted - B, Correct - B, Running Accuracy: 50.59%, Running F1 Score: 0.5128\n",
            "Number of Input Tokens:   435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a ship\n",
            "    Description: There are two pirates standing together on a ship. The pirate on the left has a rabbit sitting on his shoulder.\n",
            "    Uncanny Aspect: The pirate has a rabbit on his shoulder when traditionally it was a parrot that pirates are known for having.\n",
            "    Question: ['Why does he have a rabbit rather than a parrot?', 'What are the pirates talking about?']\n",
            "    Additional Details: scene: a ship description: There are two pirates standing together on a ship. The pirate on the left has a rabbit sitting on his shoulder. uncanny: The pirate has a rabbit on his shoulder when traditionally it was a parrot that pirates are known for having. entities: Pirate, Rabbit. choices A: Honestly? He's like, ten rings too old for her. B: He's a temp. C: He said you ate his homework. D: I'll order. You pick up. E: No, I will not push you again.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Honestly? He's like, ten rings too old for her.\n",
            "B: He's a temp.\n",
            "C: He said you ate his homework.\n",
            "D: I'll order. You pick up.\n",
            "E: No, I will not push you again.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description provided, none of the given caption choices (A, B, C, D, E) are an appropriate match. The question asks for the reason why one pirate has a rabbit instead of a parrot or what the pirates are talking about. However, none of the given captions provide an answer to those questions. Therefore, none of the given captions are the best match for the cartoon.\n",
            "\n",
            "I would not output any letter after\n",
            "Row 86: Predicted - B, Correct - B, Running Accuracy: 51.16%, Running F1 Score: 0.5178\n",
            "Number of Input Tokens:   447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a bar\n",
            "    Description: A clown stares at a shop owner from outside the shop. There is a name on the store called ''Sam's''.\n",
            "    Uncanny Aspect: It is weird for the clown to stare at someone from outside a store.\n",
            "    Question: ['Why is the clown staring at the man?']\n",
            "    Additional Details: scene: a bar description: A clown stares at a shop owner from outside the shop. There is a name on the store called \"Sam's\". uncanny: It is weird for the clown to stare at someone from outside a store. entities: Clown, Soda_fountain. choices A: You were with Ringling Brothers? I was with Lehman Brothers. B: Let's face it. One side of the bed consistently outperforms the other. C: It needs a feisty female detective. D: He's his own best friend. E: I changed my mind. It would look better on the other side.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You were with Ringling Brothers? I was with Lehman Brothers.\n",
            "B: Let's face it. One side of the bed consistently outperforms the other.\n",
            "C: It needs a feisty female detective.\n",
            "D: He's his own best friend.\n",
            "E: I changed my mind. It would look better on the other side.\n",
            "\n",
            "Caption = [/INST] E: I changed my mind. It would look better on the other side.\n",
            "\n",
            "Explanation: Although the cartoon description does not provide any explicit evidence regarding the reason for the clown's stare, the clue that the clown is staring at the shop from outside and the uncanny factor of the situation imply that the clown might be comparing or considering something. Option E, \"It would look better on the other side,\" can be interpreted as the clown evaluating the\n",
            "Row 87: Predicted - E, Correct - A, Running Accuracy: 50.57%, Running F1 Score: 0.5112\n",
            "Number of Input Tokens:   480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: living room\n",
            "    Description: Three adults are sitting around a coffee table in a living room eating and drinking. The house has very large appliances like a  lamp, a toaster, etc.\n",
            "    Uncanny Aspect: The size of the appliances is too large to be real.\n",
            "    Question: ['Why are the appliances in this house owned by the couple so large?']\n",
            "    Additional Details: scene: living room description: Three adults are sitting around a coffee table in a living room eating and drinking. The house has very large appliances like a lamp, a toaster, etc. uncanny: The size of the appliances is too large to be real. entities: Therapy, Conversation. choices A: Carry on. I'll just be a fly on the wall. B: They didn't say who...they just said one of us won't be here in the spring... C: Are you better off now than you were four innings ago? D: It's down the hall, but don't fall in. E: Relax, honey—everybody gets buyer's remorse\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Carry on. I'll just be a fly on the wall.\n",
            "B: They didn't say who...they just said one of us won't be here in the spring...\n",
            "C: Are you better off now than you were four innings ago?\n",
            "D: It's down the hall, but don't fall in.\n",
            "E: Relax, honey—everybody gets buyer's remorse\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and the given caption choices, none of them directly match the situation described in the cartoon. The cartoon describes a scene in a living room where three adults are sitting around a coffee table and the appliances are unusually large. None of the given captions mention anything about large appliances or the conversation in the scene being related to purchasese or remorse.\n",
            "\n",
            "Therefore, none of the captions (A, B, C, D\n",
            "Row 88: Predicted - B, Correct - D, Running Accuracy: 50.00%, Running F1 Score: 0.5053\n",
            "Number of Input Tokens:   404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a bar\n",
            "    Description: A man is sitting at a bar, chatting up a woman. They both have drinks.\n",
            "    Uncanny Aspect: The man is wearing women's shoes.\n",
            "    Question: ['Why is he wearing those heels?']\n",
            "    Additional Details: scene: a bar description: A man is sitting at a bar, chatting up a woman. They both have drinks. uncanny: The man is wearing women's shoes. entities: High-heeled_shoe, Courtship. choices A: If size didn't matter we'd all be swimming. B: Like it would have killed you to ask him for directions. C: Actually, I'm not crazy about long walks on the beach. D: Got anything besides Tang? E: Not now—I'm in the middle of a big case.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: If size didn't matter we'd all be swimming.\n",
            "B: Like it would have killed you to ask him for directions.\n",
            "C: Actually, I'm not crazy about long walks on the beach.\n",
            "D: Got anything besides Tang?\n",
            "E: Not now—I'm in the middle of a big case.\n",
            "\n",
            "Caption = [/INST] A. \"If size didn't matter we'd all be swimming\"\n",
            "\n",
            "Explanation:\n",
            "Given the cartoon description, there are no clear clues that indicate the man's reason for wearing women's shoes is related to any of the options provided in the caption choices. However, option A is a humorous comment on physical attributes that could apply to the man's unconventional footwear, regardless of the reason behind it. Since none of\n",
            "Row 89: Predicted - A, Correct - C, Running Accuracy: 49.44%, Running F1 Score: 0.5006\n",
            "Number of Input Tokens:   473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a convention center\n",
            "    Description: Several naked people are seated on a stage next to a person on a podium, all in front of an audience.  A \"Welcome Stockholders\" banner hangs above the stage\n",
            "    Uncanny Aspect: It's unusual to see a bunch of naked people on a stage at a stockholders meeting\n",
            "    Question: [\"Why aren't those people wearing clothes?\"]\n",
            "    Additional Details: scene: a convention center description: Several naked people are seated on a stage next to a person on a podium, all in front of an audience. A \"Welcome Stockholders\" banner hangs above the stage uncanny: It's unusual to see a bunch of naked people on a stage at a stockholders meeting entities: Annual_general_meeting, Nudity. choices A: Every time I go to Williamsburg, I just feel more and more out of place. B: Forget Oregon. I'm going to Vegas. C: First, I'd like to thank the podium. D: So you're the bug that's been going around. E: He calls it Ishmeow.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Every time I go to Williamsburg, I just feel more and more out of place.\n",
            "B: Forget Oregon. I'm going to Vegas.\n",
            "C: First, I'd like to thank the podium.\n",
            "D: So you're the bug that's been going around.\n",
            "E: He calls it Ishmeow.\n",
            "\n",
            "Caption = [/INST] A: This choice does not directly reference the unusual element in the cartoon, but it does mention feeling out of place, which could be a possible reaction to the sight of naked people at a stockholders meeting. However, it is a stretch and less likely than other options.\n",
            "\n",
            "B: This choice does not fit the cartoon at all, as there is no mention of Oregon or Vegas in the description.\n",
            "\n",
            "C: This choice directly references the podium in the cartoon but\n",
            "Row 90: Predicted - A, Correct - C, Running Accuracy: 48.89%, Running F1 Score: 0.4959\n",
            "Number of Input Tokens:   414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the outside of an apartment building\n",
            "    Description: There is a huge monster outside the man's apartment. The man is drinking and on the phone with someone.\n",
            "    Uncanny Aspect: There is a huge monster on the side of the building.\n",
            "    Question: ['Why is there a monster on the side of the building?']\n",
            "    Additional Details: scene: the outside of an apartment building description: There is a huge monster outside the man's apartment. The man is drinking and on the phone with someone. uncanny: There is a huge monster on the side of the building. entities: Monster, Wine. choices A: A strike sends us home early. B: Better make that a large pizza. C: What we have here is a reptile dysfuntion. D: Stay with me, sir. It's almost recess. E: You figured eating the black one wouldn't be noticed ??\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: A strike sends us home early.\n",
            "B: Better make that a large pizza.\n",
            "C: What we have here is a reptile dysfuntion.\n",
            "D: Stay with me, sir. It's almost recess.\n",
            "E: You figured eating the black one wouldn't be noticed ??\n",
            "\n",
            "Caption = [/INST] C. What we have here is a reptile dysfunction.\n",
            "\n",
            "The cartoon description suggests that there is a monster outside the apartment, and the caption option C acknowledges the presence of the monster while introducing a humorous element related to the monster being a reptile. The other options do not fit the description or the tone of the cartoon.</s>\n",
            "Row 91: Predicted - C, Correct - B, Running Accuracy: 48.35%, Running F1 Score: 0.4894\n",
            "Number of Input Tokens:   402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an operating room\n",
            "    Description: A bunch of surgeons are in an OR. They're getting ready for surgery when a man walks in carrying a golf bag.\n",
            "    Uncanny Aspect: A golfer doesn't belong in an OR.\n",
            "    Question: ['Why is the golfer there?']\n",
            "    Additional Details: scene: an operating room description: A bunch of surgeons are in an OR. They're getting ready for surgery when a man walks in carrying a golf bag. uncanny: A golfer doesn't belong in an OR. entities: Surgery, Caddie. choices A: Getting laid is harder than it looks. B: What's happening on your side? C: It autocorrected to \"hula\". D: Honey, be nice... he's under a lot more pressure. E: How’s my wife doing?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Getting laid is harder than it looks.\n",
            "B: What's happening on your side?\n",
            "C: It autocorrected to \"hula\".\n",
            "D: Honey, be nice... he's under a lot more pressure.\n",
            "E: How’s my wife doing?\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description and the uncanny aspect of a golfer not belonging in an operating room, it's unlikely that any of the given caption choices would fit perfectly.\n",
            "\n",
            "However, of the given choices, option E: \"How’s my wife doing?\" comes the closest to making some sense, as it could be a possibility for why the golfer might be in the OR. This is because the golfer could potentially be a caddie\n",
            "Row 92: Predicted - B, Correct - E, Running Accuracy: 47.83%, Running F1 Score: 0.4853\n",
            "Number of Input Tokens:   484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a bedroom\n",
            "    Description: A man and woman are in the bedroom with the woman on the bed and the man on the ceiling. The woman is looking at the man on the ceiling, who is in a resting position as if he were in the bed with her.\n",
            "    Uncanny Aspect: A man cannot defy the laws of gravity and sleep up on the ceiling without falling down.\n",
            "    Question: ['Why is the man up there on the ceiling?']\n",
            "    Additional Details: scene: a bedroom description: A man and woman are in the bedroom with the woman on the bed and the man on the ceiling. The woman is looking at the man on the ceiling, who is in a resting position as if he were in the bed with her. uncanny: A man cannot defy the laws of gravity and sleep up on the ceiling without falling down. entities: Marriage, Buoyancy, Roof. choices A: No, actually I fell off the wagon. B: We're out of that too. C: I support our troops as much as the next guy, but do we have to let them play through? D: You need to cut your toenails. E: I'm a big person. It only looks smaller.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: No, actually I fell off the wagon.\n",
            "B: We're out of that too.\n",
            "C: I support our troops as much as the next guy, but do we have to let them play through?\n",
            "D: You need to cut your toenails.\n",
            "E: I'm a big person. It only looks smaller.\n",
            "\n",
            "Caption = [/INST] A: No, actually I fell off the wagon (This caption does not directly address the unusual situation in the cartoon but could be an explanation for why the man is on the ceiling in a more fantastical or metaphorical sense, making it a plausible answer based on the information provided)\n",
            "\n",
            "B, C, D, and E do not fit the situation described in the cartoon and can be eliminated.\n",
            "\n",
            "Caption choices B, C, and E are\n",
            "Row 93: Predicted - A, Correct - D, Running Accuracy: 47.31%, Running F1 Score: 0.4793\n",
            "Number of Input Tokens:   449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a field\n",
            "    Description: A boy is standing next to a tree with a cherry on his head. A man is standing away from him with a bow.\n",
            "    Uncanny Aspect: The cherry is the only thing in color.\n",
            "    Question: ['Why is the cherry colored in?']\n",
            "    Additional Details: scene: a field description: A boy is standing next to a tree with a cherry on his head. A man is standing away from him with a bow. uncanny: The cherry is the only thing in color. entities: Archery, Target_practice. choices A: Act of God. We're not liable. B: I now see why you only get me every other weekend. C: I suspect some people will deny this ever happened. D: ‘How many accountants does it take to sharpen a pencil?’ you ask? In this case five. E: You can tell the judge why you were doing CX in a XXV.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Act of God. We're not liable.\n",
            "B: I now see why you only get me every other weekend.\n",
            "C: I suspect some people will deny this ever happened.\n",
            "D: ‘How many accountants does it take to sharpen a pencil?’ you ask? In this case five.\n",
            "E: You can tell the judge why you were doing CX in a XXV.\n",
            "\n",
            "Caption = [/INST] C: I suspect some people will deny this ever happened.\n",
            "\n",
            "Explanation: The unusual and uncanny aspect of the cartoon, making the cherry the only thing in color, suggests that the event depicted may be difficult to believe or that it is an unusual occurrence. The caption option C fits this description by implying that some people may have a hard time accepting what they're seeing.\n",
            "\n",
            "The other options do not fit the cartoon description and context provided.\n",
            "Row 94: Predicted - C, Correct - B, Running Accuracy: 46.81%, Running F1 Score: 0.4732\n",
            "Number of Input Tokens:   450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a bar\n",
            "    Description: A man in a hazmat suit is having a drink with another guy in the bar. They are having a conversation.\n",
            "    Uncanny Aspect: It would be difficult to drink with a hazmat suit on so it is unusual for someone to wear one.\n",
            "    Question: ['Why is the man wearing a hazmat suit?']\n",
            "    Additional Details: scene: a bar description: A man in a hazmat suit is having a drink with another guy in the bar. They are having a conversation. uncanny: It would be difficult to drink with a hazmat suit on so it is unusual for someone to wear one. entities: Hazmat_suit, Businessperson. choices A: I hate connecting through Roswell. B: I just don't care that much about Medicare anymore. C: It took us years to get somebody in the inside. D: The way I see it, I'm the miner, and you're the canary. E: Seriously, all you need is a letter from your doctor.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I hate connecting through Roswell.\n",
            "B: I just don't care that much about Medicare anymore.\n",
            "C: It took us years to get somebody in the inside.\n",
            "D: The way I see it, I'm the miner, and you're the canary.\n",
            "E: Seriously, all you need is a letter from your doctor.\n",
            "\n",
            "Caption = [/INST] A: I hate connecting through Roswell. (This caption mentions a hazmat suit without providing an explanation, but the scene's uncanny aspect suggests that the man in the hazmat suit is likely from out of town or from another world, making option A a possible fit.)</s>\n",
            "Row 95: Predicted - A, Correct - D, Running Accuracy: 46.32%, Running F1 Score: 0.4674\n",
            "Number of Input Tokens:   449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: room\n",
            "    Description: A man is climbing a mountain in midair. A man below is staring at him. There is no mountain.\n",
            "    Uncanny Aspect: The man is scaling an invisible mountain.\n",
            "    Question: [\"Why is the man scaling a mountain that isn't there?\"]\n",
            "    Additional Details: scene: room description: A man is climbing a mountain in midair. A man below is staring at him. There is no mountain. uncanny: The man is scaling an invisible mountain. entities: Climbing_wall, Mountaineering. choices A: Wow, you student loan people really know how to track someone down. B: We probably should have done something about this last year when it was still three blocks away. C: It's easy once you realize there's nothing to it. D: Just once I'd like to hallucinate a guy who does air conditioning. E: See? A real pirate would have cannonballed.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Wow, you student loan people really know how to track someone down.\n",
            "B: We probably should have done something about this last year when it was still three blocks away.\n",
            "C: It's easy once you realize there's nothing to it.\n",
            "D: Just once I'd like to hallucinate a guy who does air conditioning.\n",
            "E: See? A real pirate would have cannonballed.\n",
            "\n",
            "Caption = [/INST] C: It's easy once you realize there's nothing to it.</s>\n",
            "Row 96: Predicted - C, Correct - C, Running Accuracy: 46.88%, Running F1 Score: 0.4727\n",
            "Number of Input Tokens:   436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a meeting room\n",
            "    Description: There are five people sitting around the table in a board room. Outside there is a huge monster looking in and showing its teeth. The people are frightened.\n",
            "    Uncanny Aspect: There is a monster outside the office window.\n",
            "    Question: ['Will the monster eat the people?']\n",
            "    Additional Details: scene: a meeting room description: There are five people sitting around the table in a board room. Outside there is a huge monster looking in and showing its teeth. The people are frightened. uncanny: There is a monster outside the office window. entities: Godzilla, White-collar_worker. choices A: I couldn't find a real naked woman to ride with me in the H.O.V. lane. B: I recommend the trout. C: Looks like you boys could use some water. D: Don't worry: we have this room booked until 4:00. E: We buy everything in bulk.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I couldn't find a real naked woman to ride with me in the H.O.V. lane.\n",
            "B: I recommend the trout.\n",
            "C: Looks like you boys could use some water.\n",
            "D: Don't worry: we have this room booked until 4:00.\n",
            "E: We buy everything in bulk.\n",
            "\n",
            "Caption = [/INST] D: Don't worry: we have this room booked until 4:00.\n",
            "\n",
            "Explanation:\n",
            "Given the description of the cartoon, there is a monster outside a board room and the five people inside are frightened, it's clear that the situation is not about ordering food or a boat ride, as options B and C suggest. Option A is also not applicable as there's no mention of a woman or an HOV lane in the cartoon\n",
            "Row 97: Predicted - D, Correct - D, Running Accuracy: 47.42%, Running F1 Score: 0.4803\n",
            "Number of Input Tokens:   425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a farm\n",
            "    Description: A man is climbing the steps to a UFO. A robot or alien is at the top greeting him.\n",
            "    Uncanny Aspect: The human and alien seem to be friends.\n",
            "    Question: ['How did they meet?']\n",
            "    Additional Details: scene: a farm description: A man is climbing the steps to a UFO. A robot or alien is at the top greeting him. uncanny: The human and alien seem to be friends. entities: Alien_abduction, Farmer. choices A: It's the only way Delta lets you redeem their vouchers B: We said we would return when Cleveland won a championship. C: I don't like the way Adam looks at you. D: If I don't wake up soon, I'll have some explaining to do tomorrow. E: You know, everyone laughed at Noah, too.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It's the only way Delta lets you redeem their vouchers\n",
            "B: We said we would return when Cleveland won a championship.\n",
            "C: I don't like the way Adam looks at you.\n",
            "D: If I don't wake up soon, I'll have some explaining to do tomorrow.\n",
            "E: You know, everyone laughed at Noah, too.\n",
            "\n",
            "Caption = [/INST] C. I don't like the way Adam looks at you.\n",
            "\n",
            "Explanation: Based on the information provided, the Cartoon Description indicates that the man and the alien seem to be friends. However, there is no mention of any context that would suggest that Delta vouchers, the Cleveland championship, or explanations to someone about waking up are relevant to the friendship between the man and the alien. Option E, \"You know, everyone laughed at Noah, too,\" is\n",
            "Row 98: Predicted - C, Correct - B, Running Accuracy: 46.94%, Running F1 Score: 0.4745\n",
            "Number of Input Tokens:   432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: living room\n",
            "    Description: A man and a woman are sitting on the sofa. The woman is upset because the living room is full of monkeys climbing around.\n",
            "    Uncanny Aspect: The room is full of monkeys which would cause a mess in the house.\n",
            "    Question: ['Why is the room full of monkeys?']\n",
            "    Additional Details: scene: living room description: A man and a woman are sitting on the sofa. The woman is upset because the living room is full of monkeys climbing around. uncanny: The room is full of monkeys which would cause a mess in the house. entities: Mischief, Monkey. choices A: Shall I keep reading? B: Can we have one argument without you bringing up the monkeys? C: I'm not sure how many there are. Every time I start counting I fall asleep. D: Tap is fine. E: By a 9-0 vote, the restroom expansion project is approved.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Shall I keep reading?\n",
            "B: Can we have one argument without you bringing up the monkeys?\n",
            "C: I'm not sure how many there are. Every time I start counting I fall asleep.\n",
            "D: Tap is fine.\n",
            "E: By a 9-0 vote, the restroom expansion project is approved.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and the given caption choices, the best match is:\n",
            "\n",
            "B: Can we have one argument without you bringing up the monkeys?\n",
            "\n",
            "Explanation:\n",
            "The description mentions that the woman is upset because of the monkeys in the living room, and the question asks why the room is full of monkeys. This indicates that the topic of the monkeys is causing a conflict between the man and the woman. Therefore, option B, \"\n",
            "Row 99: Predicted - B, Correct - B, Running Accuracy: 47.47%, Running F1 Score: 0.4794\n",
            "Number of Input Tokens:   514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a living room\n",
            "    Description: Two people are sitting on a couch in a living room watching tv and reading. A food truck is parked in the room and a vendor is having a conversation with one of the people on the couch.\n",
            "    Uncanny Aspect: It is unusual that the food truck is in the living room instead of outside, and that he appears to be open for business.\n",
            "    Question: ['What made the vendor park his food truck in a house.']\n",
            "    Additional Details: scene: a living room description: Two people are sitting on a couch in a living room watching tv and reading. A food truck is parked in the room and a vendor is having a conversation with one of the people on the couch. uncanny: It is unusual that the food truck is in the living room instead of outside, and that he appears to be open for business. entities: Ice_cream_van, Food_booth. choices A: I just think it sends the wrong message. B: I guess I misunderstood when you said long bike ride. C: When I said I wanted some concessions, this is not what I had in mind. D: Well, it's another thrilling night at the Samsas’. E: Well, it's not my fault booty revenues are down this quarter.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions best matches the cartoon?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I just think it sends the wrong message.\n",
            "B: I guess I misunderstood when you said long bike ride.\n",
            "C: When I said I wanted some concessions, this is not what I had in mind.\n",
            "D: Well, it's another thrilling night at the Samsas’.\n",
            "E: Well, it's not my fault booty revenues are down this quarter.\n",
            "\n",
            "Caption = [/INST] C: When I said I wanted some concessions, this is not what I had in mind.</s>\n",
            "Row 100: Predicted - C, Correct - C, Running Accuracy: 48.00%, Running F1 Score: 0.4843\n",
            "Final Accuracy: 48.0000%\n",
            "Final F1 Score: 0.4843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wiki Context Included"
      ],
      "metadata": {
        "id": "MHPezdSXFWuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wikipedia-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqcT-PlGFTn6",
        "outputId": "20a9852f-6c65-4d9d-9047-65c6c68ee5af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wikipedia-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2024.2.2)\n",
            "Installing collected packages: wikipedia-api\n",
            "Successfully installed wikipedia-api-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipediaapi\n",
        "\n",
        "def wiki_context(link):\n",
        "\n",
        "  #strip the link to the title\n",
        "  wiki_name = (link.split('/')[-1])\n",
        "\n",
        "  #retrieve summary based on title\n",
        "  wiki_wiki = wikipediaapi.Wikipedia('NLPHumorClassification (atm76@cornell.edu)', 'en')\n",
        "\n",
        "  page = wiki_wiki.page(wiki_name)\n",
        "\n",
        "  if page.exists():\n",
        "    print(f\"Page - Title: {page.title}\")\n",
        "    print(f\"Page - Exists: True\")\n",
        "    return f\"{page.summary}\"\n",
        "  else:\n",
        "    print(f\"Page - Title: {page_title}\")\n",
        "    print(\"Page - Exists: False\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "JM772y5oFlz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_caption_wiki(dataframe_row):\n",
        "\n",
        "    # example prompt from Mistral Model Card = \"<s>[INST] What is your favourite condiment? [/INST]\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "    <s>[INST]\n",
        "\n",
        "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
        "    You will be provided with a description of a New Yorker cartoon and relevant Wikipedia summaries.\n",
        "    You must use the cartoon description information and Wikipedia summaries to decide which of the caption options best fits the cartoon.\n",
        "\n",
        "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
        "\n",
        "    Cartoon Description:\n",
        "    Location: {dataframe_row['image_location']}\n",
        "    Description: {dataframe_row['image_description']}\n",
        "    Uncanny Aspect: {dataframe_row['image_uncanny_description']}\n",
        "    Question: {dataframe_row['questions']}\n",
        "    Additional Details: {dataframe_row['from_description']}\n",
        "    Wikipedia Summaries:\n",
        "    \"\"\"\n",
        "\n",
        "    entities = dataframe_row['entities']\n",
        "    for entity in entities:\n",
        "        wiki_summary = wiki_context(entity)\n",
        "        prompt += f\"{wiki_summary} \\n\"\n",
        "\n",
        "    prompt += f\"\"\"Based on the descriptions and Wikipedia summaries provided above, which of the following captions best matches the cartoon? \\n     You must output either A, B, C, D, E immediately following \"Caption = \" \\n Caption Choices:\\n\"\"\"\n",
        "\n",
        "    # Adding caption choices\n",
        "    captions = dataframe_row['caption_choices']\n",
        "    for index, caption in enumerate(captions):\n",
        "        prompt += f\"{chr(65 + index)}: {caption}\\n\"\n",
        "\n",
        "    prompt += \"\\nCaption = [/INST]\"\n",
        "    # prompt += \"\\nWhich letter best describes the caption for the cartoon? Choose A, B, C, D, or E.\"\n",
        "    # prompt += \"\\nChoose A, B, C, D, or E based on the description above: \"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    print(\"Number of Input Tokens:  \", inputs.input_ids.size(1))    #prints number of input tokens as check for context length\n",
        "\n",
        "    generated_ids = model_4bit.generate(**inputs, max_new_tokens=100, num_return_sequences=1, do_sample=True)\n",
        "    output_text = tokenizer.batch_decode(generated_ids)[0]\n",
        "\n",
        "    print(output_text)\n",
        "\n",
        "    match = re.search(r\"Caption = \\[/INST\\] ([A-E])\", output_text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return \"No valid prediction found\"\n",
        "\n",
        "\n",
        "predicted_caption = evaluate_caption_wiki(sample_train.iloc[10])\n",
        "print(\"The model predicts caption:\", predicted_caption)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJpZg6Q4OQVZ",
        "outputId": "bcbec349-0242-4528-9ca8-d85f74bf305e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page - Title: Moai\n",
            "Page - Exists: True\n",
            "Page - Title: Tourism\n",
            "Page - Exists: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Input Tokens:   1580\n",
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon and relevant Wikipedia summaries.\n",
            "    You must use the cartoon description information and Wikipedia summaries to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: easter island\n",
            "    Description: There are giant, carved Easter Island stones scattered on a beach. All are identical and resemble a regular man but with a combed back hairstyle. In the foreground a tour guide is talking to a single male tourist who has a camera hanging around his neck.\n",
            "    Uncanny Aspect: It is unusual to see Easter Island stones which resemble a regular man.\n",
            "    Question: ['Who was the inspiration for the stones?', 'What is the tour guide saying to the tourist?']\n",
            "    Additional Details: scene: easter island description: There are giant, carved Easter Island stones scattered on a beach. All are identical and resemble a regular man but with a combed back hairstyle. In the foreground a tour guide is talking to a single male tourist who has a camera hanging around his neck. uncanny: It is unusual to see Easter Island stones which resemble a regular man. entities: Moai, Tourism. choices A: Don't be fooled. He has a dark side. B: I only like you as a friend, weapon, and means of travel. C: You're not supposed to mix Ambien and Quadrophenia. D: Not everything is about you. E: They keep watch on the offshore accounts.\n",
            "    Wikipedia Summaries:\n",
            "    Moai or moʻai (  MOH-eye; Spanish: moái; Rapa Nui: moʻai, lit. 'statue') are monolithic human figures carved by the Rapa Nui people on Rapa Nui (Easter Island) in eastern Polynesia between the years 1250 and 1500. Nearly half are still at Rano Raraku, the main moai quarry, but hundreds were transported from there and set on stone platforms called ahu around the island's perimeter. Almost all moai have overly large heads, which account for three-eighths of the size of the whole statue. They also have no legs. The moai are chiefly the living faces (aringa ora) of deified ancestors (aringa ora ata tepuna). \n",
            "The statues still gazed inland across their clan lands when Europeans first visited the island in 1722, but all of them had fallen by the latter part of the 19th century. The moai were toppled in the late 18th and early 19th centuries, possibly as a result of European contact or internecine tribal wars.\n",
            "The production and transportation of the more than 900 statues is considered a remarkable creative and physical feat. The tallest moai erected, called Paro, was almost 10 metres (33 ft) high and weighed 82 tonnes (81 long tons; 90 short tons). The heaviest moai erected was a shorter but squatter moai at Ahu Tongariki, weighing 86 tonnes (85 long tons; 95 short tons). One unfinished sculpture, if completed, would be approximately 21 m (69 ft) tall, with a weight of about 145–165 tonnes (143–162 long tons; 160–182 short tons). Statues are still being discovered as of 2023. \n",
            "Tourism is travel for pleasure, and the commercial activity of providing and supporting such travel.     UN Tourism defines tourism more generally, in terms which go \"beyond the common perception of tourism as being limited to holiday activity only\", as people \"travelling to and staying in places outside their usual environment for not more than one consecutive year for leisure and not less than 24 hours, business and other purposes\". Tourism can be domestic (within the traveller's own country) or international, and international tourism has both incoming and outgoing implications on a country's balance of payments.\n",
            "Tourism numbers declined as a result of a strong economic slowdown (the late-2000s recession) between the second half of 2008 and the end of 2009, and in consequence of the outbreak of the 2009 H1N1 influenza virus, but slowly recovered until the COVID-19 pandemic put an abrupt end to the growth. The United Nations World Tourism Organization estimated that global international tourist arrivals might have decreased by 58% to 78% in 2020, leading to a potential loss of US$0.9–1.2 trillion in international tourism receipts.\n",
            "Globally, international tourism receipts (the travel item in the balance of payments) grew to US$1.03 trillion (€740 billion) in 2005, corresponding to an increase in real terms of 3.8% from 2010. International tourist arrivals surpassed the milestone of 1 billion tourists globally for the first time in 2012. Emerging source markets such as China, Russia, and Brazil had significantly increased their spending over the previous decade.\n",
            "Global tourism accounts for c. 8% of global greenhouse-gas emissions. Emissions as well as other significant environmental and social impacts are not always beneficial to local communities and their economies. For this reason, many tourist development organizations have begun to focus on sustainable tourism to mitigate the negative effects caused by the growing impact of tourism. The United Nations World Tourism Organization emphasized these practices by promoting tourism as part of the Sustainable Development Goals, through programs like the International Year for Sustainable Tourism for Development in 2017, and programs like Tourism for SDGs focusing on how SDG 8, SDG 12 and SDG 14 implicate tourism in creating a sustainable economy.\n",
            "Tourism has reached new dimensions with the emerging industry of space tourism, as well as the cruise ship industry. Another potential new tourism industry is virtual tourism. \n",
            "Based on the descriptions and Wikipedia summaries provided above, which of the following captions best matches the cartoon? \n",
            "     You must output either A, B, C, D, E immediately following \"Caption = \" \n",
            " Caption Choices:\n",
            "A: Don't be fooled. He has a dark side.\n",
            "B: I only like you as a friend, weapon, and means of travel.\n",
            "C: You're not supposed to mix Ambien and Quadrophenia.\n",
            "D: Not everything is about you.\n",
            "E: They keep watch on the offshore accounts.\n",
            "\n",
            "Caption = [/INST] D: Not everything is about you.</s>\n",
            "The model predicts caption: D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate_model_accuracy(sample_train, num_rows):\n",
        "    correct_predictions = 0\n",
        "    true_labels = []\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_rows):\n",
        "        predicted_caption = evaluate_caption_wiki(sample_train.iloc[i])\n",
        "        correct_choice = sample_train.iloc[i]['label']\n",
        "\n",
        "        true_labels.append(correct_choice)\n",
        "        predictions.append(predicted_caption)\n",
        "\n",
        "        if predicted_caption == correct_choice:\n",
        "            correct_predictions += 1\n",
        "\n",
        "        accuracy = (correct_predictions / (i + 1)) * 100\n",
        "        running_f1 = f1_score(true_labels, predictions, average='weighted', labels=['A', 'B', 'C', 'D', 'E'])\n",
        "\n",
        "        print(f\"Row {i+1}: Predicted - {predicted_caption}, Correct - {correct_choice}, \"f\"Running Accuracy: {accuracy:.2f}%, Running F1 Score: {running_f1:.4f}\")\n",
        "\n",
        "    final_accuracy = (correct_predictions / num_rows) * 100\n",
        "    final_f1_score = f1_score(true_labels, predictions, average='weighted', labels=['A', 'B', 'C', 'D', 'E'])\n",
        "\n",
        "    return final_accuracy, final_f1_score\n",
        "\n",
        "accuracy, f1_score = evaluate_model_accuracy(sample_train, 100)\n",
        "print(f\"Final Accuracy: {accuracy:.4f}%\")\n",
        "print(f\"Final F1 Score: {f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MBHszFjzSDk5",
        "outputId": "df66e8eb-5663-4e07-8da5-087f862e4882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page - Title: Sexual fetishism\n",
            "Page - Exists: True\n",
            "Page - Title: Fly-killing device\n",
            "Page - Exists: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Input Tokens:   776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at matching cartoons to their captions.\n",
            "    You will be provided with a description of a New Yorker cartoon and relevant Wikipedia summaries.\n",
            "    You must use the cartoon description information and Wikipedia summaries to decide which of the caption options best fits the cartoon.\n",
            "\n",
            "    You must output either A, B, C, D, E immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a bedroom\n",
            "    Description: A woman is sitting suggestively on-top of her husband in bed; the man looks a bit confused. The man is wearing a football helmet, as a fly swatter sits to the side. The woman is wearing a set of bug ears.\n",
            "    Uncanny Aspect: It's unusual because the implication is that the woman has a sexual fetish for pretending to be an insect. This sort of taboo subject is rarely discussed.\n",
            "    Question: [\"What is the woman's interest/fetish, and why does she have it?\"]\n",
            "    Additional Details: scene: a bedroom description: A woman is sitting suggestively on-top of her husband in bed; the man looks a bit confused. The man is wearing a football helmet, as a fly swatter sits to the side. The woman is wearing a set of bug ears. uncanny: It's unusual because the implication is that the woman has a sexual fetish for pretending to be an insect. This sort of taboo subject is rarely discussed. entities: Sexual_fetishism, Fly-killing_device. choices A: I think we need a new sex therapist. B: This is the exact moment Susan realized she may be an accomplice and not a magician's assistant... C: Try to look housebroken. D: You realize a seven-foot diary is fair game. E: I'm losing confidence in Google Maps too.\n",
            "    Wikipedia Summaries:\n",
            "    Sexual fetishism or erotic fetishism is a sexual fixation on a nonliving object or nongenital body part. The object of interest is called the fetish; the person who has a fetish for that object is a fetishist. A sexual fetish may be regarded as a non-pathological aid to sexual excitement, or as a mental disorder if it causes significant psychosocial distress for the person or has detrimental effects on important areas of their life. Sexual arousal from a particular body part can be further classified as partialism.\n",
            "While medical definitions restrict the term sexual fetishism to objects or body parts, fetish can, in common discourse, also refer to sexual interest in specific activities. \n",
            "A fly-killing device is used for pest control of flying insects, such as houseflies, wasps, moths, gnats, and mosquitoes. \n",
            "Based on the descriptions and Wikipedia summaries provided above, which of the following captions best matches the cartoon? \n",
            "     You must output either A, B, C, D, E immediately following \"Caption = \" \n",
            " Caption Choices:\n",
            "A: I think we need a new sex therapist.\n",
            "B: This is the exact moment Susan realized she may be an accomplice and not a magician's assistant...\n",
            "C: Try to look housebroken.\n",
            "D: You realize a seven-foot diary is fair game.\n",
            "E: I'm losing confidence in Google Maps too.\n",
            "\n",
            "Caption = [/INST] A: I think we need a new sex therapist.</s>\n",
            "Row 1: Predicted - A, Correct - A, Running Accuracy: 100.00%, Running F1 Score: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page - Title: Telephone call\n",
            "Page - Exists: True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-27c07840efe4>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_f1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Final Accuracy: {accuracy:.4f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Final F1 Score: {f1_score:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-27c07840efe4>\u001b[0m in \u001b[0;36mevaluate_model_accuracy\u001b[0;34m(sample_train, num_rows)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpredicted_caption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_caption_wiki\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mcorrect_choice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-7fafcb1b3fd3>\u001b[0m in \u001b[0;36mevaluate_caption_wiki\u001b[0;34m(dataframe_row)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mentities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mwiki_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwiki_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"{wiki_summary} \\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-d9e6fe97a9d2>\u001b[0m in \u001b[0;36mwiki_context\u001b[0;34m(link)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Page - Title: {page.title}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Page - Exists: True\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"{page.summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Page - Title: {page_title}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wikipediaapi/__init__.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    918\u001b[0m         \"\"\"\n\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_called\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extracts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"extracts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wikipediaapi/__init__.py\u001b[0m in \u001b[0;36m_fetch\u001b[0;34m(self, call)\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"WikipediaPage\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;34m\"\"\"Fetches some data?.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwiki\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_called\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wikipediaapi/__init__.py\u001b[0m in \u001b[0;36mextracts\u001b[0;34m(self, page, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mused_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_common_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wikipediaapi/__init__.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, page, params)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"redirects\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_redirects\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - Ranking Task Execution: Baseline + Wiki Summary Context"
      ],
      "metadata": {
        "id": "ilSJ5iGhXsYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Baseline No Context"
      ],
      "metadata": {
        "id": "NSTg0TXOXtPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_caption(dataframe_row):\n",
        "\n",
        "    # example prompt from Mistral Model Card = \"<s>[INST] What is your favourite condiment? [/INST]\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "    <s>[INST]\n",
        "\n",
        "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
        "    You will be provided with a description of a New Yorker cartoon.\n",
        "    You must use the cartoon description information to decide which of the caption options is best.\n",
        "\n",
        "    You must output either A, B immediately following \"Caption = \"\n",
        "\n",
        "    Cartoon Description:\n",
        "    Location: {dataframe_row['image_location']}\n",
        "    Description: {dataframe_row['image_description']}\n",
        "    Uncanny Aspect: {dataframe_row['image_uncanny_description']}\n",
        "    Question: {dataframe_row['questions']}\n",
        "    Additional Details: {dataframe_row['from_description']}\n",
        "\n",
        "    Based on the descriptions provided above, which of the following captions is best?\n",
        "\n",
        "    Caption Choices:\n",
        "    \"\"\"\n",
        "\n",
        "    # Adding caption choices\n",
        "    captions = dataframe_row['caption_choices']\n",
        "    for index, caption in enumerate(captions):\n",
        "        prompt += f\"{chr(65 + index)}: {caption}\\n\"\n",
        "\n",
        "    prompt += \"\\nCaption = [/INST]\"\n",
        "    # prompt += \"\\nWhich letter best describes the caption for the cartoon? Choose A, B, C, D, or E.\"\n",
        "    # prompt += \"\\nChoose A, B, C, D, or E based on the description above: \"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    print(\"Number of Input Tokens:  \", inputs.input_ids.size(1))    #prints number of input tokens as check for context length\n",
        "\n",
        "    generated_ids = model_4bit.generate(**inputs, max_new_tokens=100, num_return_sequences=1, do_sample=True)\n",
        "    output_text = tokenizer.batch_decode(generated_ids)[0]\n",
        "\n",
        "    print(output_text)\n",
        "\n",
        "    match = re.search(r\"Caption = \\[/INST\\] ([A-B])\", output_text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return \"No valid prediction found\"\n",
        "\n",
        "\n",
        "predicted_caption = evaluate_caption(sample_train_rank.iloc[10])\n",
        "print(\"The model predicts caption:\", predicted_caption)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9GT7H3KXsBo",
        "outputId": "28923d50-afde-472c-96e2-58c0afd2d3e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Input Tokens:   327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an office\n",
            "    Description: Some people are working in an office. There is a bird in the cubicle in the middle, sitting on a nest.\n",
            "    Uncanny Aspect: The bird is gigantic and way bigger than anything else.\n",
            "    Question: ['Why is the bird so big?']\n",
            "    Additional Details: scene: an office description: Some people are working in an office. There is a bird in the cubicle in the middle, sitting on a nest. uncanny: The bird is gigantic and way bigger than anything else. entities: Chicken, Giant. choices: A: We'll need to verify you're free range, also. B: I can remember when she was just a fuzzy yellow intern.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: We'll need to verify you're free range, also.\n",
            "B: I can remember when she was just a fuzzy yellow intern.\n",
            "\n",
            "Caption = [/INST] Based on the description provided, neither caption option A nor B directly answers the question \"Why is the bird so big?\" and does not seem to fit with the uncanny aspect of the cartoon description which mentions that the bird is \"gigantic and way bigger than anything else.\" Instead, both captions refer to chickens or birds as entities and seem to reference office jargon and humor unrelated to the cartoon description.\n",
            "\n",
            "Therefore, based on the information provided\n",
            "The model predicts caption: B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate_model_accuracy(sample_train, num_rows):\n",
        "    correct_predictions = 0\n",
        "    true_labels = []\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_rows):\n",
        "        predicted_caption = evaluate_caption(sample_train.iloc[i])\n",
        "        correct_choice = sample_train.iloc[i]['label']\n",
        "\n",
        "        true_labels.append(correct_choice)\n",
        "        predictions.append(predicted_caption)\n",
        "\n",
        "        if predicted_caption == correct_choice:\n",
        "            correct_predictions += 1\n",
        "\n",
        "        accuracy = (correct_predictions / (i + 1)) * 100\n",
        "        running_f1 = f1_score(true_labels, predictions, average='weighted', labels=['A', 'B'])\n",
        "\n",
        "        print(f\"Row {i+1}: Predicted - {predicted_caption}, Correct - {correct_choice}, \"f\"Running Accuracy: {accuracy:.2f}%, Running F1 Score: {running_f1:.4f}\")\n",
        "\n",
        "    final_accuracy = (correct_predictions / num_rows) * 100\n",
        "    final_f1_score = f1_score(true_labels, predictions, average='weighted', labels=['A', 'B'])\n",
        "\n",
        "    return final_accuracy, final_f1_score\n",
        "\n",
        "\n",
        "accuracy, f1_score = evaluate_model_accuracy(sample_train_rank, 100)\n",
        "print(f\"Final Accuracy: {accuracy:.4f}%\")\n",
        "print(f\"Final F1 Score: {f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhwekY2bYBWL",
        "outputId": "c676dd05-7496-4890-b60e-5408506a4b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Input Tokens:   288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a river\n",
            "    Description: A bear is standing in a river. Some fish are trying to jump up a waterfall.\n",
            "    Uncanny Aspect: Nothing looks unusual. This is a standard thing for bears and fish to do.\n",
            "    Question: ['Does the bear catch the fish?']\n",
            "    Additional Details: scene: a river description: A bear is standing in a river. Some fish are trying to jump up a waterfall. uncanny: Nothing looks unusual. This is a standard thing for bears and fish to do. entities: Salmon, Bear. choices: A: Take my wife, please! B: Heaven... or hell?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Take my wife, please!\n",
            "B: Heaven... or hell?\n",
            "\n",
            "Caption = [/INST] Given the information provided, neither caption A nor caption B fit the scene described in the cartoon.\n",
            "\n",
            "The cartoon description makes it clear that the bear is not trying to catch the fish, but rather, the fish are trying to jump up a waterfall. Therefore, neither of the given captions can be the correct caption for this particular cartoon.\n",
            "\n",
            "So, in this case, neither A nor B is the best option. There is an error in the question\n",
            "Row 1: Predicted - No valid prediction found, Correct - A, Running Accuracy: 0.00%, Running F1 Score: 0.0000\n",
            "Number of Input Tokens:   366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a tailor\n",
            "    Description: A wolf is trying on sheep's clothing and other outfits in a shop. A man is helping him. He is carrying a bunch of costumes.\n",
            "    Uncanny Aspect: There is a wolf in sheep's clothing in a costumer shop. Wolves are not this smart.\n",
            "    Question: ['Why is the wolf trying on costumes?']\n",
            "    Additional Details: scene: a tailor description: A wolf is trying on sheep's clothing and other outfits in a shop. A man is helping him. He is carrying a bunch of costumes. uncanny: There is a wolf in sheep's clothing in a costumer shop. Wolves are not this smart. entities: Wolf_in_sheep%27s_clothing, Skin. choices: A: Now that's what I call a dinner jacket. B: We all agree Mr President - it was a perfect call\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Now that's what I call a dinner jacket.\n",
            "B: We all agree Mr President - it was a perfect call\n",
            "\n",
            "Caption = [/INST] A. \"Now that's what I call a dinner jacket\" is the best caption choice for the given description, as it directly relates to the wolf trying on clothing in the tailor shop. The other caption is not related to the description provided.</s>\n",
            "Row 2: Predicted - A, Correct - A, Running Accuracy: 50.00%, Running F1 Score: 0.6667\n",
            "Number of Input Tokens:   349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: restaurant\n",
            "    Description: A man is sitting at a table in a restaurant, talking to the waiter. His soup has turned into a waterspout.\n",
            "    Uncanny Aspect: The soup has exploded into a full blown waterspout.\n",
            "    Question: ['Why does this soup bowl create its own weather?']\n",
            "    Additional Details: scene: restaurant description: A man is sitting at a table in a restaurant, talking to the waiter. His soup has turned into a waterspout. uncanny: The soup has exploded into a full blown waterspout. entities: Smoke, Pungency. choices: A: On second thought, let's skip the chocolate lava cake for dessert. B: I asked for the whole freshwater trout, not the bowl of waterspout.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: On second thought, let's skip the chocolate lava cake for dessert.\n",
            "B: I asked for the whole freshwater trout, not the bowl of waterspout.\n",
            "\n",
            "Caption = [/INST] Based on the information provided, the best caption for the given New Yorker cartoon description is:\n",
            "\n",
            "B. \"I asked for the whole freshwater trout, not the bowl of waterspout.\"\n",
            "\n",
            "This caption not only aligns with the scene described in the cartoon but also adds humor by highlighting the unexpected outcome of the man's order. The soup turning into a waterspout is an uncanny and unintended element, and the caption\n",
            "Row 3: Predicted - B, Correct - A, Running Accuracy: 33.33%, Running F1 Score: 0.5000\n",
            "Number of Input Tokens:   354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: Doctor's Office\n",
            "    Description: A stranger in a trench coat and fedora hat stands besides a doctor. The stranger is acting suspicious but no one is looking at him.\n",
            "    Uncanny Aspect: The stranger is in the middle of a private meeting between patient and doctor.\n",
            "    Question: ['Why is the stranger there?']\n",
            "    Additional Details: scene: Doctor's Office description: A stranger in a trench coat and fedora hat stands besides a doctor. The stranger is acting suspicious but no one is looking at him. uncanny: The stranger is in the middle of a private meeting between patient and doctor. entities: Doctor, Instruments_used_in_general_medicine. choices: A: Good news! We have a solid lead on who stole your liver. B: Would you care to review the privacy waiver one more time?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Good news! We have a solid lead on who stole your liver.\n",
            "B: Would you care to review the privacy waiver one more time?\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description and the uncanny aspect, neither caption A nor caption B is the best description of the situation.\n",
            "\n",
            "The description mentions that the stranger is acting suspicious but no one is looking at him. The uncanny aspect indicates that the stranger is in the middle of a private meeting between the doctor and a patient. However, neither caption suggests that the stranger is involved in a private meeting, and both captions refer to entities not present\n",
            "Row 4: Predicted - B, Correct - A, Running Accuracy: 25.00%, Running F1 Score: 0.4000\n",
            "Number of Input Tokens:   313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the desert\n",
            "    Description: Two men are exhausted, crawling through the desert. They're following a marching band leader.\n",
            "    Uncanny Aspect: The band leader is out in the middle of a deserted wasteland.\n",
            "    Question: ['Is this a mirage?']\n",
            "    Additional Details: scene: the desert description: Two men are exhausted, crawling through the desert. They're following a marching band leader. uncanny: The band leader is out in the middle of a deserted wasteland. entities: Marching, Allegiance. choices: A: I finally know what it means to be led astray B: Could really use some rain on this parade.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I finally know what it means to be led astray\n",
            "B: Could really use some rain on this parade.\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description, it seems that the men are following the marching band leader despite being in the middle of a desert, an unlikely and unusual setting for a marching band. This uncanny aspect adds to the potential for a humorous interpretation of the situation.\n",
            "\n",
            "Caption A, \"I finally know what it means to be led astray,\" fits well with this interpretation. The men are following the band leader even in the most inopportune\n",
            "Row 5: Predicted - B, Correct - B, Running Accuracy: 40.00%, Running F1 Score: 0.4200\n",
            "Number of Input Tokens:   336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a restaurant\n",
            "    Description: A man is sitting at a table in a restaurant. He is reading a menu while a bear stands in front of him, dripping wet.\n",
            "    Uncanny Aspect: There is a bear inside a restaurant when he should be in the woods.\n",
            "    Question: ['Why is the bear so wet?', 'What is the bear doing in the restaurant?']\n",
            "    Additional Details: scene: a restaurant description: A man is sitting at a table in a restaurant. He is reading a menu while a bear stands in front of him, dripping wet. uncanny: There is a bear inside a restaurant when he should be in the woods. entities: Bear, Fur. choices: A: I was looking for something a little drier. B: Aren't you going to write this down?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I was looking for something a little drier.\n",
            "B: Aren't you going to write this down?\n",
            "\n",
            "Caption = [/INST] A: I was looking for something a little drier.\n",
            "\n",
            "Explanation: Given the description and the uncanny aspect of the situation, it's more logical for the bear to be looking for something drier since he is wet and in a restaurant, which is an unlikely environment for bears. The second option \"Aren't you going to write this down?\" does not fit the scene well and seems unrelated to the description or the unusual presence of the bear in the restaurant\n",
            "Row 6: Predicted - A, Correct - B, Running Accuracy: 33.33%, Running F1 Score: 0.3556\n",
            "Number of Input Tokens:   380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a car dealership\n",
            "    Description: A couple is at a car lot when a salesman shows them a hideous car. the care has cat arms coming out of the tires and cat eyes for headlights and razor sharp teeth.\n",
            "    Uncanny Aspect: Cars do not have cat body parts coming out of it.\n",
            "    Question: ['Why does the car resemble a cat?']\n",
            "    Additional Details: scene: a car dealership description: A couple is at a car lot when a salesman shows them a hideous car. the care has cat arms coming out of the tires and cat eyes for headlights and razor sharp teeth. uncanny: Cars do not have cat body parts coming out of it. entities: Car, Monster. choices: A: When there's a full moon, he drinks 93 unleaded, not 87. B: What’s it going to take to get you in this car today?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: When there's a full moon, he drinks 93 unleaded, not 87.\n",
            "B: What’s it going to take to get you in this car today?\n",
            "\n",
            "Caption = [/INST] A. When there's a full moon, he drinks 93 unleaded, not 87. (This caption is less fitting as there's no indication of a full moon in the cartoon description and the cartoon features a car that resembles a cat, not a werewolf.)\n",
            "\n",
            "B. What’s it going to take to get you in this car today? (This caption is less fitting as well, as it references a sales\n",
            "Row 7: Predicted - A, Correct - B, Running Accuracy: 28.57%, Running F1 Score: 0.3061\n",
            "Number of Input Tokens:   449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: two branches\n",
            "    Description: Two butterflies are standing on the ends of branches facing each other. The wings of the one on the right resemble a stained glass window. They appear to be having a conversation.\n",
            "    Uncanny Aspect: The wing on the butterfly to the right is a pattern that is very unusual for a butterfly. It is square blocks such as what you might see in a stained glass window. It is uncommon for butterflies to talk to one another.\n",
            "    Question: ['What are the two butterflies talking about?']\n",
            "    Additional Details: scene: two branches description: Two butterflies are standing on the ends of branches facing each other. The wings of the one on the right resemble a stained glass window. They appear to be having a conversation. uncanny: The wing on the butterfly to the right is a pattern that is very unusual for a butterfly. It is square blocks such as what you might see in a stained glass window. It is uncommon for butterflies to talk to one another. entities: Butterfly, Abstract_art, Piet_Mondrian. choices: A: You think this is weird? My sister looks like a soup can. B: I don't have to worry about predators near modern art museums.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You think this is weird? My sister looks like a soup can.\n",
            "B: I don't have to worry about predators near modern art museums.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and uncanny aspect provided, it is unlikely that the butterflies are discussing predators or modern art. therefore, Choice B is less likely to be the correct caption.\n",
            "\n",
            "The cartoon description mentions that the two butterflies are having a conversation and the one on the right has unusual stained glass window-like wings. The uncanny aspect confirms that its wings are uncommon for a butterfly, suggesting that the conversation could be\n",
            "Row 8: Predicted - B, Correct - A, Running Accuracy: 25.00%, Running F1 Score: 0.2634\n",
            "Number of Input Tokens:   415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: therapist office\n",
            "    Description: A psychiatrist sits in a recliner in his office talking and taking notes. A bearded cowboy lays down on a patients lounge sofa playing his guitar staring off with an unfocused look.\n",
            "    Uncanny Aspect: It is unusual that a patient would be playing guitar during a therapy session.\n",
            "    Question: ['Why is the patient playing a guitar?', 'What is the therapist saying or writing down?']\n",
            "    Additional Details: scene: therapist office description: A psychiatrist sits in a recliner in his office talking and taking notes. A bearded cowboy lays down on a patients lounge sofa playing his guitar staring off with an unfocused look. uncanny: It is unusual that a patient would be playing guitar during a therapy session. entities: Cowboy, Psychotherapy. choices: A: Let me get this straight \"if my phone don't ring, I'll know its you\" ? B: Get over it. You're not an old cowhand, you're Irving Goldstein from Brooklyn.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Let me get this straight \"if my phone don't ring, I'll know its you\" ?\n",
            "B: Get over it. You're not an old cowhand, you're Irving Goldstein from Brooklyn.\n",
            "\n",
            "Caption = [/INST] A. \"Let me get this straight 'if my phone don't ring, I'll know its you'\"\n",
            "\n",
            "This caption is more likely to fit the scenario described as it provides a clear link between the patient's guitar playing and the idea of distracting himself from therapy, potentially with thoughts of someone else. The other caption seems more dismissive and lacks the connection to the therapist office or the patient's behavior, making it less suitable based on the provided description\n",
            "Row 9: Predicted - A, Correct - B, Running Accuracy: 22.22%, Running F1 Score: 0.2346\n",
            "Number of Input Tokens:   338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a park bench\n",
            "    Description: Two men are on a bench. One man is being attacked by birds. The other man is reading and stares at him.\n",
            "    Uncanny Aspect: Birds are covering the man. This is not normal unless the man is covered with food.\n",
            "    Question: ['Why are the birds all over the man?']\n",
            "    Additional Details: scene: a park bench description: Two men are on a bench. One man is being attacked by birds. The other man is reading and stares at him. uncanny: Birds are covering the man. This is not normal unless the man is covered with food. entities: Bird_feeding, Imprinting_(psychology). choices: A: You shouldn't have opened that can of worms. B: How come you get all the attention?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You shouldn't have opened that can of worms.\n",
            "B: How come you get all the attention?\n",
            "\n",
            "Caption = [/INST] Based on the information given, the best caption would be: A: \"You shouldn't have opened that can of worms.\"\n",
            "\n",
            "Explanation:\n",
            "The description mentions that the man being attacked by birds is not covered in food, making it an uncanny situation. The caption option A implies that the man accidentally attracted the birds by opening a can of worms, which fits this uncanny aspect and the overall scene of the cartoon.\n",
            "\n",
            "Option B,\n",
            "Row 10: Predicted - B, Correct - A, Running Accuracy: 20.00%, Running F1 Score: 0.2089\n",
            "Number of Input Tokens:   327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an office\n",
            "    Description: Some people are working in an office. There is a bird in the cubicle in the middle, sitting on a nest.\n",
            "    Uncanny Aspect: The bird is gigantic and way bigger than anything else.\n",
            "    Question: ['Why is the bird so big?']\n",
            "    Additional Details: scene: an office description: Some people are working in an office. There is a bird in the cubicle in the middle, sitting on a nest. uncanny: The bird is gigantic and way bigger than anything else. entities: Chicken, Giant. choices: A: We'll need to verify you're free range, also. B: I can remember when she was just a fuzzy yellow intern.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: We'll need to verify you're free range, also.\n",
            "B: I can remember when she was just a fuzzy yellow intern.\n",
            "\n",
            "Caption = [/INST] Based on the description provided, the caption that is most likely to fit the New Yorker cartoon is A: \"We'll need to verify you're free range, also.\" This is because the unusual aspect of the cartoon is the giant bird in the office, and A's mention of \"free range\" could be a humorous reference to the bird being a large and unusual employee in the office setting. Additionally, the word \"also\" in A implies that there is\n",
            "Row 11: Predicted - B, Correct - B, Running Accuracy: 27.27%, Running F1 Score: 0.2744\n",
            "Number of Input Tokens:   383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the living room\n",
            "    Description: A pair of couples are sitting around a coffee table in a living room. One of the men is pointedly looking at his watch. Behind him is a set of cross bars.\n",
            "    Uncanny Aspect: It's unusual to see a normal living room behind a set of what appears to be jailhouse bars.\n",
            "    Question: ['Why are there cross bars instead of a proper door?']\n",
            "    Additional Details: scene: the living room description: A pair of couples are sitting around a coffee table in a living room. One of the men is pointedly looking at his watch. Behind him is a set of cross bars. uncanny: It's unusual to see a normal living room behind a set of what appears to be jailhouse bars. entities: Prison_cell, Therapy. choices: A: I'd love to come, but you know the old ball and chain. B: I forget, are we \"gated community\" or \"medium security\"?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I'd love to come, but you know the old ball and chain.\n",
            "B: I forget, are we \"gated community\" or \"medium security\"?\n",
            "\n",
            "Caption = [/INST] Based on the description and context provided, the best caption for this New Yorker cartoon would be:\n",
            "\n",
            "A: \"I'd love to come, but you know the old ball and chain.\"\n",
            "\n",
            "This caption works well with the scene as it incorporates the unusual aspect of the living room being behind jailhouse bars, and also plays on the idiom \"ball and chain,\" which refers to a marriage or long-term relationship being restrictive or limiting, much like\n",
            "Row 12: Predicted - B, Correct - A, Running Accuracy: 25.00%, Running F1 Score: 0.2449\n",
            "Number of Input Tokens:   335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the desert\n",
            "    Description: A cactus has legs and is walking. Two joggers are running and one woman is staring at it.\n",
            "    Uncanny Aspect: The cactus has legs and is walking.\n",
            "    Question: ['Why does the cactus have legs?']\n",
            "    Additional Details: scene: the desert description: A cactus has legs and is walking. Two joggers are running and one woman is staring at it. uncanny: The cactus has legs and is walking. entities: Cactus, Jogging. choices: A: You should never have said \"Boy that'd make one hell of a coat rack.\" B: You know how they say that in the Spring, the desert comes alive?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You should never have said \"Boy that'd make one hell of a coat rack.\"\n",
            "B: You know how they say that in the Spring, the desert comes alive?\n",
            "\n",
            "Caption = [/INST] B: You know how they say that in the Spring, the desert comes alive?\n",
            "\n",
            "Explanation: The description mentions that the scene is in the desert, and the cartoon's uncanny aspect is the walking cactus. The additional detail of the joggers and woman don't have a bearing on the question. Option A doesn't make sense in the context of the desert or the cartoon, while option B references the idea of the desert coming to life\n",
            "Row 13: Predicted - B, Correct - B, Running Accuracy: 30.77%, Running F1 Score: 0.2957\n",
            "Number of Input Tokens:   332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: living room\n",
            "    Description: A man and a woman are sitting on a couch. They are surrounded by numerous monkeys.\n",
            "    Uncanny Aspect: Monkeys are found in jungles or zoos, not in houses.\n",
            "    Question: ['Why are the monkeys there?']\n",
            "    Additional Details: scene: living room description: A man and a woman are sitting on a couch. They are surrounded by numerous monkeys. uncanny: Monkeys are found in jungles or zoos, not in houses. entities: Mischief, Monkey. choices: A: I don't mind the monkey see as much as the monkey doo. B: The stager says this is how we'll sell the house.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I don't mind the monkey see as much as the monkey doo.\n",
            "B: The stager says this is how we'll sell the house.\n",
            "\n",
            "Caption = [/INST] Based on the descriptions provided above, the best caption is A: \"I don't mind the monkey see as much as the monkey doo.\" This caption is funnier and more fitting for a New Yorker Cartoon as it plays on the phrase \"The monkey see, monkey do\" and acknowledges the uncanny nature of the situation. Additionally, it focuses on the reaction of the man and woman, who seem unfazed by the presence of the monkeys\n",
            "Row 14: Predicted - B, Correct - A, Running Accuracy: 28.57%, Running F1 Score: 0.2667\n",
            "Number of Input Tokens:   305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the desert\n",
            "    Description: A cactus has legs and is walking. Two joggers are running and one woman is staring at it.\n",
            "    Uncanny Aspect: The cactus has legs and is walking.\n",
            "    Question: ['Why does the cactus have legs?']\n",
            "    Additional Details: scene: the desert description: A cactus has legs and is walking. Two joggers are running and one woman is staring at it. uncanny: The cactus has legs and is walking. entities: Cactus, Jogging. choices: A: Oh no. Arpaio is running. B: Keep moving. He's a hugger.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Oh no. Arpaio is running.\n",
            "B: Keep moving. He's a hugger.\n",
            "\n",
            "Caption = [/INST] A.\n",
            "\n",
            "Explanation:\n",
            "The description mentions \"two joggers\" and \"one woman,\" but it does not provide any information about their identities. However, option A makes a specific reference to \"Arpajo,\" who is a well-known figure in the desert southwest of the United States, known for his law enforcement career. This specific reference fits well with the context of the scene described in the cartoon, making option A a better fit.\n",
            "\n",
            "Option\n",
            "Row 15: Predicted - A, Correct - B, Running Accuracy: 26.67%, Running F1 Score: 0.2571\n",
            "Number of Input Tokens:   366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the beach\n",
            "    Description: A man is relaxing on a small island under a palm tree. Another man with tattered clothes and a briefcase stares at him.\n",
            "    Uncanny Aspect: There is a businessman on the island with tattered clothes while another man is just relaxing and looking fine.\n",
            "    Question: ['What happened to the man with tattered clothes?']\n",
            "    Additional Details: scene: the beach description: A man is relaxing on a small island under a palm tree. Another man with tattered clothes and a briefcase stares at him. uncanny: There is a businessman on the island with tattered clothes while another man is just relaxing and looking fine. entities: Coconut, Beach_furniture. choices: A: The drinks are great, but it's a LONG walk to the cabana. B: Welcome to paradise. I take it he won another term.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: The drinks are great, but it's a LONG walk to the cabana.\n",
            "B: Welcome to paradise. I take it he won another term.\n",
            "\n",
            "Caption = [/INST] Based on the descriptions provided, the best caption is A: \"The drinks are great, but it's a LONG walk to the cabana.\"\n",
            "\n",
            "The reason is that there is no indication in the cartoon description that either man is a politician or that one has won an election. Additionally, the man in tattered clothes and a businessman's briefcase is an unusual sight on a beach, but it doesn't necessarily suggest a political theme. Meanwhile, \"The\n",
            "Row 16: Predicted - B, Correct - B, Running Accuracy: 31.25%, Running F1 Score: 0.2991\n",
            "Number of Input Tokens:   477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a police station\n",
            "    Description: There is a police line-up with 4 men and 1 woman. They are all wearing a number around their necks from 1 to 5. The men are all dressed in regular clothes but the woman stands out because she is a ballerina.\n",
            "    Uncanny Aspect: A ballerina is in a police line-up with 4 men. The way she is dressed is unusual as well as the fact that she looks nothing else like the other people in the line-up.\n",
            "    Question: ['How did the ballerina end up in the line-up?']\n",
            "    Additional Details: scene: a police station description: There is a police line-up with 4 men and 1 woman. They are all wearing a number around their necks from 1 to 5. The men are all dressed in regular clothes but the woman stands out because she is a ballerina. uncanny: A ballerina is in a police line-up with 4 men. The way she is dressed is unusual as well as the fact that she looks nothing else like the other people in the line-up. entities: Ballet_dancer, Police_lineup. choices: A: It's Number Three, Officer. The thief had a small nose. B: O.K., now we'd like to see No. 4 in the tutu.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It's Number Three, Officer. The thief had a small nose.\n",
            "B: O.K., now we'd like to see No. 4 in the tutu.\n",
            "\n",
            "Caption = [/INST] B: O.K., now we'd like to see No. 4 in the tutu.\n",
            "\n",
            "Explanation:\n",
            "The description of the cartoon mentions that the ballerina stands out in the line-up due to her appearance being unusual among the other people. The choice \"It's Number Three, Officer. The thief had a small nose.\" while an option, does not fit the scene as it does not explain why the ballerina is in\n",
            "Row 17: Predicted - B, Correct - B, Running Accuracy: 35.29%, Running F1 Score: 0.3371\n",
            "Number of Input Tokens:   300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: easter island\n",
            "    Description: There are a bunch of statues of heads in a field. Another head is smiling.\n",
            "    Uncanny Aspect: Only one head looks different than the others.\n",
            "    Question: ['What is the statue smiling about?']\n",
            "    Additional Details: scene: easter island description: There are a bunch of statues of heads in a field. Another head is smiling. uncanny: Only one head looks different than the others. entities: Egghead, Statue. choices: A: It's a little known cult in the Short Ears. B: We really need to revisit our immigration policy.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It's a little known cult in the Short Ears.\n",
            "B: We really need to revisit our immigration policy.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and question provided, the best caption is A: \"It's a little known cult in the Short Ears.\"\n",
            "\n",
            "Explanation: The description of the scene suggests that the statues are unusual or out of place, and the fact that only one head looks different than the others further emphasizes this. The question asks what the smiling statue might be smiling about, but the description does not provide any context as to why this head might be smiling or\n",
            "Row 18: Predicted - B, Correct - B, Running Accuracy: 38.89%, Running F1 Score: 0.3714\n",
            "Number of Input Tokens:   329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a baseball pit\n",
            "    Description: Some baseball players are watching the game from the dugout. One of them has high heels on.\n",
            "    Uncanny Aspect: A baseball player is wearing lady shoes.\n",
            "    Question: ['Why is he wearing that to play baseball?']\n",
            "    Additional Details: scene: a baseball pit description: Some baseball players are watching the game from the dugout. One of them has high heels on. uncanny: A baseball player is wearing lady shoes. entities: Baseball#Players, High-heeled_shoe. choices: A: Get me my flats, I'm going out to the mound. B: Go talk to him, lefty, he never listens to a woman.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Get me my flats, I'm going out to the mound.\n",
            "B: Go talk to him, lefty, he never listens to a woman.\n",
            "\n",
            "Caption = [/INST] Based on the given cartoon description and context, the best caption for this situation would be:\n",
            "\n",
            "B: Go talk to him, lefty, he never listens to a woman.\n",
            "\n",
            "The reason for this choice is that there doesn't seem to be any reason given for why the baseball player in question would be wearing high heels to the baseball game, and the context of the scene appears to be focused on the players watching the game from the dugout. Therefore, the\n",
            "Row 19: Predicted - B, Correct - A, Running Accuracy: 36.84%, Running F1 Score: 0.3423\n",
            "Number of Input Tokens:   319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a sidewalk\n",
            "    Description: There is a man wearing a crown with a woman walking in a city. The crown is yellow and the cape is red.\n",
            "    Uncanny Aspect: There is a guy wearing a crown in a city.\n",
            "    Question: ['Why is there a king in a city?']\n",
            "    Additional Details: scene: a sidewalk description: There is a man wearing a crown with a woman walking in a city. The crown is yellow and the cape is red. uncanny: There is a guy wearing a crown in a city. entities: King, Streetcorner. choices: A: Harry, the whole point of leaving England was to blend in. B: People do respect you, regardless of your position.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Harry, the whole point of leaving England was to blend in.\n",
            "B: People do respect you, regardless of your position.\n",
            "\n",
            "Caption = [/INST] Based on the description provided, the best caption for the cartoon would be A: \"Harry, the whole point of leaving England was to blend in.\" The reason for this is that the cartoon description mentions that the man is wearing a crown and is in a city, which is uncanny and not the norm for everyday city life. The fact that the man is trying to blend in suggests that he is not actually a king, but rather someone who is pretending to be one\n",
            "Row 20: Predicted - B, Correct - A, Running Accuracy: 35.00%, Running F1 Score: 0.3167\n",
            "Number of Input Tokens:   317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a cloud\n",
            "    Description: A number of men are sitting around a table in the clouds discussing a chart. Jack is climbing the beanstalk into the clouds and looking at them.\n",
            "    Uncanny Aspect: Businessmen should be in an office, not in the sky.\n",
            "    Question: ['What does Jack think about this?']\n",
            "    Additional Details: scene: a cloud description: A number of men are sitting around a table in the clouds discussing a chart. Jack is climbing the beanstalk into the clouds and looking at them. uncanny: Businessmen should be in an office, not in the sky. entities: Jack_and_the_Beanstalk, Meeting. choices: A: We have a stalker. B: We're being stalked.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: We have a stalker.\n",
            "B: We're being stalked.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description provided, it seems unlikely that Jack would perceive the businessmen in the clouds as stalkers. Instead, the unusual setting of a business meeting in the clouds might suggest that Jack finds the situation strange or even comical. Therefore, option A (\"We have a stalker.\") is less likely to be the correct answer.\n",
            "\n",
            "On the other hand, option B (\"We're being stalked.\") could potentially make more sense if the businessmen were stalking\n",
            "Row 21: Predicted - B, Correct - A, Running Accuracy: 33.33%, Running F1 Score: 0.2940\n",
            "Number of Input Tokens:   332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a field\n",
            "    Description: Two turkeys are in a fenced in area. One of them has women legs with fishnets and high heels.\n",
            "    Uncanny Aspect: Turkeys do not have human legs and do not wear high heels with fishnets.\n",
            "    Question: ['Why is the turkey dressing up?']\n",
            "    Additional Details: scene: a field description: Two turkeys are in a fenced in area. One of them has women legs with fishnets and high heels. uncanny: Turkeys do not have human legs and do not wear high heels with fishnets. entities: Turkey_(bird), Prostitution. choices: A: What happens in November, stays in November. B: Don’t laugh, it got my uncle out of the army.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: What happens in November, stays in November.\n",
            "B: Don’t laugh, it got my uncle out of the army.\n",
            "\n",
            "Caption = [/INST] A: What happens in November, stays in November.\n",
            "\n",
            "Explanation: Given the description of the cartoon with a turkey dressed unnaturally in women's legs with fishnets and high heels, it is reasonable to assume that this is a Thanksgiving-themed cartoon. The joke in option A plays on the common saying \"What happens in Vegas, stays in Vegas,\" and applies it to the context of the cartoon by using \"What happens in\n",
            "Row 22: Predicted - A, Correct - B, Running Accuracy: 31.82%, Running F1 Score: 0.2896\n",
            "Number of Input Tokens:   505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: boardroom\n",
            "    Description: Six people and one animal are sitting in chairs positioned in a circle in a therapist's office. The person sitting in the center of the image is wearing glasses and and a chin beard and appears to be the therapist. Many of the other people are characters from Wizard of the Oz (Dorothy, Scarecrow, Tin Man, Cowardly Lion).\n",
            "    Uncanny Aspect: Characters from a fictional story are sitting in a real world setting (therapist's office). It's also unusual to see fictional characters needing/getting therapy.\n",
            "    Question: ['Why are Wizard of Oz characters getting therapy?']\n",
            "    Additional Details: scene: boardroom description: Six people and one animal are sitting in chairs positioned in a circle in a therapist's office. The person sitting in the center of the image is wearing glasses and and a chin beard and appears to be the therapist. Many of the other people are characters from Wizard of the Oz (Dorothy, Scarecrow, Tin Man, Cowardly Lion). uncanny: Characters from a fictional story are sitting in a real world setting (therapist's office). It's also unusual to see fictional characters needing/getting therapy. entities: Land_of_Oz, Meeting. choices: A: This is my first session, but I have the feeling I've seen all these people before. B: If you adopt her, please understand that she comes with a lot of baggage.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: This is my first session, but I have the feeling I've seen all these people before.\n",
            "B: If you adopt her, please understand that she comes with a lot of baggage.\n",
            "\n",
            "Caption = [/INST] A: This is my first session, but I have the feeling I've seen all these people before.\n",
            "\n",
            "Explanation:\n",
            "The description mentions that the scene takes place in a therapist's office and that many of the people present are characters from The Wizard of Oz. This setup is already somewhat unusual, as fictional characters are not typically depicted in real-world settings like this, let alone in therapy sessions. Given this context, option A is the more likely choice\n",
            "Row 23: Predicted - A, Correct - B, Running Accuracy: 30.43%, Running F1 Score: 0.2850\n",
            "Number of Input Tokens:   339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: therapy room\n",
            "    Description: An octopus is on the sofa. A man is holding a paper near him.\n",
            "    Uncanny Aspect: An octopus is on a sofa near a man.\n",
            "    Question: ['Why is the octopus on the sofa?']\n",
            "    Additional Details: scene: therapy room description: An octopus is on the sofa. A man is holding a paper near him. uncanny: An octopus is on a sofa near a man. entities: Psychotherapy, Octopus. choices: A: You’re right. Maybe sometimes a sea cucumber is just a sea cucumber. B: I think we'll skip the ink blot test, and go right to your mother.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You’re right. Maybe sometimes a sea cucumber is just a sea cucumber.\n",
            "B: I think we'll skip the ink blot test, and go right to your mother.\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the description and the context of the cartoon, Option B: \"I think we'll skip the ink blot test, and go right to your mother.\" seems more fitting. The setting of the scene being a therapy room and the man holding a paper suggest that this is a therapeutic session. Ink blot tests are often used in psychoanalysis, making Option B a more appropriate response. Option A does not make any direct reference to the ther\n",
            "Row 24: Predicted - B, Correct - A, Running Accuracy: 29.17%, Running F1 Score: 0.2669\n",
            "Number of Input Tokens:   335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a living room\n",
            "    Description: A walrus is sitting in a chair reading a book. A woman is talking to him.\n",
            "    Uncanny Aspect: Walruses don't read and don't live in houses.\n",
            "    Question: ['What are they talking about?']\n",
            "    Additional Details: scene: a living room description: A walrus is sitting in a chair reading a book. A woman is talking to him. uncanny: Walruses don't read and don't live in houses. entities: Walrus, Reading. choices: A: I always knew adopting from Russia would be challenge. B: Did you put 3,250 pounds of 'fresh mackerel' on my credit card?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I always knew adopting from Russia would be challenge.\n",
            "B: Did you put 3,250 pounds of 'fresh mackerel' on my credit card?\n",
            "\n",
            "Caption = [/INST] A. The description states that the walrus is reading a book in a living room, which is an unnatural and uncanny situation for a walrus as they don't live in houses and can't read. The conversation between the woman and the walrus could be about the challenges of adopting him, given the unusual circumstances. Therefore, option A is a more fitting caption.\n",
            "\n",
            "Option B doesn't seem to fit as there's no mention of credit cards\n",
            "Row 25: Predicted - A, Correct - B, Running Accuracy: 28.00%, Running F1 Score: 0.2632\n",
            "Number of Input Tokens:   338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: outside\n",
            "    Description: A woman is being attacked by human-sized mosquitoes. A man stares at her. They are outside.\n",
            "    Uncanny Aspect: There are gigantic mosquitoes carrying the woman away. Mosquitoes are tiny in real life.\n",
            "    Question: ['Why are the mosquitoes so huge?']\n",
            "    Additional Details: scene: outside description: A woman is being attacked by human-sized mosquitoes. A man stares at her. They are outside. uncanny: There are gigantic mosquitoes carrying the woman away. Mosquitoes are tiny in real life. entities: Mosquito, Kidnapping. choices: A: Is this your first visit to Minnesota? B: You HAD to ask, \"What else could go wrong?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Is this your first visit to Minnesota?\n",
            "B: You HAD to ask, \"What else could go wrong?\n",
            "\n",
            "Caption = [/INST] Based on the provided description and uncanny aspect, the best caption would be:\n",
            "\n",
            "B: You HAD to ask, \"What else could go wrong?\"\n",
            "\n",
            "This is because the unusual and unexpected event of giant mosquitoes carrying off a woman is more in line with the sarcastic and unexpected tone of a New Yorker cartoon, and the question in B acknowledges the absurdity of the situation.\n",
            "\n",
            "Captions that make direct reference to Minnesota, such\n",
            "Row 26: Predicted - B, Correct - A, Running Accuracy: 26.92%, Running F1 Score: 0.2476\n",
            "Number of Input Tokens:   315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: on the floor\n",
            "    Description: There is a disassembled maze. Two mice are perusing the instructions.\n",
            "    Uncanny Aspect: Mice are going to build a maze.\n",
            "    Question: ['Why are they building it?']\n",
            "    Additional Details: scene: on the floor description: There is a disassembled maze. Two mice are perusing the instructions. uncanny: Mice are going to build a maze. entities: Maze, Ready-to-assemble_furniture, Mouse. choices: A: Look, it's right here - \"cheese sold separately\" B: They haven't even built it and we came.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Look, it's right here - \"cheese sold separately\"\n",
            "B: They haven't even built it and we came.\n",
            "\n",
            "Caption = [/INST] Based on the New Yorker cartoon description provided, the best caption is:\n",
            "\n",
            "B: They haven't even built it and we came.\n",
            "\n",
            "Explanation:\n",
            "The cartoon description indicates that the mice are perusing the instructions for a disassembled maze on the floor. Given the context of the scene, it is unlikely that they have built the maze yet since they are still looking at the instructions. The additional details do not provide any information about\n",
            "Row 27: Predicted - B, Correct - A, Running Accuracy: 25.93%, Running F1 Score: 0.2335\n",
            "Number of Input Tokens:   344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: living room\n",
            "    Description: A woman with a large burlap bag on her shoulder leaves a room full of goats. There is a man with a goat on his lap who looks shocked.\n",
            "    Uncanny Aspect: It is unusual for someone to have so many goats in their house.\n",
            "    Question: ['Why is the lady leaving the man with so many goats?']\n",
            "    Additional Details: scene: living room description: A woman with a large burlap bag on her shoulder leaves a room full of goats. There is a man with a goat on his lap who looks shocked. uncanny: It is unusual for someone to have so many goats in their house. entities: Goat, Animal_control_service. choices: A: Come sweater season, you'll be back! B: Can I have custody of little Billy?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Come sweater season, you'll be back!\n",
            "B: Can I have custody of little Billy?\n",
            "\n",
            "Caption = [/INST] Based on the information provided, it is not clear why the woman is leaving the man with the goats. The description mentions that it is unusual for someone to have so many goats in their house, but it does not give any indication of why the woman might be taking the goats with her.\n",
            "\n",
            "Additionally, the question asks \"Why is the lady leaving the man with so many goats?\" The choices provided do not answer this question, as neither option implies that the woman\n",
            "Row 28: Predicted - B, Correct - A, Running Accuracy: 25.00%, Running F1 Score: 0.2207\n",
            "Number of Input Tokens:   427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a yoga studio\n",
            "    Description: A man and woman are standing facing one another (mirrored) inside of a yoga studio. The man looks upset at what the woman is telling him. The man is carrying a living room rug and the woman is carrying a yoga mat.\n",
            "    Uncanny Aspect: It's typical to use a yoga mat in a yoga studio so it's unusual to see someone trying to use a living room heavy rug as their yoga mat.\n",
            "    Question: ['Why is the man trying to use a living room rug instead of a yoga mat?']\n",
            "    Additional Details: scene: a yoga studio description: A man and woman are standing facing one another (mirrored) inside of a yoga studio. The man looks upset at what the woman is telling him. The man is carrying a living room rug and the woman is carrying a yoga mat. uncanny: It's typical to use a yoga mat in a yoga studio so it's unusual to see someone trying to use a living room heavy rug as their yoga mat. entities: Carpet, Yoga_mat. choices: A: 'Abdullah's is one floor up.' B: Sorry, sir. We don't allow...hats.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: 'Abdullah's is one floor up.'\n",
            "B: Sorry, sir. We don't allow...hats.\n",
            "\n",
            "Caption = [/INST] Based on the provided cartoon description and uncanny aspect, neither of the given captions (A or B) fit the scene. The correct caption should explain why the man is trying to use a living room rug instead of a yoga mat. Here is a suggested caption:\n",
            "\n",
            "Caption: 'He read in an ancient text that only on this exact rug could one find ultimate enlightenment.'</s>\n",
            "Row 29: Predicted - B, Correct - B, Running Accuracy: 27.59%, Running F1 Score: 0.2438\n",
            "Number of Input Tokens:   339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the north pole\n",
            "    Description: There is a sleigh on a snowfield. Reindeer are riding in it while Santa is pulling it.\n",
            "    Uncanny Aspect: It's a reversal from the usual, where the reindeer pull Santa.\n",
            "    Question: ['Have the reindeer rebelled?']\n",
            "    Additional Details: scene: the north pole description: There is a sleigh on a snowfield. Reindeer are riding in it while Santa is pulling it. uncanny: It's a reversal from the usual, where the reindeer pull Santa. entities: Role_reversal, Santa_Claus, Reindeer. choices: A: Our contract has a subordinate Claus. B: He lost the bet: Venice *is* north of Toronto.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Our contract has a subordinate Claus.\n",
            "B: He lost the bet: Venice *is* north of Toronto.\n",
            "\n",
            "Caption = [/INST] Based on the descriptions provided, the best caption for the cartoon is A: \"Our contract has a subordinate Claus.\" This preserves the theme of the role reversal in the cartoon, while B is unrelated to the scene and entities in the description.</s>\n",
            "Row 30: Predicted - B, Correct - A, Running Accuracy: 26.67%, Running F1 Score: 0.2311\n",
            "Number of Input Tokens:   333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an office\n",
            "    Description: A giant chicken is in an office near computers. It is on a huge nest. People are working at computers around it.\n",
            "    Uncanny Aspect: There is a giant chicken in the office on a nest.\n",
            "    Question: ['Why is there a huge chicken in the office?']\n",
            "    Additional Details: scene: an office description: A giant chicken is in an office near computers. It is on a huge nest. People are working at computers around it. uncanny: There is a giant chicken in the office on a nest. entities: Cubicle, Chicken, Nest. choices: A: We'll need to verify you're free range, also. B: I can remember when she was just a fuzzy yellow intern.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: We'll need to verify you're free range, also.\n",
            "B: I can remember when she was just a fuzzy yellow intern.\n",
            "\n",
            "Caption = [/INST] A: We'll need to verify you're free range, also.\n",
            "\n",
            "Explanation: The description states that there is a giant chicken in the office on a nest, which is an uncanny aspect that adds to the surprise and potential humor of the cartoon. The choice \"A: We'll need to verify you're free range, also\" plays off the uncanny aspect by incorporating a common phrase related to chickens and farms, and can add to the\n",
            "Row 31: Predicted - A, Correct - B, Running Accuracy: 25.81%, Running F1 Score: 0.2295\n",
            "Number of Input Tokens:   398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a gas station\n",
            "    Description: In front of a gas station there is a gas station employee holding up a dip stick while talking to a lady. They are both standing in front of a giant hotdog shaped and painted vehicle. The employee is talking while the vehicle owner listens.\n",
            "    Uncanny Aspect: It is unusual that a vehicle would have the shape and color of a hotdog.\n",
            "    Question: ['What is the employee saying?']\n",
            "    Additional Details: scene: a gas station description: In front of a gas station there is a gas station employee holding up a dip stick while talking to a lady. They are both standing in front of a giant hotdog shaped and painted vehicle. The employee is talking while the vehicle owner listens. uncanny: It is unusual that a vehicle would have the shape and color of a hotdog. entities: Wienermobile, Customer. choices: A: For this model I suggest using high grade premium extra virgin olive oil. B: You can use the loaner corn dog while you wait. Can you drive a stick?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: For this model I suggest using high grade premium extra virgin olive oil.\n",
            "B: You can use the loaner corn dog while you wait. Can you drive a stick?\n",
            "\n",
            "Caption = [/INST] Based on the given description and the uncanny aspect of the hotdog-shaped vehicle, option B seems more fitting as the employee's statement. The reason being that hotdogs are often associated with food, and it is more logical for the employee to offer a loaner hotdog or corn dog while the vehicle is being serviced. The first option, suggesting using high-grade olive oil for the vehicle, is less likely given the context provided.</s>\n",
            "Row 32: Predicted - B, Correct - B, Running Accuracy: 28.12%, Running F1 Score: 0.2505\n",
            "Number of Input Tokens:   304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: stage\n",
            "    Description: A magician is putting a paper into a shredder. It is being held by his assistant.\n",
            "    Uncanny Aspect: The magician is doing a commonplace task.\n",
            "    Question: ['What is he shredding?']\n",
            "    Additional Details: scene: stage description: A magician is putting a paper into a shredder. It is being held by his assistant. uncanny: The magician is doing a commonplace task. entities: Paper_shredder, Magic_(illusion). choices: A: Here's a trick I learned from my lawyer. B: Observe. Collusion. No collusion.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Here's a trick I learned from my lawyer.\n",
            "B: Observe. Collusion. No collusion.\n",
            "\n",
            "Caption = [/INST] Based on the given description and the uncanny aspect of the magician doing a commonplace task, neither caption A nor caption B directly relates to the cartoon. The cartoon does not provide any indication of a lawyer or collusion being involved.\n",
            "\n",
            "Therefore, neither A nor B is the best caption for this cartoon. A more fitting caption could be something like \"Mind-Boggling Paper Destruction Trick\" or \"Puzzling Paper\n",
            "Row 33: Predicted - B, Correct - A, Running Accuracy: 27.27%, Running F1 Score: 0.2385\n",
            "Number of Input Tokens:   341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the sea\n",
            "    Description: Two sharks are facing each other in the ocean. One shark has a retail store wardrobe dummy in its mouth while the other watches.\n",
            "    Uncanny Aspect: It is unusual for a shark to have a wardrobe dummy in its mouth.\n",
            "    Question: ['Why does the shark have a dummy in its mouth.', 'What is the other shark who is watching thinking?']\n",
            "    Additional Details: scene: the sea description: Two sharks are facing each other in the ocean. One shark has a retail store wardrobe dummy in its mouth while the other watches. uncanny: It is unusual for a shark to have a wardrobe dummy in its mouth. entities: Shark, Mannequin. choices: A: You're both dummies! B: It's low cal...no dressing.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You're both dummies!\n",
            "B: It's low cal...no dressing.\n",
            "\n",
            "Caption = [/INST] Based on the descriptions provided above, the best caption is B: \"It's low cal...no dressing.\" This caption maintains the lighthearted, humorous tone of The New Yorker and plays off the unexpected sight of a shark with a mannequin in its mouth, making it a fitting caption for the cartoon. The use of the \"low cal\" reference to the mannequin is a witty take on the common dieting expression and adds to\n",
            "Row 34: Predicted - B, Correct - A, Running Accuracy: 26.47%, Running F1 Score: 0.2275\n",
            "Number of Input Tokens:   317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: Art Gallery\n",
            "    Description: A chef is barbecuing in the middle of a museum. A boy is waiting on his burger, and a curator is yelling.\n",
            "    Uncanny Aspect: You can't have grills in a museum.\n",
            "    Question: ['What is he cooking?']\n",
            "    Additional Details: scene: Art Gallery description: A chef is barbecuing in the middle of a museum. A boy is waiting on his burger, and a curator is yelling. uncanny: You can't have grills in a museum. entities: Grill, Art_critic. choices: A: We sold the backyard to save the business. B: You are under the wrong impression, sir.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: We sold the backyard to save the business.\n",
            "B: You are under the wrong impression, sir.\n",
            "\n",
            "Caption = [/INST] Based on the information provided, the most fitting caption would be:\n",
            "\n",
            "B: You are under the wrong impression, sir.\n",
            "\n",
            "Explanation:\n",
            "The scene describes a chef barbecuing in a museum, which is an uncanny situation as grills are not allowed in museums. Therefore, the chef's statement in choice A implies they have a backyard for barbecuing, which is not mentioned in the description. Instead, the scene suggests that the chef is\n",
            "Row 35: Predicted - B, Correct - B, Running Accuracy: 28.57%, Running F1 Score: 0.2463\n",
            "Number of Input Tokens:   388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an office room\n",
            "    Description: Two men are seated on opposite sides of a desk in a cubicle.  Behind them several other men are wielding weapons and chasing a man fleeing from them\n",
            "    Uncanny Aspect: It's unusual to see office workers brandishing weapons and chasing someone\n",
            "    Question: ['What did the running man do?']\n",
            "    Additional Details: scene: an office room description: Two men are seated on opposite sides of a desk in a cubicle. Behind them several other men are wielding weapons and chasing a man fleeing from them uncanny: It's unusual to see office workers brandishing weapons and chasing someone entities: Mobbing, Meeting. choices: A: Just remember to keep away from Fletcher's wife, and Davidson's daughter, and Harris's iPod. B: Yes, I do believe we have an opening in the Marketing Department. Are you interested?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Just remember to keep away from Fletcher's wife, and Davidson's daughter, and Harris's iPod.\n",
            "B: Yes, I do believe we have an opening in the Marketing Department. Are you interested?\n",
            "\n",
            "Caption = [/INST] Based on the descriptions provided, the best caption for the given New Yorker cartoon would be A: \"Just remember to keep away from Fletcher's wife, and Davidson's daughter, and Harris's iPod.\" This caption fits the cartoon description better as it addresses the unusual situation of office workers brandishing weapons and chasing someone, creating a scene of chaos and mobbing, whereas option B seems irrelevant and unrelated to the scene.</s>\n",
            "Row 36: Predicted - B, Correct - A, Running Accuracy: 27.78%, Running F1 Score: 0.2354\n",
            "Number of Input Tokens:   486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a meeting room\n",
            "    Description: Four people and three robots are gathered around a meeting table in an office. A vote is taking place: three robots and one human are voting yes on the proposition. The boss is mad at the person who is voting yes.\n",
            "    Uncanny Aspect: Robots generally don't hold positions on company boards, so, the fact that they are voting evokes the notion of robot takeovers. The single person voting yes is betraying the other humans, which is why the boss is mad at him.\n",
            "    Question: ['Why is the person voting yes, agreeing with the robots and not the humans?', 'Why are the robots trying to take over the company?']\n",
            "    Additional Details: scene: a meeting room description: Four people and three robots are gathered around a meeting table in an office. A vote is taking place: three robots and one human are voting yes on the proposition. The boss is mad at the person who is voting yes. uncanny: Robots generally don't hold positions on company boards, so, the fact that they are voting evokes the notion of robot takeovers. The single person voting yes is betraying the other humans, which is why the boss is mad at him. entities: AI_takeover, Robot. choices: A: Jenkins, if I want another yes-man I'll build one. B: Johnson, nobody cares if _you_ can pass the Turing test.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Jenkins, if I want another yes-man I'll build one.\n",
            "B: Johnson, nobody cares if _you_ can pass the Turing test.\n",
            "\n",
            "Caption = [/INST] Based on the descriptions provided above, I would choose A: \"Jenkins, if I want another yes-man I'll build one.\" This caption fits the context of the cartoon as it refers to the person betraying the other humans by siding with the robots. The boss's frustration and the uncanny aspect of robots holding positions in a company also support this choice. The other caption, while technically true (robots don't care about passing the\n",
            "Row 37: Predicted - B, Correct - A, Running Accuracy: 27.03%, Running F1 Score: 0.2252\n",
            "Number of Input Tokens:   325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: lawn\n",
            "    Description: A man is lounging on a chair in his front yard with a woman in front of him. There is a bus in his driveway with his campaign advertisement on it.\n",
            "    Uncanny Aspect: Most people wouldn't have a bus in their driveway.\n",
            "    Question: ['Is the politician driving his own bus?']\n",
            "    Additional Details: scene: lawn description: A man is lounging on a chair in his front yard with a woman in front of him. There is a bus in his driveway with his campaign advertisement on it. uncanny: Most people wouldn't have a bus in their driveway. entities: Election, Tour_bus_service. choices: A: Your constituent called. B: Ever heard of life imitating art?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Your constituent called.\n",
            "B: Ever heard of life imitating art?\n",
            "\n",
            "Caption = [/INST] Based on the description provided, the best caption for the cartoon is:\n",
            "\n",
            "B: Ever heard of life imitating art?\n",
            "\n",
            "Explanation:\n",
            "The cartoon describes an unusual scene where a man has a bus in his driveway, which is uncanny as most people wouldn't have such a thing. The questioning aspect of the scenario further suggests that this is an extraordinary situation. The option B provides a witty and intriguing response that connects the unusual\n",
            "Row 38: Predicted - B, Correct - A, Running Accuracy: 26.32%, Running F1 Score: 0.2158\n",
            "Number of Input Tokens:   392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a marriage counselor's office\n",
            "    Description: A man is sitting at a desk opposite a couple.  To the man's left is what appears to be a aquarium\n",
            "    Uncanny Aspect: It's unusual to see a large aquarium in an office setting\n",
            "    Question: ['What is that aquarium doing there?']\n",
            "    Additional Details: scene: a marriage counselor's office description: A man is sitting at a desk opposite a couple. To the man's left is what appears to be a aquarium uncanny: It's unusual to see a large aquarium in an office setting entities: Aquarium, Divorce. choices: A: And if you'll agree to drop the divorce proceedings and reconcile I'll throw in a pair of lobsters. B: You'll find that a couple of hours in the Cool Whip vat will make you see things in a whole new light.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: And if you'll agree to drop the divorce proceedings and reconcile I'll throw in a pair of lobsters.\n",
            "B: You'll find that a couple of hours in the Cool Whip vat will make you see things in a whole new light.\n",
            "\n",
            "Caption = [/INST] A: And if you'll agree to drop the divorce proceedings and reconcile I'll throw in a pair of lobsters.\n",
            "\n",
            "Explanation: The presence of an aquarium in a marriage counselor's office is an uncanny aspect that may intrigue the question \"What is that aquarium doing there?\" The caption option A directly addresses the question and provides a plausible explanation for the aquarium's presence by relating it to a possible solution in the context\n",
            "Row 39: Predicted - A, Correct - A, Running Accuracy: 28.21%, Running F1 Score: 0.2449\n",
            "Number of Input Tokens:   330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a restaurant\n",
            "    Description: A man is sitting at the table in a restaurant reading a menu. A waiter is chatting with him and getting his order.\n",
            "    Uncanny Aspect: The menu is gigantic.\n",
            "    Question: ['Why is the menu so big?']\n",
            "    Additional Details: scene: a restaurant description: A man is sitting at the table in a restaurant reading a menu. A waiter is chatting with him and getting his order. uncanny: The menu is gigantic. entities: Menu, Waiting_staff. choices: A: The Executive Order requires us to make everyone's hands look small. B: If you'd like, I can have the sommelier drag over the wine list.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: The Executive Order requires us to make everyone's hands look small.\n",
            "B: If you'd like, I can have the sommelier drag over the wine list.\n",
            "\n",
            "Caption = [/INST] B: If you'd like, I can have the sommelier drag over the wine list.\n",
            "\n",
            "Explanation:\n",
            "The given description mentions that the menu is gigantic, but it does not imply any executive order or hand size reference. Therefore, the first option A is not the best fit. Option B is a plausible response from a waiter in a fancy restaurant and fits well with the given description.</s>\n",
            "Row 40: Predicted - B, Correct - B, Running Accuracy: 30.00%, Running F1 Score: 0.2602\n",
            "Number of Input Tokens:   341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: hamster cage\n",
            "    Description: A mouse is conducting a hamster wheel experiment with other mice. The mouse is also talking to a turtle .\n",
            "    Uncanny Aspect: Mice do not conduct experiments. Mice are known to be tested on.\n",
            "    Question: ['Why is the mouse conducting the experiment?']\n",
            "    Additional Details: scene: hamster cage description: A mouse is conducting a hamster wheel experiment with other mice. The mouse is also talking to a turtle . uncanny: Mice do not conduct experiments. Mice are known to be tested on. entities: Hamster_wheel, Turtle. choices: A: Well for starters, you were 4 days late to the interview. B: As mentioned, we're transitioning to a hybrid model.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Well for starters, you were 4 days late to the interview.\n",
            "B: As mentioned, we're transitioning to a hybrid model.\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description and the uncanny aspect, neither of the given captions seem to fit. Since mice do not conduct experiments on other mice, the first caption seems unlikely. The second caption mentions a \"hybrid model,\" which has no connection to the given description or uncanny aspect.\n",
            "\n",
            "Therefore, none of the provided captions would be the best fit for this cartoon description. We cannot determine the reason why the mouse\n",
            "Row 41: Predicted - B, Correct - A, Running Accuracy: 29.27%, Running F1 Score: 0.2509\n",
            "Number of Input Tokens:   445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a grocery store\n",
            "    Description: Two customers are shopping at a supermarket. They're pushing carts and chatting.\n",
            "    Uncanny Aspect: One of the customers is a whale, which shouldn't be out of the water, much less pushing a shopping cart. The other appears to be Amish, and his people don't shop at modern stores. He also has a peg leg.\n",
            "    Question: ['What happened to his leg?', 'What does an Amish person say to a whale?']\n",
            "    Additional Details: scene: a grocery store description: Two customers are shopping at a supermarket. They're pushing carts and chatting. uncanny: One of the customers is a whale, which shouldn't be out of the water, much less pushing a shopping cart. The other appears to be Amish, and his people don't shop at modern stores. He also has a peg leg. entities: Moby-Dick, Captain_Ahab. choices: A: Oh I'm sorry, maybe I'd move faster if SOMEONE didn't bite my leg off. B: After having 'caught' his white whale, Ahab quickly settled into domesticity.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Oh I'm sorry, maybe I'd move faster if SOMEONE didn't bite my leg off.\n",
            "B: After having 'caught' his white whale, Ahab quickly settled into domesticity.\n",
            "\n",
            "Caption = [/INST] A. \"What happened to his leg?\" is the more appropriate question given the description, so the whale's explanation about someone biting his leg is a better fit than the Amish man making a comment about Ahab's 'caught' white whale. Therefore, the best caption is A.</s>\n",
            "Row 42: Predicted - A, Correct - A, Running Accuracy: 30.95%, Running F1 Score: 0.2765\n",
            "Number of Input Tokens:   373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a building\n",
            "    Description: A lady is standing on a bar with a drink in her hand and looking towards the man sitting nearby with worried look on his face. There is a huge face behind the bar counter of a guy with facial hair.\n",
            "    Uncanny Aspect: Waiter's 10 times larger face behind the bar counter is unsusual.\n",
            "    Question: ['Why is the waiter so big?']\n",
            "    Additional Details: scene: a building description: A lady is standing on a bar with a drink in her hand and looking towards the man sitting nearby with worried look on his face. There is a huge face behind the bar counter of a guy with facial hair. uncanny: Waiter's 10 times larger face behind the bar counter is unsusual. entities: Giant, Liquor. choices: A: You think this is awkward? Try living a few floors down. B: The parade has gotten awfully personalized this year.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You think this is awkward? Try living a few floors down.\n",
            "B: The parade has gotten awfully personalized this year.\n",
            "\n",
            "Caption = [/INST] Based on the given description and the uncanny aspect of the cartoon, the best caption for this cartoon would be:\n",
            "\n",
            "A: You think this is awkward? Try living a few floors down.\n",
            "\n",
            "This caption plays off the unexpected size of the waiter's face, which is the uncanny aspect of the cartoon, and adds to the humor by implying that there may be even more unusual things in the building. It also fits well with the overall mood\n",
            "Row 43: Predicted - B, Correct - A, Running Accuracy: 30.23%, Running F1 Score: 0.2678\n",
            "Number of Input Tokens:   340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the road\n",
            "    Description: Two people are riding bikes in the city. A man is wearing a knight's costume. A woman stares at him.\n",
            "    Uncanny Aspect: A man on a bike is dressed as a knight.\n",
            "    Question: ['Why is there a knight on a bike in modern times?']\n",
            "    Additional Details: scene: the road description: Two people are riding bikes in the city. A man is wearing a knight's costume. A woman stares at him. uncanny: A man on a bike is dressed as a knight. entities: Cycling, Armour, Helmet. choices: A: It's the swimming portion that I am most concerned with. B: Let's just make it past the Renaissance festival, okay?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It's the swimming portion that I am most concerned with.\n",
            "B: Let's just make it past the Renaissance festival, okay?\n",
            "\n",
            "Caption = [/INST] Based on the description provided, the best caption would be B: \"Let's just make it past the Renaissance festival, okay?\"\n",
            "\n",
            "The reason for this is that the context of the situation in the cartoon description does not provide enough information to support the first caption option. The man dressed as a knight on a bike in modern times is an unusual sight, and the phrase \"swimming portion\" in option A does not make sense in relation to the scene.\n",
            "Row 44: Predicted - B, Correct - A, Running Accuracy: 29.55%, Running F1 Score: 0.2595\n",
            "Number of Input Tokens:   338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: doctor's office\n",
            "    Description: A man is in the doctor's office sitting on the patient's bed. the doctor happily talks to the man who has leaves growing out of him.\n",
            "    Uncanny Aspect: there is no known disease where leaves grow out of someone.\n",
            "    Question: ['Why are there leaves growing out of the man?']\n",
            "    Additional Details: scene: doctor's office description: A man is in the doctor's office sitting on the patient's bed. the doctor happily talks to the man who has leaves growing out of him. uncanny: there is no known disease where leaves grow out of someone. entities: Patient, Rare_disease. choices: A: So when you fell did it make a sound? B: Are you here for your annual or your perennial?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: So when you fell did it make a sound?\n",
            "B: Are you here for your annual or your perennial?\n",
            "\n",
            "Caption = [/INST] Given the description and the uncanny aspect of the situation, option B: \"Are you here for your annual or your perennial?\" would be the more appropriate and humorous caption for the cartoon. This option plays on the word \"perennial,\" which refers to something that lasts for a long time, and in this context, it humorously refers to the leaves growing out of the man. Option A, \"So when you fell did it make a sound?\" does not fit the\n",
            "Row 45: Predicted - No valid prediction found, Correct - B, Running Accuracy: 28.89%, Running F1 Score: 0.2593\n",
            "Number of Input Tokens:   327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an antique store\n",
            "    Description: Some customers are browsing at a china shop. There is a bull behind a counter examining a cup.\n",
            "    Uncanny Aspect: There is a bull who is either looking at china or works there and is ringing someone up.\n",
            "    Question: ['Why is there a bull in a china shop?']\n",
            "    Additional Details: scene: an antique store description: Some customers are browsing at a china shop. There is a bull behind a counter examining a cup. uncanny: There is a bull who is either looking at china or works there and is ringing someone up. entities: Porcelain, Bull. choices: A: I tend to complicate simple things. B: He came in with the coup last week.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I tend to complicate simple things.\n",
            "B: He came in with the coup last week.\n",
            "\n",
            "Caption = [/INST] Based on the provided cartoon description and uncanny aspect, neither caption A nor caption B directly relate to the scene. The cartoon description and uncanny aspect suggest that the bull is either a customer or an employee in a china shop, but they do not indicate any complications or coups. Therefore, neither caption A nor caption B is the best option.\n",
            "\n",
            "It would be best to come up with a new caption that directly relates to the scene and\n",
            "Row 46: Predicted - B, Correct - A, Running Accuracy: 28.26%, Running F1 Score: 0.2515\n",
            "Number of Input Tokens:   362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a courtroom\n",
            "    Description: A judge is presiding over a courtroom. There is a lawyer questioning a teddy bear in a witness box.\n",
            "    Uncanny Aspect: There is a teddy bear in the witness box. Inanimate objects can't give testimony.\n",
            "    Question: ['Why is the bear in the witness box?']\n",
            "    Additional Details: scene: a courtroom description: A judge is presiding over a courtroom. There is a lawyer questioning a teddy bear in a witness box. uncanny: There is a teddy bear in the witness box. Inanimate objects can't give testimony. entities: Testimony, Teddy_bear. choices: A: And at what point did they threaten to beat the stuffing out of you? B: Ah, I was wondering what my secretary meant by 'barely legal'.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: And at what point did they threaten to beat the stuffing out of you?\n",
            "B: Ah, I was wondering what my secretary meant by 'barely legal'.\n",
            "\n",
            "Caption = [/INST] Given the information provided, it is clear that the uncanny aspect of the cartoon is the presence of a teddy bear in the witness box, which is an inanimate object and cannot give testimony. Therefore, neither of the provided captions logically fits the scene. The correct answer should reflect the absurdity or humor of the situation, given that a bear is testifying in a courtroom.\n",
            "\n",
            "Based on the spirit of the cartoon and the information provided, Option A\n",
            "Row 47: Predicted - No valid prediction found, Correct - A, Running Accuracy: 27.66%, Running F1 Score: 0.2471\n",
            "Number of Input Tokens:   360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: downtown city\n",
            "    Description: A giant, monstrous snail is attacking a city. A doctor and police officer are bystanders of the situation. The police officer uses his binoculars to see the snail.\n",
            "    Uncanny Aspect: Giant snails that size do not exist and snails do not attack cities.\n",
            "    Question: ['Why is there a snail attacking the city?']\n",
            "    Additional Details: scene: downtown city description: A giant, monstrous snail is attacking a city. A doctor and police officer are bystanders of the situation. The police officer uses his binoculars to see the snail. uncanny: Giant snails that size do not exist and snails do not attack cities. entities: Snail, Physician. choices: A: Every brewery in town is involved in the response. B: I told you we should have salted the roads.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Every brewery in town is involved in the response.\n",
            "B: I told you we should have salted the roads.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and uncanny aspect provided, neither caption A nor caption B is a good fit for the situation described. The cartoon describes a giant, monstrous snail attacking a city, which is an uncanny and unrealistic scenario. The scene includes a doctor and police officer viewing the situation as bystanders. The captions provided, however, do not relate to the giant snail or the city under attack. Instead, they reference breweries and\n",
            "Row 48: Predicted - B, Correct - B, Running Accuracy: 29.17%, Running F1 Score: 0.2595\n",
            "Number of Input Tokens:   347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: living room\n",
            "    Description: A group of men are watching a football game while someone is havign therapy in the background. The person having therapy is a woman who seems upset.\n",
            "    Uncanny Aspect: People do not have therapy while others are watching a game in the same room.\n",
            "    Question: ['Why is she having therapy in a living room?']\n",
            "    Additional Details: scene: living room description: A group of men are watching a football game while someone is havign therapy in the background. The person having therapy is a woman who seems upset. uncanny: People do not have therapy while others are watching a game in the same room. entities: Psychoanalysis, Fan_(person)#Sports. choices: A: I'd like to try group therapy with a different group. B: See?! He always does this at fourth and long!\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I'd like to try group therapy with a different group.\n",
            "B: See?! He always does this at fourth and long!\n",
            "\n",
            "Caption = [/INST] Based on the information provided, the caption that is least unusual or incongruous with the scene is A: \"I'd like to try group therapy with a different group.\" This caption does not directly address the presence of therapy in a living room with a football game taking place, but it does not conflict with the situation in any way either. The situation itself, having therapy in a living room while others are watching a game, is already an unusual and potentially uncanny situation. Therefore\n",
            "Row 49: Predicted - B, Correct - A, Running Accuracy: 28.57%, Running F1 Score: 0.2520\n",
            "Number of Input Tokens:   471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: kitchen\n",
            "    Description: In a kitchen there is a little boy holding a Genie's lamp who is looking up at a Genie. But the Genie isn't appearing from the lamp. Instead, the Genie is coming out of a toaster on the kitchen counter and he is now talking to the little boy.\n",
            "    Uncanny Aspect: It is unusual for a Genie to be coming out of a toaster.\n",
            "    Question: ['Why is the Genie coming out of a toaster?', 'What is the Genie saying?']\n",
            "    Additional Details: scene: kitchen description: In a kitchen there is a little boy holding a Genie's lamp who is looking up at a Genie. But the Genie isn't appearing from the lamp. Instead, the Genie is coming out of a toaster on the kitchen counter and he is now talking to the little boy. uncanny: It is unusual for a Genie to be coming out of a toaster. entities: Jinn, Toaster. choices: A: To change settings on the lamp, just click the switch one time to the left from \"waffles\" to \"wishes.\" B: I went ahead and fixed the bagel setting, too. So with parts and labor, that actually comes out to two wishes.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: To change settings on the lamp, just click the switch one time to the left from \"waffles\" to \"wishes.\"\n",
            "B: I went ahead and fixed the bagel setting, too. So with parts and labor, that actually comes out to two wishes.\n",
            "\n",
            "Caption = [/INST] A: To change settings on the lamp, just click the switch one time to the left from \"waffles\" to \"wishes.\" (This caption fits well with the uncanny situation of a Genie coming out of a toaster and could potentially be a humorous take on technology malfunctions or misconceptions about how to use a Genie's lamp.)</s>\n",
            "Row 50: Predicted - A, Correct - B, Running Accuracy: 28.00%, Running F1 Score: 0.2499\n",
            "Number of Input Tokens:   411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: talkshow\n",
            "    Description: A woman is sitting on recliner speaking to a man wearing a suit, sitting behind a desk. There is a microphone on the desk and two cameras pointed at them, implying this is a talk show. Behind the people are two windows showing a city scape, with bars over the windows.\n",
            "    Uncanny Aspect: It's unusual to see bars over windows looking out over the city on TV.\n",
            "    Question: ['Why are there metal bars over the windows?']\n",
            "    Additional Details: scene: talkshow description: A woman is sitting on recliner speaking to a man wearing a suit, sitting behind a desk. There is a microphone on the desk and two cameras pointed at them, implying this is a talk show. Behind the people are two windows showing a city scape, with bars over the windows. uncanny: It's unusual to see bars over windows looking out over the city on TV. entities: Guest_appearance, Late-night_talk_show. choices: A: then i said to myself why do people even wear clothes anyway B: Both the movie and I will be released this summer.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: then i said to myself why do people even wear clothes anyway\n",
            "B: Both the movie and I will be released this summer.\n",
            "\n",
            "Caption = [/INST] A. \"then i said to myself why do people even wear clothes anyway\"\n",
            "\n",
            "Explanation:\n",
            "Given the description of the scene and the fact that it's a talk show, it's unlikely that the topic of conversation would be about a movie release. Therefore, option B does not fit the situation. Furthermore, the uncanny aspect of the cartoon is the presence of bars over the windows in a talk show setting, so a caption that addresses this element would\n",
            "Row 51: Predicted - A, Correct - B, Running Accuracy: 27.45%, Running F1 Score: 0.2477\n",
            "Number of Input Tokens:   443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an office room\n",
            "    Description: There are three people in an office. One man is the boss sitting behind his desk. There is a woman who is sitting on a mans back and riding him around the office like a horse. The man is running on the ground on all fours.\n",
            "    Uncanny Aspect: There is a woman riding a man in the office like he is a horse.\n",
            "    Question: ['Why is the man letting himself be treated like a horse?']\n",
            "    Additional Details: scene: an office room description: There are three people in an office. One man is the boss sitting behind his desk. There is a woman who is sitting on a mans back and riding him around the office like a horse. The man is running on the ground on all fours. uncanny: There is a woman riding a man in the office like he is a horse. entities: Piggyback_(transportation), White-collar_worker. choices: A: Ferguson, looks like the Cattlemen's Association account goes to Ms. Jameson. B: O.K., let's wrap up and call it a day. I feel like we're losing our focus.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Ferguson, looks like the Cattlemen's Association account goes to Ms. Jameson.\n",
            "B: O.K., let's wrap up and call it a day. I feel like we're losing our focus.\n",
            "\n",
            "Caption = [/INST] Based on the descriptions provided, it's clear that the scene in the cartoon is quite unusual and unexpected, with a woman riding a man like a horse. Therefore, neither of the given captions seems to fit the scene very well.\n",
            "\n",
            "However, if we have to choose between the two options given, Capeat A, \"Ferguson, looks like the Cattlemen's Association account goes to Ms. Jameson,\" is more likely to be related to the scene\n",
            "Row 52: Predicted - B, Correct - B, Running Accuracy: 28.85%, Running F1 Score: 0.2596\n",
            "Number of Input Tokens:   323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an interrogation room\n",
            "    Description: At a police station, two cops are questioning a shark. One of the cops is showing him a photo.\n",
            "    Uncanny Aspect: Sharks die when they're out of water.\n",
            "    Question: ['What did the shark do?']\n",
            "    Additional Details: scene: an interrogation room description: At a police station, two cops are questioning a shark. One of the cops is showing him a photo. uncanny: Sharks die when they're out of water. entities: Detective, Shark. choices: A: You are looking for a loan shark, not a lone shark. B: Can we make this quick? I gotta keep moving.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You are looking for a loan shark, not a lone shark.\n",
            "B: Can we make this quick? I gotta keep moving.\n",
            "\n",
            "Caption = [/INST] Based on the description provided and the given uncanny aspect (Sharks die when they're out of water), neither of the provided captions is directly related to the situation in the cartoon. Therefore, neither A nor B is the best caption choice. It's unlikely a shark would be found in an interrogation room or making a request for quickness when being questioned. There seems to be a misunderstanding as these captions don't fit the context given in the cart\n",
            "Row 53: Predicted - B, Correct - B, Running Accuracy: 30.19%, Running F1 Score: 0.2712\n",
            "Number of Input Tokens:   350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a ledge of a building\n",
            "    Description: There are two people looking at a menu on a balcony. A waiter is looking outside a window talking to them.\n",
            "    Uncanny Aspect: There are two people having dinner on a balcony, which is dangerous.\n",
            "    Question: [\"Why are the people on a balcony that doesn't seem to support them?\"]\n",
            "    Additional Details: scene: a ledge of a building description: There are two people looking at a menu on a balcony. A waiter is looking outside a window talking to them. uncanny: There are two people having dinner on a balcony, which is dangerous. entities: Waiting_staff, Menu. choices: A: I recommend the pigeon. It's locally sourced. B: Momento mori, momento mori, momento mori...\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I recommend the pigeon. It's locally sourced.\n",
            "B: Momento mori, momento mori, momento mori...\n",
            "\n",
            "Caption = [/INST] Based on the description provided, none of the given captions are the best fit. The description mentions a waiter talking to the people on the balcony, but the captions provided do not reference the waiter or his dialogue. Additionally, neither caption directly addresses the uncanny or dangerous aspect of the situation - the people having dinner on a potentially unsafe balcony. The description raises the question of why the people are on the balcony that doesn't seem to support them, but\n",
            "Row 54: Predicted - B, Correct - A, Running Accuracy: 29.63%, Running F1 Score: 0.2639\n",
            "Number of Input Tokens:   375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: in the sky\n",
            "    Description: Two pilots are navigating a plane through the sky. Another man is standing on a cloud, trying to hitch a ride.\n",
            "    Uncanny Aspect: Clouds are not solid and can't be stood on. Hitchhikers are always on the ground, and they can't get that high up in the air.\n",
            "    Question: ['Is that hitchhiker real or a hallucination?']\n",
            "    Additional Details: scene: in the sky description: Two pilots are navigating a plane through the sky. Another man is standing on a cloud, trying to hitch a ride. uncanny: Clouds are not solid and can't be stood on. Hitchhikers are always on the ground, and they can't get that high up in the air. entities: Airplane, Hitchhiking. choices: A: OK, but he is going to have to check that bag. B: I never download anything from the cloud.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: OK, but he is going to have to check that bag.\n",
            "B: I never download anything from the cloud.\n",
            "\n",
            "Caption = [/INST] Based on the description provided, neither caption A nor caption B are ideal as they do not correlate with the scene and characters depicted in the cartoon. Given the scene's context, a suitable caption could be something like, \"Looks like we have a stowaway!\" or \"Strange things happen at this altitude.\" This new caption fits the situation and provides a humorous take on the unusual occurrence in the cartoon.\n",
            "\n",
            "If we must choose\n",
            "Row 55: Predicted - B, Correct - A, Running Accuracy: 29.09%, Running F1 Score: 0.2569\n",
            "Number of Input Tokens:   333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an empty room\n",
            "    Description: Many clones of the same guy step out into the hallway from a room. A woman stands in shock as she uses her phone.\n",
            "    Uncanny Aspect: There are not this many identical people in the world. These are clones which do not exist.\n",
            "    Question: ['How did the man clone himself?']\n",
            "    Additional Details: scene: an empty room description: Many clones of the same guy step out into the hallway from a room. A woman stands in shock as she uses her phone. uncanny: There are not this many identical people in the world. These are clones which do not exist. entities: Human_cloning, Crowd. choices: A: We're going to need more diversity training. B: On second thought, bring the name tags.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: We're going to need more diversity training.\n",
            "B: On second thought, bring the name tags.\n",
            "\n",
            "Caption = [/INST] Based on the description provided, option A: \"We're going to need more diversity training\" would be the best caption. The shock and surprise on the woman's face suggests that she is not used to seeing so many identical people, and her statement on the phone implies that she may be reporting an unusual occurrence. The mention of diversity training in option A acknowledges the unusual nature of the situation and suggests that the clones are not part of the normal population. Option B:\n",
            "Row 56: Predicted - B, Correct - B, Running Accuracy: 30.36%, Running F1 Score: 0.2678\n",
            "Number of Input Tokens:   322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a butcher shop\n",
            "    Description: A woman is looking at a poster of dancers in a store. A clerk is watching her from behind a counter.\n",
            "    Uncanny Aspect: Everything is pretty ordinary here.\n",
            "    Question: ['What is the woman thinking?']\n",
            "    Additional Details: scene: a butcher shop description: A woman is looking at a poster of dancers in a store. A clerk is watching her from behind a counter. uncanny: Everything is pretty ordinary here. entities: Can-can, Leg. choices: A: It's been just one big celebration ever since the election. B: It's not disturbing until someone wants to buy them by the ounce.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It's been just one big celebration ever since the election.\n",
            "B: It's not disturbing until someone wants to buy them by the ounce.\n",
            "\n",
            "Caption = [/INST] Based on the information provided, the ordinary setting and the woman's action of looking at the dancers poster suggest that she might be daydreaming or reminiscing, rather than having any explicit thoughts related to the election or buying items by the ounce. Therefore, the caption that fits best with the given scenario is B: \"It's not disturbing until someone wants to buy them by the ounce.\" Since the described scene does not indicate any connection to an election or\n",
            "Row 57: Predicted - B, Correct - B, Running Accuracy: 31.58%, Running F1 Score: 0.2784\n",
            "Number of Input Tokens:   335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: bedroom\n",
            "    Description: A couple is in bed with a shady looking man. The man is talking to the wife. The other man is wearing a coat and hat.\n",
            "    Uncanny Aspect: There is a man with a coat and hat on in bed with two other people.\n",
            "    Question: [\"Why is this man in the couple's bed?\"]\n",
            "    Additional Details: scene: bedroom description: A couple is in bed with a shady looking man. The man is talking to the wife. The other man is wearing a coat and hat. uncanny: There is a man with a coat and hat on in bed with two other people. entities: Stranger, Marriage. choices: A: I'll take it from here, Marlowe. B: We didn't sign the privacy agreement.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I'll take it from here, Marlowe.\n",
            "B: We didn't sign the privacy agreement.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and the uncanny aspect given, the most plausible caption would be \"B: We didn't sign the privacy agreement.\"\n",
            "\n",
            "The description mentions that the man's behavior is shady, and the fact that he is wearing a coat and hat in bed with a couple is an unusual and unexpected sight. The caption choice \"A: I'll take it from here, Marlowe\" does not make much sense in this context\n",
            "Row 58: Predicted - B, Correct - A, Running Accuracy: 31.03%, Running F1 Score: 0.2713\n",
            "Number of Input Tokens:   418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a grocery store\n",
            "    Description: A man dressed like an Amish person is pushing a shopping cart around in a grocery store, shopping for groceries.  Behind him stands a whal, doing the same thing.\n",
            "    Uncanny Aspect: It's unusual to see a man in amish clothing shopping in a supermarket, and it's considerably more unusual to see a giant whale shopping for groceries\n",
            "    Question: ['Why is there a whale shopping for groceries?']\n",
            "    Additional Details: scene: a grocery store description: A man dressed like an Amish person is pushing a shopping cart around in a grocery store, shopping for groceries. Behind him stands a whal, doing the same thing. uncanny: It's unusual to see a man in amish clothing shopping in a supermarket, and it's considerably more unusual to see a giant whale shopping for groceries entities: Moby-Dick, Captain_Ahab. choices: A: I've got plenty of sperm. Just get me some Viagra. B: Oh, hey, I almost didn't recognize you outside of work.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I've got plenty of sperm. Just get me some Viagra.\n",
            "B: Oh, hey, I almost didn't recognize you outside of work.\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description, neither caption A nor caption B are directly related to the scene. While the cartoon description mentions the presence of a man dressed like an Amish person and a whale, there is no indication in the description or additional details that either character is connected to Moby-Dick or Captain Ahab. Additionally, neither caption references the grocery store setting or the unusual nature of a man in Amish clothing and a whale\n",
            "Row 59: Predicted - B, Correct - B, Running Accuracy: 32.20%, Running F1 Score: 0.2815\n",
            "Number of Input Tokens:   427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a beach\n",
            "    Description: A woman and a large shark are sitting on a desert island, while a man, presumably her husband, is off of the island in the water. The giant shark is looking at the man, as if it's defensively protecting the woman from him. The woman watches on nervously.\n",
            "    Uncanny Aspect: The shark being solely interested in the man is odd --- most sharks don't discriminate based on gender.\n",
            "    Question: ['Why is the shark trying to steal the woman from the man?']\n",
            "    Additional Details: scene: a beach description: A woman and a large shark are sitting on a desert island, while a man, presumably her husband, is off of the island in the water. The giant shark is looking at the man, as if it's defensively protecting the woman from him. The woman watches on nervously. uncanny: The shark being solely interested in the man is odd --- most sharks don't discriminate based on gender. entities: Shark, Guard, Infidelity. choices: A: Let’s ask him to stay for dinner. B: For the last time, no, I can't open cans.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Let’s ask him to stay for dinner.\n",
            "B: For the last time, no, I can't open cans.\n",
            "\n",
            "Caption = [/INST] This description and the given caption choices do not match well. The description suggests that the shark is protecting the woman, implying some sort of threat or danger to the woman from the man. None of the caption choices address this aspect of the cartoon. Therefore, neither A nor B is the best caption choice. Instead, a more fitting caption could be something like: \"At least I don't have to worry about him leaving with another woman.\" or \"I guess\n",
            "Row 60: Predicted - No valid prediction found, Correct - A, Running Accuracy: 31.67%, Running F1 Score: 0.2775\n",
            "Number of Input Tokens:   351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a ship\n",
            "    Description: A sailor hoists up multiple flags, each one showing an emoji. The other sailor looks on with a thoughtful look on his face.\n",
            "    Uncanny Aspect: Sailors in the navy do not use emojis as the design for their flags because it would look ridiculous.\n",
            "    Question: ['Why are their emojis on the flag?']\n",
            "    Additional Details: scene: a ship description: A sailor hoists up multiple flags, each one showing an emoji. The other sailor looks on with a thoughtful look on his face. uncanny: Sailors in the navy do not use emojis as the design for their flags because it would look ridiculous. entities: Flag, Emoji. choices: A: We've been struggling to enlist millenials. B: Midshipman Ebert liked the movie.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: We've been struggling to enlist millenials.\n",
            "B: Midshipman Ebert liked the movie.\n",
            "\n",
            "Caption = [/INST] Based on the information given in the cartoon description and the uncanny aspect, neither caption A nor B is the best choice. The cartoon description and the uncanny aspect do not provide enough information to suggest that millennials or a movie are related to the scene. Therefore, neither caption fits well with the provided information.\n",
            "\n",
            "The cartoon description and the uncanny aspect suggest that there is an incongruity in having emojis on flags on a ship. Since the\n",
            "Row 61: Predicted - B, Correct - A, Running Accuracy: 31.15%, Running F1 Score: 0.2706\n",
            "Number of Input Tokens:   345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: ocean\n",
            "    Description: Two sharks are facing each other in the ocean. One shark has a retail store wardrobe dummy in its mouth while the other watches.\n",
            "    Uncanny Aspect: It is unusual for a shark to have a wardrobe dummy in its mouth.\n",
            "    Question: ['Why does the shark have a dummy in its mouth.', 'What is the other shark who is watching thinking?']\n",
            "    Additional Details: scene: ocean description: Two sharks are facing each other in the ocean. One shark has a retail store wardrobe dummy in its mouth while the other watches. uncanny: It is unusual for a shark to have a wardrobe dummy in its mouth. entities: Shark, Mannequin. choices: A: A real person would be wiggling much more. B: The doctor said it might help me quit.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: A real person would be wiggling much more.\n",
            "B: The doctor said it might help me quit.\n",
            "\n",
            "Caption = [/INST] Based on the information given in the cartoon description and the caption choices, the best caption is A: \"A real person would be wiggling much more.\"\n",
            "\n",
            "The reason for this is that the cartoon description explicitly states that the shark with the mannequin in its mouth is unusual and that it has a mannequin, which is a large, inanimate object. The mannequin is depicted as being still and not moving or wiggling as a\n",
            "Row 62: Predicted - B, Correct - B, Running Accuracy: 32.26%, Running F1 Score: 0.2803\n",
            "Number of Input Tokens:   378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: downtown city\n",
            "    Description: A giant, monstrous snail is attacking a city. A doctor and police officer are bystanders of the situation. The police officer uses his binoculars to see the snail.\n",
            "    Uncanny Aspect: Giant snails that size do not exist and snails do not attack cities.\n",
            "    Question: ['Why is there a snail attacking the city?']\n",
            "    Additional Details: scene: downtown city description: A giant, monstrous snail is attacking a city. A doctor and police officer are bystanders of the situation. The police officer uses his binoculars to see the snail. uncanny: Giant snails that size do not exist and snails do not attack cities. entities: Snail, Physician. choices: A: If my calculations are correct, it should reach City Hall by June. B: If you turn the binoculars around, the problem pretty much goes away.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: If my calculations are correct, it should reach City Hall by June.\n",
            "B: If you turn the binoculars around, the problem pretty much goes away.\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description and the question given, the correct caption would be:\n",
            "\n",
            "B: \"If you turn the binoculars around, the problem pretty much goes away.\"\n",
            "\n",
            "The reason for this is that the description does not provide any information about the cause or reason behind the giant snail attacking the city. The only indications we have are that it is an uncanny and unlikely event. The choices provided do not align with what we know\n",
            "Row 63: Predicted - B, Correct - B, Running Accuracy: 33.33%, Running F1 Score: 0.2898\n",
            "Number of Input Tokens:   306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the living room\n",
            "    Description: A woman is sitting on her couch in fear. There is a baseball game going on in her living room.\n",
            "    Uncanny Aspect: There are baseball players playing ball in the house.\n",
            "    Question: [\"Why aren't the players outside?\"]\n",
            "    Additional Details: scene: the living room description: A woman is sitting on her couch in fear. There is a baseball game going on in her living room. uncanny: There are baseball players playing ball in the house. entities: Baseball, Telephone_call, Obliviousness. choices: A: All his pitches have been inside. B: They called it a Phase 1 trial.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: All his pitches have been inside.\n",
            "B: They called it a Phase 1 trial.\n",
            "\n",
            "Caption = [/INST] A: All his pitches have been inside.\n",
            "\n",
            "Explanation:\n",
            "The cartoon description mentions a baseball game is going on in the living room with baseball players playing inside the house, which is an uncanny situation. The caption option A directly relates to the unexpected behavior of the baseball players in the context of the cartoon description, making it a fitting choice. The option B, although unrelated to the cartoon description, is a possible caption for a different\n",
            "Row 64: Predicted - A, Correct - A, Running Accuracy: 34.38%, Running F1 Score: 0.3068\n",
            "Number of Input Tokens:   314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a living room\n",
            "    Description: Two women are sitting on a couch in a living room. A man is sitting nearby on top of an egg.\n",
            "    Uncanny Aspect: There is a huge egg being used as a chair.\n",
            "    Question: ['What is he trying to hatch?']\n",
            "    Additional Details: scene: a living room description: Two women are sitting on a couch in a living room. A man is sitting nearby on top of an egg. uncanny: There is a huge egg being used as a chair. entities: Egg, Chicken. choices: A: I'd hate to see the size of that chicken. B: But will he lift a finger after it hatches?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I'd hate to see the size of that chicken.\n",
            "B: But will he lift a finger after it hatches?\n",
            "\n",
            "Caption = [/INST] A: I'd hate to see the size of that chicken.\n",
            "\n",
            "Explanation:\n",
            "The description mentions that there is a huge egg being used as a chair, which is an uncanny and unexpected element in the scene. The caption \"I'd hate to see the size of that chicken\" plays off of this by making a joke about the potential size of the chicken that will eventually hatch from the egg. This option also correctly identifies the entities in the scene\n",
            "Row 65: Predicted - A, Correct - B, Running Accuracy: 33.85%, Running F1 Score: 0.3048\n",
            "Number of Input Tokens:   348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: cave\n",
            "    Description: Two cavepeople enter someone's cave to find the person attacked by a reptile. The reptile has its mouth around the person's ankle.\n",
            "    Uncanny Aspect: If someone was bitten by a reptile then they would be bleeding.\n",
            "    Question: ['Why did the reptile bite the man?']\n",
            "    Additional Details: scene: cave description: Two cavepeople enter someone's cave to find the person attacked by a reptile. The reptile has its mouth around the person's ankle. uncanny: If someone was bitten by a reptile then they would be bleeding. entities: Dinosaur, Caveman. choices: A: I wouldn't let him pose for the new mural. B: The doctor said it will eventually just go extinct.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I wouldn't let him pose for the new mural.\n",
            "B: The doctor said it will eventually just go extinct.\n",
            "\n",
            "Caption = [/INST] A: \"I wouldn't let him pose for the new mural with a reptile bite like that.\"\n",
            "\n",
            "Explanation:\n",
            "In this cartoon description, there is no information given that would suggest the reptile's behavior is natural or expected, such as it being sick or extinct. Additionally, the presence of cavepeople and the use of the phrase \"attacked by a reptile\" implies that something unusual or dangerous has occurred. The caption\n",
            "Row 66: Predicted - A, Correct - B, Running Accuracy: 33.33%, Running F1 Score: 0.3028\n",
            "Number of Input Tokens:   345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the living room\n",
            "    Description: A man and a woman are sitting on the sofa. The woman is upset because the living room is full of monkeys climbing around.\n",
            "    Uncanny Aspect: The room is full of monkeys which would cause a mess in the house.\n",
            "    Question: ['Why is the room full of monkeys?']\n",
            "    Additional Details: scene: the living room description: A man and a woman are sitting on the sofa. The woman is upset because the living room is full of monkeys climbing around. uncanny: The room is full of monkeys which would cause a mess in the house. entities: Monkey, Amazon_rainforest, Amazon_(company). choices: A: If you can meditate here you can meditate anywhere. B: Can we have one argument without you bringing up the monkeys?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: If you can meditate here you can meditate anywhere.\n",
            "B: Can we have one argument without you bringing up the monkeys?\n",
            "\n",
            "Caption = [/INST] Based on the description and choices provided, I would rank caption B as the best option. This is because the description mentions that \"The woman is upset because\" the living room is full of monkeys, implying that the man may be the cause of the monkeys being in the room. therefore, introducing this topic in an argument would be a common and realistic response. Additionally, the description does not provide any indication that the man and woman are practicing meditation. Therefore, option A,\n",
            "Row 67: Predicted - B, Correct - B, Running Accuracy: 34.33%, Running F1 Score: 0.3117\n",
            "Number of Input Tokens:   472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a dance studio\n",
            "    Description: A man and woman are dancing in a dance studio. They are holding hands (man's left/woman's right) and the man has his right hand on her waist and she has her left hand on his shoulder. The man's right leg is long and curling making the letter \"e\". The woman's expression is of enjoyment or fun.\n",
            "    Uncanny Aspect: While seeing two people dancing isn't unusual, seeing a person's leg curl around making the letter \"e\" and being extremely long (compared to the other leg) is unusual.\n",
            "    Question: [\"How is the man's leg curling around?\"]\n",
            "    Additional Details: scene: a dance studio description: A man and woman are dancing in a dance studio. They are holding hands (man's left/woman's right) and the man has his right hand on her waist and she has her left hand on his shoulder. The man's right leg is long and curling making the letter \"e\". The woman's expression is of enjoyment or fun. uncanny: While seeing two people dancing isn't unusual, seeing a person's leg curl around making the letter \"e\" and being extremely long (compared to the other leg) is unusual. entities: Two_Left_Feet, Dance. choices: A: Don’t worry, it gets easier. B: Ummm... can I lead this one?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Don’t worry, it gets easier.\n",
            "B: Ummm... can I lead this one?\n",
            "\n",
            "Caption = [/INST] A: Don’t worry, it gets easier.\n",
            "\n",
            "Explanation: Based on the information provided in the cartoon description and the given question, the man's leg curling around to form the letter \"e\" is an unusual sight in a dance studio. The additional details do not provide enough context to suggest that the man intends to lead the dance or that there is any confusion about who should lead. Therefore, the caption \"Don’t worry, it gets easier\n",
            "Row 68: Predicted - A, Correct - A, Running Accuracy: 35.29%, Running F1 Score: 0.3262\n",
            "Number of Input Tokens:   379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an office\n",
            "    Description: A man in a suit and tie is angrily cleaning the office window and the window cleaner is talking on the phone in the office. The roles seem to have reversed.\n",
            "    Uncanny Aspect: The man in the suit and tie usually is working in the office while the man in slacks cleans the windows.\n",
            "    Question: ['Why is the man in the suit cleaning the windows?']\n",
            "    Additional Details: scene: an office description: A man in a suit and tie is angrily cleaning the office window and the window cleaner is talking on the phone in the office. The roles seem to have reversed. uncanny: The man in the suit and tie usually is working in the office while the man in slacks cleans the windows. entities: Businessperson, Window_cleaner, Role_reversal. choices: A: I am telling you this guy is a micromanager. B: I don't think I could ever go back.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I am telling you this guy is a micromanager.\n",
            "B: I don't think I could ever go back.\n",
            "\n",
            "Caption = [/INST] Based on the information provided, the best caption is: A: \"I am telling you this guy is a micromanager.\"\n",
            "\n",
            "Explanation:\n",
            "The depiction of the man in a suit and tie angrily cleaning the windows while the window cleaner talks on the phone is unusual because in conventional situations, the man in a suit is the one who is supposed to be working in the office, while the window cleaner is the one who is supposed to be cleaning\n",
            "Row 69: Predicted - B, Correct - A, Running Accuracy: 34.78%, Running F1 Score: 0.3196\n",
            "Number of Input Tokens:   360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: road\n",
            "    Description: A car is driven on a road that is leading to a giant Planet Earth. There are clouds and mountains and houses in the background.\n",
            "    Uncanny Aspect: A huge replica of earth planet on the road is the unusual element.\n",
            "    Question: ['Why is the huge sphere that looks like planet earth on the road?']\n",
            "    Additional Details: scene: road description: A car is driven on a road that is leading to a giant Planet Earth. There are clouds and mountains and houses in the background. uncanny: A huge replica of earth planet on the road is the unusual element. entities: Car, Earth. choices: A: Honey, I told you the whole world is headed to the Cape this weekend. B: Gosh, the Tom-Tom really won't carry the weight that an atlas would.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Honey, I told you the whole world is headed to the Cape this weekend.\n",
            "B: Gosh, the Tom-Tom really won't carry the weight that an atlas would.\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description, the best caption would be: A: \"Honey, I told you the whole world is headed to the Cape this weekend.\"\n",
            "\n",
            "Explanation:\n",
            "The cartoon description mentions that there are houses in the background, which implies that there are people living there. The large Earth replica on the road could suggest a mass exodus of people traveling to a particular destination. The caption option A speaks directly to this\n",
            "Row 70: Predicted - B, Correct - A, Running Accuracy: 34.29%, Running F1 Score: 0.3132\n",
            "Number of Input Tokens:   449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the outside of a building\n",
            "    Description: There is a guru looking old man sitting Indian style on the ledge of a multi story building. Just beneath him is a climber with backpack and climbing gear who is climbing the building and hanging on to the guru's ledge. The guru is talking to the climber.\n",
            "    Uncanny Aspect: It is unusual for an old man to be sitting on the ledge of a building. It is also unusual for a climber to be climbing a building.\n",
            "    Question: ['Why is there an old man sitting on the ledge of a building?', 'What is the old man saying to the climber?']\n",
            "    Additional Details: scene: the outside of a building description: There is a guru looking old man sitting Indian style on the ledge of a multi story building. Just beneath him is a climber with backpack and climbing gear who is climbing the building and hanging on to the guru's ledge. The guru is talking to the climber. uncanny: It is unusual for an old man to be sitting on the ledge of a building. It is also unusual for a climber to be climbing a building. entities: God, Parkour. choices: A: They're downsizing on Olympus, too. B: The window cleaner brings a pastry.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: They're downsizing on Olympus, too.\n",
            "B: The window cleaner brings a pastry.\n",
            "\n",
            "Caption = [/INST] Based on the description provided, neither caption A nor caption B are suitable. The reason is that neither of these captions address the specific elements of the cartoon. \n",
            "\n",
            "The scene depicts an old guru sitting on a building ledge, and a climber attempting to climb the same building. The fact that the guru is an old man and the climber is climber are both considered uncanny. \n",
            "\n",
            "Caption A mentions \"Olympus,\"\n",
            "Row 71: Predicted - B, Correct - B, Running Accuracy: 35.21%, Running F1 Score: 0.3213\n",
            "Number of Input Tokens:   352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the beach\n",
            "    Description: A man is relaxing on a small island under a palm tree. Another man with tattered clothes and a briefcase stares at him.\n",
            "    Uncanny Aspect: There is a businessman on the island with tattered clothes while another man is just relaxing and looking fine.\n",
            "    Question: ['What happened to the man with tattered clothes?']\n",
            "    Additional Details: scene: the beach description: A man is relaxing on a small island under a palm tree. Another man with tattered clothes and a briefcase stares at him. uncanny: There is a businessman on the island with tattered clothes while another man is just relaxing and looking fine. entities: Coconut, Beach_furniture. choices: A: Thank you for agreeing to meet remotely. B: Technically, it's still a cannibal island.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Thank you for agreeing to meet remotely.\n",
            "B: Technically, it's still a cannibal island.\n",
            "\n",
            "Caption = [/INST] Based on the given cartoon description and the uncanny aspect, the caption \"B: Technically, it's still a cannibal island\" is the best fit. This caption plays on the unexpected juxtaposition of a businessman in tattered clothes on a seemingly deserted island, which could suggest a cannibalistic context. The other option, \"A: Thank you for agreeing to meet remotely,\" does not relate to the scene or the\n",
            "Row 72: Predicted - B, Correct - A, Running Accuracy: 34.72%, Running F1 Score: 0.3150\n",
            "Number of Input Tokens:   362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a small island\n",
            "    Description: A plumber approaches a small island with his tools. He is approaching a man who looks like he was stranded on the island.\n",
            "    Uncanny Aspect: there would be no need for someone to use plumbing while stranded on an island.\n",
            "    Question: ['Why did the plumber think he was needed?']\n",
            "    Additional Details: scene: a small island description: A plumber approaches a small island with his tools. He is approaching a man who looks like he was stranded on the island. uncanny: there would be no need for someone to use plumbing while stranded on an island. entities: Plumber, Wrench. choices: A: I'm sorry. I called the wrong number. I wanted a pizza delivered. B: Just once I'd like to hallucinate a guy who does air conditioning.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I'm sorry. I called the wrong number. I wanted a pizza delivered.\n",
            "B: Just once I'd like to hallucinate a guy who does air conditioning.\n",
            "\n",
            "Caption = [/INST] A. The description states that there is a man who looks like he was stranded on the island. It's unlikely that he would be hallucinating a plumber or an air conditioner repairman while stranded. The option A is the more likely explanation for why the plumber might be there.</s>\n",
            "Row 73: Predicted - A, Correct - B, Running Accuracy: 34.25%, Running F1 Score: 0.3129\n",
            "Number of Input Tokens:   418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a grocery store\n",
            "    Description: A man dressed like an Amish person is pushing a shopping cart around in a grocery store, shopping for groceries.  Behind him stands a whal, doing the same thing.\n",
            "    Uncanny Aspect: It's unusual to see a man in amish clothing shopping in a supermarket, and it's considerably more unusual to see a giant whale shopping for groceries\n",
            "    Question: ['Why is there a whale shopping for groceries?']\n",
            "    Additional Details: scene: a grocery store description: A man dressed like an Amish person is pushing a shopping cart around in a grocery store, shopping for groceries. Behind him stands a whal, doing the same thing. uncanny: It's unusual to see a man in amish clothing shopping in a supermarket, and it's considerably more unusual to see a giant whale shopping for groceries entities: Beluga_whale, Shopping_cart. choices: A: I've got plenty of sperm. Just get me some Viagra. B: Oh, hey, I almost didn't recognize you outside of work.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I've got plenty of sperm. Just get me some Viagra.\n",
            "B: Oh, hey, I almost didn't recognize you outside of work.\n",
            "\n",
            "Caption = [/INST] A. \"I've got plenty of sperm. Just get me some Viagra.\" (This caption acknowledges the unusual nature of the scene by incorporating the element of the Amish man, while also providing a humorous twist with the reference to Viagra, which is a distinctly human concern.)</s>\n",
            "Row 74: Predicted - A, Correct - B, Running Accuracy: 33.78%, Running F1 Score: 0.3109\n",
            "Number of Input Tokens:   351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a field\n",
            "    Description: An archer is aiming at a girl. The girl has a cherry on her head. They are in the mountains.\n",
            "    Uncanny Aspect: The girl has a cherry on her head, not an apple, so it's hard to shoot without killing her.\n",
            "    Question: ['Why does the girl have a cherry on her head?']\n",
            "    Additional Details: scene: a field description: An archer is aiming at a girl. The girl has a cherry on her head. They are in the mountains. uncanny: The girl has a cherry on her head, not an apple, so it's hard to shoot without killing her. entities: Archery, Target_practice. choices: A: I now see why you only get me every other weekend. B: This might be above your pay grade, Dad.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I now see why you only get me every other weekend.\n",
            "B: This might be above your pay grade, Dad.\n",
            "\n",
            "Caption = [/INST] A: I now see why you only get me every other weekend. (The description mentions nothing about the archer being a father, but the unusual target makes the task more difficult and seems like an intentional challenge, which could explain why the archer may only get to hit the target every other weekend.)</s>\n",
            "Row 75: Predicted - A, Correct - A, Running Accuracy: 34.67%, Running F1 Score: 0.3237\n",
            "Number of Input Tokens:   369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a building\n",
            "    Description: A lady is standing on a bar with a drink in her hand and looking towards the man sitting nearby with worried look on his face. There is a huge face behind the bar counter of a guy with facial hair.\n",
            "    Uncanny Aspect: Waiter's 10 times larger face behind the bar counter is unsusual.\n",
            "    Question: ['Why is the waiter so big?']\n",
            "    Additional Details: scene: a building description: A lady is standing on a bar with a drink in her hand and looking towards the man sitting nearby with worried look on his face. There is a huge face behind the bar counter of a guy with facial hair. uncanny: Waiter's 10 times larger face behind the bar counter is unsusual. entities: Giant, Liquor. choices: A: I always knew you had an inflated ego. B: How much did you spend at Macy's this year?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I always knew you had an inflated ego.\n",
            "B: How much did you spend at Macy's this year?\n",
            "\n",
            "Caption = [/INST] Based on the information provided, the best caption for the cartoon description would be:\n",
            "\n",
            "A. \"I always knew you had an inflated ego.\"\n",
            "\n",
            "The cartoon description does not mention anything about the size of the man or his spending habits at Macy's, but it does mention the giant, unusual size of the waiter's face. The caption choice A is a humorous comment on the man's perceived ego, which fits well with the visual\n",
            "Row 76: Predicted - B, Correct - B, Running Accuracy: 35.53%, Running F1 Score: 0.3313\n",
            "Number of Input Tokens:   334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the middle of a desert\n",
            "    Description: Two cowboys on horses are inspecting a scene. There is a modern stove and some pots and pans on the ground near a bonfire.\n",
            "    Uncanny Aspect: There are modern things in the scene meant for kitchens near the fire.\n",
            "    Question: ['Why are there modern things in the scene?']\n",
            "    Additional Details: scene: the middle of a desert description: Two cowboys on horses are inspecting a scene. There is a modern stove and some pots and pans on the ground near a bonfire. uncanny: There are modern things in the scene meant for kitchens near the fire. entities: Cowboy, Espresso_machine. choices: A: Maybe we should have just stayed home. B: I knew I heard espresso shots.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Maybe we should have just stayed home.\n",
            "B: I knew I heard espresso shots.\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description and the uncanny aspect of modern kitchen appliances in the desert scene, I would go with option B: \"I knew I heard espresso shots.\" This caption plays up the unexpected or unusual nature of the modern kitchen appliances in the scene and adds a humor element to it. The cowboys' conversation about espresso shots adds to the unexpectedness of the situation and further emphasizes the uncanny aspect of the scene.\n",
            "\n",
            "Row 77: Predicted - B, Correct - B, Running Accuracy: 36.36%, Running F1 Score: 0.3388\n",
            "Number of Input Tokens:   313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a swimming pool\n",
            "    Description: A huge sea dragon is in the pool. A couple is relaxing in the pool and on the side.\n",
            "    Uncanny Aspect: There is a sea dragon in the pool. They are imaginary and usually would be in oceans in fables.\n",
            "    Question: ['Why is there a sea dragon in the pool?']\n",
            "    Additional Details: scene: a swimming pool description: A huge sea dragon is in the pool. A couple is relaxing in the pool and on the side. uncanny: There is a sea dragon in the pool. They are imaginary and usually would be in oceans in fables. entities: Dragon, Leisure. choices: A: Your tattoo escaped. B: Do you think he sees us?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Your tattoo escaped.\n",
            "B: Do you think he sees us?\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description and the uncanny aspect of a sea dragon being in a swimming pool, neither of the given captions directly addresses the presence of the sea dragon in the pool. Therefore, neither A nor B are definitively the best option. However, if we were to make an educated guess based on the common themes of New Yorker cartoons, we might lean towards option B: \"Do you think he sees us?\" as it touches upon the element of\n",
            "Row 78: Predicted - B, Correct - A, Running Accuracy: 35.90%, Running F1 Score: 0.3328\n",
            "Number of Input Tokens:   326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a royal chamber\n",
            "    Description: There is a huge sword or knife above the king hanging from a string. A king sits there in his throne while a court reader reads a scroll.\n",
            "    Uncanny Aspect: There is a huge sword above the king. It could easily fall on him.\n",
            "    Question: ['Why is the sword so huge?']\n",
            "    Additional Details: scene: a royal chamber description: There is a huge sword or knife above the king hanging from a string. A king sits there in his throne while a court reader reads a scroll. uncanny: There is a huge sword above the king. It could easily fall on him. entities: Dagger, King. choices: A: Now is the winter of our discontent... B: And the king lived happily severed after.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Now is the winter of our discontent...\n",
            "B: And the king lived happily severed after.\n",
            "\n",
            "Caption = [/INST] A: Now is the winter of our discontent...\n",
            "\n",
            "Explanation:\n",
            "\n",
            "The description mentions that there is a huge sword or knife above the king, which creates an uncanny and threatening atmosphere. The question asks why the sword is so huge, and choice A references William Shakespeare's \"Richard III,\" where the character famously says, \"Now is the winter of our discontent.\" This caption fits well with the description and adds an ominous tone that\n",
            "Row 79: Predicted - A, Correct - B, Running Accuracy: 35.44%, Running F1 Score: 0.3305\n",
            "Number of Input Tokens:   347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: airplane\n",
            "    Description: This is a plane full of people. A baker is tossing a pizza on the plane. The woman next to him looks puzzled.\n",
            "    Uncanny Aspect: There is a baker on the plane tossing a pizza.\n",
            "    Question: ['Why is the baker tossing a pizza on the plane?']\n",
            "    Additional Details: scene: airplane description: This is a plane full of people. A baker is tossing a pizza on the plane. The woman next to him looks puzzled. uncanny: There is a baker on the plane tossing a pizza. entities: Pizza, Chef. choices: A: You can either complain about airline food or do something about it B: I've found that using this venue results in some interesting new toppings.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You can either complain about airline food or do something about it\n",
            "B: I've found that using this venue results in some interesting new toppings.\n",
            "\n",
            "Caption = [/INST] Based on the given description, Capion B: \"I've found that using this venue results in some interesting new toppings.\" is more fitting for the situation in the cartoon. The context does not suggest that the baker is unhappy with the airline food or trying to alleviate others' complaints. Instead, it seems more likely that he is intrigued by the unique culinary possibilities afforded by cooking in an airplane setting.</s>\n",
            "Row 80: Predicted - B, Correct - A, Running Accuracy: 35.00%, Running F1 Score: 0.3247\n",
            "Number of Input Tokens:   362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an office room\n",
            "    Description: A man's head is coming out of a desk. The desk is of the boss of a company. He is talking to it.\n",
            "    Uncanny Aspect: There is a head coming out of a desk.\n",
            "    Question: ['Why is there a head coming out of a desk?']\n",
            "    Additional Details: scene: an office room description: A man's head is coming out of a desk. The desk is of the boss of a company. He is talking to it. uncanny: There is a head coming out of a desk. entities: Decapitation, Evaluation. choices: A: It's Broadcasting 101. We're Network. Talking Heads are CABLE. B: I'm sorry I couldn't get more for you in the divorce settlement.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It's Broadcasting 101. We're Network. Talking Heads are CABLE.\n",
            "B: I'm sorry I couldn't get more for you in the divorce settlement.\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description, neither caption A nor cable B explicitly answers the question of \"Why is there a head coming out of a desk?\" However, caption A does make an indirect reference to the head being a part of a broadcasting company, which could be an explanation for the uncanny occurrence. Therefore, while not a perfect match, caption A is a more reasonable guess than caption B, which seems unrelated to the given scene.\n",
            "Row 81: Predicted - B, Correct - B, Running Accuracy: 35.80%, Running F1 Score: 0.3319\n",
            "Number of Input Tokens:   413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a bedroom\n",
            "    Description: A couple are lying on a bed together.  The man is dressed in sporting equipment.  The woman is wearing a dress and has a hairband with some fuzzy-tipped antennae attached\n",
            "    Uncanny Aspect: It's unusual for a man to be lying in bed dressed in sporting equipment\n",
            "    Question: ['Why is that man dressed like that?']\n",
            "    Additional Details: scene: a bedroom description: A couple are lying on a bed together. The man is dressed in sporting equipment. The woman is wearing a dress and has a hairband with some fuzzy-tipped antennae attached uncanny: It's unusual for a man to be lying in bed dressed in sporting equipment entities: Foreplay, Sports_equipment. choices: A: With the score tied love to love, Henry suddenly found himself inches away from the goal line. B: Okay. Now you be the naughty mosquito, and I'll be the tormented sporting goods salesman.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: With the score tied love to love, Henry suddenly found himself inches away from the goal line.\n",
            "B: Okay. Now you be the naughty mosquito, and I'll be the tormented sporting goods salesman.\n",
            "\n",
            "Caption = [/INST] Based on the given cartoon description, the best caption would be A: \"With the score tied love to love, Henry suddenly found himself inches away from the goal line.\" This caption fits well with the description as it explains the man's behavior in the unusual setting of lying in bed dressed in sporting equipment, suggesting a metaphorical comparison to a competitive game or race in the context of their relationship. The second caption, while creative and funny, does not directly connect to\n",
            "Row 82: Predicted - B, Correct - B, Running Accuracy: 36.59%, Running F1 Score: 0.3389\n",
            "Number of Input Tokens:   349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a living roo\n",
            "    Description: A man is standing next to the table and calling someone on the phone. Man looks concerned and there is a knife stabbed on this back with couple pieces of paper.\n",
            "    Uncanny Aspect: Man taking on the phone with a knife stabbed on this back is unusual.\n",
            "    Question: ['Why did someone stab the knife on his back?']\n",
            "    Additional Details: scene: a living roo description: A man is standing next to the table and calling someone on the phone. Man looks concerned and there is a knife stabbed on this back with couple pieces of paper. uncanny: Man taking on the phone with a knife stabbed on this back is unusual. entities: Telephone_call, Betrayal. choices: A: Yes, I got the invitation to my funeral. B: 'Sharply worded' would describe it.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Yes, I got the invitation to my funeral.\n",
            "B: 'Sharply worded' would describe it.\n",
            "\n",
            "Caption = [/INST] A.\n",
            "\n",
            "The description mentions that the man looks concerned and there are papers with the knife, suggesting that this may be in response to news of his own death or impending betrayal. The first caption option, \"Yes, I got the invitation to my funeral,\" is a humorous but plausible way for the man to react to such news, implying that he had been expecting it or even planning for it. The second caption option, \"Sharply word\n",
            "Row 83: Predicted - A, Correct - B, Running Accuracy: 36.14%, Running F1 Score: 0.3368\n",
            "Number of Input Tokens:   297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a desert\n",
            "    Description: A man is crawling through the desert. Another man is attempting to paddle a boat through the sand.\n",
            "    Uncanny Aspect: A rowboat shouldn't be in the middle of the desert.\n",
            "    Question: ['Why is he trying to row?']\n",
            "    Additional Details: scene: a desert description: A man is crawling through the desert. Another man is attempting to paddle a boat through the sand. uncanny: A rowboat shouldn't be in the middle of the desert. entities: Rowing, Thirst. choices: A: Your form is all wrong. B: Noah, trust me. Its over.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Your form is all wrong.\n",
            "B: Noah, trust me. Its over.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and the given caption choices, the best caption would be:\n",
            "\n",
            "A: \"Your form is all wrong.\"\n",
            "\n",
            "Although both captions are humorous, option A directly addresses the unusual scene in the cartoon - a man attempting to row a boat in the desert. Option B, while funny, does not link directly to the visual elements presented in the cartoon. Therefore, option A is the more appropriate choice.\n",
            "\n",
            "So, the\n",
            "Row 84: Predicted - B, Correct - B, Running Accuracy: 36.90%, Running F1 Score: 0.3438\n",
            "Number of Input Tokens:   366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: conference\n",
            "    Description: A man is having a TED talk. He is literally pointing to a picture of Ted, which is him dressed up in women's clothes. People are staring at him.\n",
            "    Uncanny Aspect: The man is dressed in women's clothes.\n",
            "    Question: ['Why is the man dressed up as a woman on the picture on stage?']\n",
            "    Additional Details: scene: conference description: A man is having a TED talk. He is literally pointing to a picture of Ted, which is him dressed up in women's clothes. People are staring at him. uncanny: The man is dressed in women's clothes. entities: Ted_talk, Public_speaking. choices: A: My talk today is about why \"going viral\" isn't always a good idea. B: To illustrate how couples come to look alike, this is my wife.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: My talk today is about why \"going viral\" isn't always a good idea.\n",
            "B: To illustrate how couples come to look alike, this is my wife.\n",
            "\n",
            "Caption = [/INST] A. \"My talk today is about why 'going viral' isn't always a good idea.\"\n",
            "\n",
            "Explanation: The cartoon description mentions that the man is having a TED talk, which is a public speaking event where people share ideas, often on topics that are grounded in scientific or technological innovation. The fact that the man is pointing to a picture of himself dressed up as Ted and that people are staring at him suggests that the man's unusual appearance and\n",
            "Row 85: Predicted - A, Correct - B, Running Accuracy: 36.47%, Running F1 Score: 0.3417\n",
            "Number of Input Tokens:   312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a fish bowl\n",
            "    Description: Two people are inside of a fish bowl. They are working like they are in an office.\n",
            "    Uncanny Aspect: People are too small to be in a fishbowl.\n",
            "    Question: ['Why are they in a fish bowl?']\n",
            "    Additional Details: scene: a fish bowl description: Two people are inside of a fish bowl. They are working like they are in an office. uncanny: People are too small to be in a fishbowl. entities: White-collar_worker, Personal_computer. choices: A: Some guys never make it out of the plastic bag. B: You'd think they could just monitor our computers.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Some guys never make it out of the plastic bag.\n",
            "B: You'd think they could just monitor our computers.\n",
            "\n",
            "Caption = [/INST] Based on the provided description, the best caption for this New Yorker cartoon would be:\n",
            "\n",
            "A: Some guys never make it out of the plastic bag.\n",
            "\n",
            "The reason for this is that the description explicitly states that the people are \"too small to be in a fishbowl,\" which makes it clear that they are contained in a confined space. The caption option A plays off this uncanny aspect by suggesting that these people are stuck or trapped, much like a\n",
            "Row 86: Predicted - B, Correct - A, Running Accuracy: 36.05%, Running F1 Score: 0.3360\n",
            "Number of Input Tokens:   337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the kitchen\n",
            "    Description: A couple is looking at various traps set out in the kitchen. There are bear traps on the floor, spikes, and the fridge is chained up.\n",
            "    Uncanny Aspect: Everything in the kitchen is booby-trapped or locked.\n",
            "    Question: ['Why is everyone in the kitchen booby-trapped and locked up?']\n",
            "    Additional Details: scene: the kitchen description: A couple is looking at various traps set out in the kitchen. There are bear traps on the floor, spikes, and the fridge is chained up. uncanny: Everything in the kitchen is booby-trapped or locked. entities: Trapping, Refrigerator. choices: A: Damn. Now I'm kinda hungry. B: I've never been hungrier\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Damn. Now I'm kinda hungry.\n",
            "B: I've never been hungrier\n",
            "\n",
            "Caption = [/INST] Based on the description provided, the best caption would be A: \"Damn. Now I'm kinda hungry.\" The reason for this is that the couple is simply looking at the traps in the kitchen, indicating that they may have set them up for protection or amusement rather than actually intending to use them as food traps. Therefore, it is more likely that they are still planning to cook and eat food in the kitchen, despite the traps. The caption \"I\n",
            "Row 87: Predicted - B, Correct - A, Running Accuracy: 35.63%, Running F1 Score: 0.3305\n",
            "Number of Input Tokens:   378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a restaurant\n",
            "    Description: There is a man carrying a garbage can in a restaurant. He is bringing it to a table with another waiter, who is talking to some customers.\n",
            "    Uncanny Aspect: A waiter is carrying a garbage can to a table at a restaurant?\n",
            "    Question: ['Why is the waiter bringing a garbage can to the table in the restaurant?']\n",
            "    Additional Details: scene: a restaurant description: There is a man carrying a garbage can in a restaurant. He is bringing it to a table with another waiter, who is talking to some customers. uncanny: A waiter is carrying a garbage can to a table at a restaurant? entities: Waste_container, Waiting_staff. choices: A: I'm sorry, sir, but we do reserve the right to serve refuse to anyone. B: You've heard of farm-to-table? We also offer table to landfill.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I'm sorry, sir, but we do reserve the right to serve refuse to anyone.\n",
            "B: You've heard of farm-to-table? We also offer table to landfill.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and the given caption choices, option B: \"You've heard of farm-to-table? We also offer table to landfill.\" is the best match. The scene shows a waiter bringing a garbage can to a table, which is an unusual and unexpected event in a restaurant setting, making the uncanny aspect and the playful tone of choice B fitting. Additionally, this answer plays with the current food trends, such as farm-to-table\n",
            "Row 88: Predicted - B, Correct - A, Running Accuracy: 35.23%, Running F1 Score: 0.3252\n",
            "Number of Input Tokens:   313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an empty room\n",
            "    Description: There are a bunch of men that look identical coming into a room. A woman is on the phone staring at them.\n",
            "    Uncanny Aspect: All the men look the same. This is not possible.\n",
            "    Question: ['Why are all the men exactly the same?']\n",
            "    Additional Details: scene: an empty room description: There are a bunch of men that look identical coming into a room. A woman is on the phone staring at them. uncanny: All the men look the same. This is not possible. entities: Human_cloning, Crowd. choices: A: We're going to need more diversity training. B: On second thought, bring the name tags.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: We're going to need more diversity training.\n",
            "B: On second thought, bring the name tags.\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description provided, the best caption is:\n",
            "\n",
            "A: We're going to need more diversity training.\n",
            "\n",
            "The reason for this is that the fact that all the men look the same is described as \"unusual\" or \"uncanny,\" and the woman's reaction to this, as well as the context of the scene, suggests that this is an issue that needs to be addressed. The phrase \"diversity training\" is a common term\n",
            "Row 89: Predicted - B, Correct - B, Running Accuracy: 35.96%, Running F1 Score: 0.3318\n",
            "Number of Input Tokens:   341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: an airplane\n",
            "    Description: Superman is on the plane with regular citizens. There is a man sitting beside him and they give each other a glance.\n",
            "    Uncanny Aspect: Superman is known to fly. He usually does not need airplanes to travel.\n",
            "    Question: ['Why is Superman taking the plane?']\n",
            "    Additional Details: scene: an airplane description: Superman is on the plane with regular citizens. There is a man sitting beside him and they give each other a glance. uncanny: Superman is known to fly. He usually does not need airplanes to travel. entities: Superman, Airline_seat. choices: A: I feel like we've gotten a little soft, Lex. B: I am searching for a city that still has phone booths.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I feel like we've gotten a little soft, Lex.\n",
            "B: I am searching for a city that still has phone booths.\n",
            "\n",
            "Caption = [/INST] A: I feel like we've gotten a little soft, Lex.\n",
            "\n",
            "Explanation:\n",
            "The cartoon description suggests that Superman is taking a plane ride with regular citizens, which is an unusual behavior for him since he has the ability to fly. The caption option A fits well with the scene as it could imply that Superman is taking the plane trip to blend in with the normal population and feel more connected with humanity. The other option B seems less relevant to the situation\n",
            "Row 90: Predicted - A, Correct - A, Running Accuracy: 36.67%, Running F1 Score: 0.3421\n",
            "Number of Input Tokens:   284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a music studio\n",
            "    Description: A bunch of animals are singing and playing instruments. A man and woman are controlling the sound.\n",
            "    Uncanny Aspect: Pets cannot sing or play instruments.\n",
            "    Question: ['Why are there cats, dogs, and fish singing and playing instruments?']\n",
            "    Additional Details: scene: a music studio description: A bunch of animals are singing and playing instruments. A man and woman are controlling the sound. uncanny: Pets cannot sing or play instruments. entities: Cat, Dog. choices: A: It's a motley crew. B: Less woofer?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: It's a motley crew.\n",
            "B: Less woofer?\n",
            "\n",
            "Caption = [/INST] A: It's a motley crew.\n",
            "\n",
            "Explanation:\n",
            "\n",
            "The description indicates that there are animals singing and playing instruments in a music studio, with a man and woman controlling the sound. While it is uncanny that pets, such as cats and dogs, cannot sing or play instruments in real life, the cartoon depiction of these animals engaging in this human activity is a common trope in animation and art. The term \"motley crew\" is an appropriate and\n",
            "Row 91: Predicted - A, Correct - B, Running Accuracy: 36.26%, Running F1 Score: 0.3400\n",
            "Number of Input Tokens:   318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: living room\n",
            "    Description: A man is sitting in a living room with a bunch of goats. A woman has packed her bags and is leaving.\n",
            "    Uncanny Aspect: Goats don't belong inside the house.\n",
            "    Question: ['Why are there so many goats in the house?']\n",
            "    Additional Details: scene: living room description: A man is sitting in a living room with a bunch of goats. A woman has packed her bags and is leaving. uncanny: Goats don't belong inside the house. entities: Goat, Animal_control_service. choices: A: Could you bring me back a goat? B: I know, I know. It's for the kids.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Could you bring me back a goat?\n",
            "B: I know, I know. It's for the kids.\n",
            "\n",
            "Caption = [/INST] Based on the given description and uncanny aspect, neither caption A nor caption B seems to match the scene perfectly. However, caption B is more plausible as an explanation for having goats in a living room. Goats are often associated with children due to farm visits or pets. Therefore, I would rank caption B as the best option for this New Yorker cartoon description. However, the absence of any mention of kids or the reason for the woman's departure\n",
            "Row 92: Predicted - B, Correct - A, Running Accuracy: 35.87%, Running F1 Score: 0.3348\n",
            "Number of Input Tokens:   446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a tree\n",
            "    Description: Tarzan and his wife, Jane, are on some branches in a vine-covered tree. Jane is pregnant and seated, while tarzan has a knife on his waistbelt. They both look left towards something that isn't pictured.\n",
            "    Uncanny Aspect: The fact that they are both looking the same direction suggests that there is something they both see, but it's not clear what it is. Also, Jane's pregnancy suggests that they might be trying to protect her.\n",
            "    Question: [\"What are they looking at, and is it a threat to Jane's pregnancy?\"]\n",
            "    Additional Details: scene: a tree description: Tarzan and his wife, Jane, are on some branches in a vine-covered tree. Jane is pregnant and seated, while tarzan has a knife on his waistbelt. They both look left towards something that isn't pictured. uncanny: The fact that they are both looking the same direction suggests that there is something they both see, but it's not clear what it is. Also, Jane's pregnancy suggests that they might be trying to protect her. entities: Tarzan, Pregnancy. choices: A: Call the broker and lower the offer. B: Well, you'll be a monkey's uncle.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: Call the broker and lower the offer.\n",
            "B: Well, you'll be a monkey's uncle.\n",
            "\n",
            "Caption = [/INST] Based on the given description, neither of the provided captions is suitable. The description mentions that Tarzan and Jane are looking in the same direction towards something that isn't pictured, which suggests that there might be a threat to Jane's pregnancy. Neither of the provided captions addresses the potential threat or the fact that they are in a tree with Jane being pregnant. Therefore, neither A nor B is the best caption option.\n",
            "\n",
            "For a more fitting caption,\n",
            "Row 93: Predicted - B, Correct - B, Running Accuracy: 36.56%, Running F1 Score: 0.3411\n",
            "Number of Input Tokens:   418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: street\n",
            "    Description: There is an angel and a devil standing in front of a fender bender scene in a residential area. The devil has horns and a forked tail and is facing the angel who has a halo and wings. The angel is talking.\n",
            "    Uncanny Aspect: It is unusual for an angel or devil to be driving a car. It's also unusual for an angel and devil to be involved in the same car accident.\n",
            "    Question: ['Why are an angel and devil driving cars?', \"Who's fault was the accident?\"]\n",
            "    Additional Details: scene: street description: There is an angel and a devil standing in front of a fender bender scene in a residential area. The devil has horns and a forked tail and is facing the angel who has a halo and wings. The angel is talking. uncanny: It is unusual for an angel or devil to be driving a car. It's also unusual for an angel and devil to be involved in the same car accident. entities: Devil, Angel, Traffic_collision. choices: A: You’re supposed to be on the other shoulder. B: First hell froze over and now this...\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: You’re supposed to be on the other shoulder.\n",
            "B: First hell froze over and now this...\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and the uncanny aspect, I would choose option B: \"First hell froze over and now this...\"\n",
            "\n",
            "Explanation:\n",
            "The unconventional setting of an angel and a devil being in a residential area and involved in a car accident is quite unusual, and the cartoon description mentions it being \"uncanny\" that they are both driving cars. Option B acknowledges this unusual situation by referencing the saying \"first XYZ happened\n",
            "Row 94: Predicted - B, Correct - A, Running Accuracy: 36.17%, Running F1 Score: 0.3360\n",
            "Number of Input Tokens:   348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: doctor's office\n",
            "    Description: A doctor is taking notes from a shadow puppet. The shadow puppet is in the shape of a bunny rabbit.\n",
            "    Uncanny Aspect: Shadow puppets, unlike humans, cannot be seen for health reasons.\n",
            "    Question: ['Why is the doctor looking after a shadow puppet?']\n",
            "    Additional Details: scene: doctor's office description: A doctor is taking notes from a shadow puppet. The shadow puppet is in the shape of a bunny rabbit. uncanny: Shadow puppets, unlike humans, cannot be seen for health reasons. entities: Physical_examination, Shadow_play. choices: A: So, for the record, are you a duck or a rabbit? B: So Mr. Updike, what seems to be the problem?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: So, for the record, are you a duck or a rabbit?\n",
            "B: So Mr. Updike, what seems to be the problem?\n",
            "\n",
            "Caption = [/INST] A. \"So, for the record, are you a duck or a rabbit?\"\n",
            "\n",
            "Explanation:\n",
            "The description states that the doctor is taking notes from a shadow puppet in the shape of a bunny rabbit. Since shadow puppets are inanimate objects and cannot be seen for health reasons as per the uncanny aspect, it is unlikely that the doctor would be conducting a physical examination on a real patient named Mr. Updike, as suggested by c\n",
            "Row 95: Predicted - A, Correct - A, Running Accuracy: 36.84%, Running F1 Score: 0.3456\n",
            "Number of Input Tokens:   321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: backyard\n",
            "    Description: There is a huge beachball in a pool. People are outside in swimsuits looking at it.\n",
            "    Uncanny Aspect: There is a huge beach ball filling up an entire pool.\n",
            "    Question: ['Why is there a huge beachball in a pool?']\n",
            "    Additional Details: scene: backyard description: There is a huge beachball in a pool. People are outside in swimsuits looking at it. uncanny: There is a huge beach ball filling up an entire pool. entities: Swimming_pool, Beach_ball. choices: A: If size didn't matter we'd all be swimming. B: Can I borrow a safety pin for about 5 seconds?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: If size didn't matter we'd all be swimming.\n",
            "B: Can I borrow a safety pin for about 5 seconds?\n",
            "\n",
            "Caption = [/INST] A: If size didn't matter we'd all be swimming.\n",
            "\n",
            "Explanation: The scene description indicates that people are outside in swimsuits looking at the beachball in the pool. The uncanny aspect of the cartoon is that the beachball is so large that it is filling up the entire pool. The caption choice A \"If size didn't matter we'd all be swimming\" perfectly captures the essence of the scene by humorously commenting on\n",
            "Row 96: Predicted - A, Correct - A, Running Accuracy: 37.50%, Running F1 Score: 0.3549\n",
            "Number of Input Tokens:   396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a bedroom\n",
            "    Description: 6 people are all lying in one large bed facing a tv.  They all appear to be wearing glasses and staring straight forward, and the 2 people on either flank are wearing suits.\n",
            "    Uncanny Aspect: It's unusual to find 6 people sharing a bed, and it's unusual for people to lie in bed wearing a suit\n",
            "    Question: ['Why are all those people in the same bed?']\n",
            "    Additional Details: scene: a bedroom description: 6 people are all lying in one large bed facing a tv. They all appear to be wearing glasses and staring straight forward, and the 2 people on either flank are wearing suits. uncanny: It's unusual to find 6 people sharing a bed, and it's unusual for people to lie in bed wearing a suit entities: Divorce, Lawyer, Television. choices: A: I liked it better when we just had your people call my people. B: We're the only couple I know that has a board of trustees.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I liked it better when we just had your people call my people.\n",
            "B: We're the only couple I know that has a board of trustees.\n",
            "\n",
            "Caption = [/INST] Based on the description provided, it is not clear that the people in the cartoon are couples, or that they are involved in a divorce or legal proceedings. Therefore, neither caption A nor B is the best choice.\n",
            "\n",
            "A more ambiguous caption that could fit the scene might be \"Jury Duty,\" but without additional context, it's impossible to definitively choose a caption based on the information given.</s>\n",
            "Row 97: Predicted - B, Correct - A, Running Accuracy: 37.11%, Running F1 Score: 0.3500\n",
            "Number of Input Tokens:   318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a restaurant\n",
            "    Description: There is a man carrying a garbage can in a restaurant. He is bringing it to a table with another waiter, who is talking to some customers.\n",
            "    Uncanny Aspect: A waiter is carrying a garbage can to a table at a restaurant?\n",
            "    Question: ['Why is the waiter bringing a garbage can to the table in the restaurant?']\n",
            "    Additional Details: scene: a restaurant description: There is a man carrying a garbage can in a restaurant. He is bringing it to a table with another waiter, who is talking to some customers. uncanny: A waiter is carrying a garbage can to a table at a restaurant? entities: Waste_container, Waiting_staff. choices: A: I miss my mask. B: Define fresh.\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I miss my mask.\n",
            "B: Define fresh.\n",
            "\n",
            "Caption = [/INST] Based on the information provided in the cartoon description and the context of the given uncanny aspect and question, neither caption option A nor caption option B appears to be an appropriate fit for the scene. The cartoon description clearly states that a waiter is carrying a garbage can to a table at a restaurant, and there's no suggested link between masks or defining fresh in this scenario. Therefore, neither caption option A nor option B is the best choice.\n",
            "\n",
            "Without any additional\n",
            "Row 98: Predicted - B, Correct - B, Running Accuracy: 37.76%, Running F1 Score: 0.3557\n",
            "Number of Input Tokens:   327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: the living room\n",
            "    Description: There is a family in chairs and a sofa. They are gathered together. Jail cell bars are around them.\n",
            "    Uncanny Aspect: There are jail cell bars around them.\n",
            "    Question: ['Why is the family room jailed off?']\n",
            "    Additional Details: scene: the living room description: There is a family in chairs and a sofa. They are gathered together. Jail cell bars are around them. uncanny: There are jail cell bars around them. entities: Prison_cell, Therapy. choices: A: I'd love to come, but you know the old ball and chain. B: I forget, are we \"gated community\" or \"medium security\"?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: I'd love to come, but you know the old ball and chain.\n",
            "B: I forget, are we \"gated community\" or \"medium security\"?\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and the given caption choices, the best caption is A: \"I'd love to come, but you know the old ball and chain.\" The reason is that the uncanny aspect of the cartoon is the presence of jail cell bars, which strongly suggest that the family is in some kind of detention or imprisonment. The caption A plays on this theme by using the metaphor of a ball and chain to describe a constraint on someone's\n",
            "Row 99: Predicted - B, Correct - A, Running Accuracy: 37.37%, Running F1 Score: 0.3509\n",
            "Number of Input Tokens:   309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\n",
            "    <s> [INST]\n",
            "\n",
            "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
            "    You will be provided with a description of a New Yorker cartoon.\n",
            "    You must use the cartoon description information to decide which of the caption options is best.\n",
            "\n",
            "    You must output either A, B immediately following \"Caption = \"\n",
            "\n",
            "    Cartoon Description:\n",
            "    Location: a residential home\n",
            "    Description: Two people are looking at their house. It has been caved in by a giant piano.\n",
            "    Uncanny Aspect: The piano is way larger than any piano should be.\n",
            "    Question: ['Who dropped the piano on the house?']\n",
            "    Additional Details: scene: a residential home description: Two people are looking at their house. It has been caved in by a giant piano. uncanny: The piano is way larger than any piano should be. entities: Piano, Demolition. choices: A: This is the only house I could find under a grand. B: Wow! Did that just fall off the beanstalk?\n",
            "\n",
            "    Based on the descriptions provided above, which of the following captions is best?\n",
            "\n",
            "    Caption Choices:\n",
            "    A: This is the only house I could find under a grand.\n",
            "B: Wow! Did that just fall off the beanstalk?\n",
            "\n",
            "Caption = [/INST] Based on the cartoon description and uncanny aspect provided, neither caption A nor caption B are ideal. The provided captions do not directly reference the giant, uncanny piano that is the focus of the cartoon.\n",
            "\n",
            "A more fitting caption could be something like: \"C: Well, at least we'll be the talk of the neighborhood. D: What's a piano doing out in the street, anyway?\"\n",
            "\n",
            "These options acknowledge the unusual situation in the\n",
            "Row 100: Predicted - B, Correct - A, Running Accuracy: 37.00%, Running F1 Score: 0.3461\n",
            "Final Accuracy: 37.0000%\n",
            "Final F1 Score: 0.3461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Wiki Context"
      ],
      "metadata": {
        "id": "l4aUVAyHYvU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_caption_wiki(dataframe_row):\n",
        "\n",
        "    # example prompt from Mistral Model Card = \"<s>[INST] What is your favourite condiment? [/INST]\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "    <s>[INST]\n",
        "\n",
        "    Pretend you are a New Yorker Cartoon Caption expert, great at ranking cartoon captions.\n",
        "    You will be provided with a description of a New Yorker cartoon.\n",
        "    You must use the cartoon description information to decide which of the caption options is best.\n",
        "\n",
        "    You must output either A, B immediately following \"Caption = \"\n",
        "\n",
        "    Cartoon Description:\n",
        "    Location: {dataframe_row['image_location']}\n",
        "    Description: {dataframe_row['image_description']}\n",
        "    Uncanny Aspect: {dataframe_row['image_uncanny_description']}\n",
        "    Question: {dataframe_row['questions']}\n",
        "    Additional Details: {dataframe_row['from_description']}\n",
        "    Wikipedia Summaries:\n",
        "    \"\"\"\n",
        "\n",
        "    entities = dataframe_row['entities']\n",
        "    for entity in entities:\n",
        "        wiki_summary = wiki_context(entity)\n",
        "        prompt += f\"{wiki_summary} \\n\"\n",
        "\n",
        "    prompt += f\"\"\"Based on the descriptions and Wikipedia summaries provided above, which of the following captions is best? \\n     You must output either A, B immediately following \"Caption = \" \\n Caption Choices:\\n\"\"\"\n",
        "\n",
        "    # Adding caption choices\n",
        "    captions = dataframe_row['caption_choices']\n",
        "    for index, caption in enumerate(captions):\n",
        "        prompt += f\"{chr(65 + index)}: {caption}\\n\"\n",
        "\n",
        "    prompt += \"\\nCaption = [/INST]\"\n",
        "    # prompt += \"\\nWhich letter best describes the caption for the cartoon? Choose A, B, C, D, or E.\"\n",
        "    # prompt += \"\\nChoose A, B, C, D, or E based on the description above: \"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    print(\"Number of Input Tokens:  \", inputs.input_ids.size(1))    #prints number of input tokens as check for context length\n",
        "\n",
        "    generated_ids = model_4bit.generate(**inputs, max_new_tokens=100, num_return_sequences=1, do_sample=True)\n",
        "    output_text = tokenizer.batch_decode(generated_ids)[0]\n",
        "\n",
        "    print(output_text)\n",
        "\n",
        "    match = re.search(r\"Caption = \\[/INST\\] ([A-B])\", output_text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return \"No valid prediction found\"\n",
        "\n",
        "\n",
        "predicted_caption = evaluate_caption_wiki(sample_train_rank.iloc[10])\n",
        "print(\"The model predicts caption:\", predicted_caption)"
      ],
      "metadata": {
        "id": "lJyTgUkqY73t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate_model_accuracy(sample_train, num_rows):\n",
        "    correct_predictions = 0\n",
        "    true_labels = []\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_rows):\n",
        "        predicted_caption = evaluate_caption_wiki(sample_train.iloc[i])\n",
        "        correct_choice = sample_train.iloc[i]['label']\n",
        "\n",
        "        true_labels.append(correct_choice)\n",
        "        predictions.append(predicted_caption)\n",
        "\n",
        "        if predicted_caption == correct_choice:\n",
        "            correct_predictions += 1\n",
        "\n",
        "        accuracy = (correct_predictions / (i + 1)) * 100\n",
        "        running_f1 = f1_score(true_labels, predictions, average='weighted', labels=['A', 'B'])\n",
        "\n",
        "        print(f\"Row {i+1}: Predicted - {predicted_caption}, Correct - {correct_choice}, \"f\"Running Accuracy: {accuracy:.2f}%, Running F1 Score: {running_f1:.4f}\")\n",
        "\n",
        "    final_accuracy = (correct_predictions / num_rows) * 100\n",
        "    final_f1_score = f1_score(true_labels, predictions, average='weighted', labels=['A', 'B'])\n",
        "\n",
        "    return final_accuracy, final_f1_score\n",
        "\n",
        "accuracy, f1_score = evaluate_model_accuracy(sample_train_rank, 100)\n",
        "print(f\"Final Accuracy: {accuracy:.4f}%\")\n",
        "print(f\"Final F1 Score: {f1_score:.4f}\")"
      ],
      "metadata": {
        "id": "8EYDq8Dnbof1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 - RAG Context Set-Up"
      ],
      "metadata": {
        "id": "DQQiXIq3tJkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following Example from Mistral Docs https://docs.mistral.ai/guides/rag/"
      ],
      "metadata": {
        "id": "m9LXDZJ6tdY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mistralai.client import MistralClient, ChatMessage\n",
        "import numpy as np\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "78Oe2ylZtJUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into Chunks\n",
        "\n",
        "chunk_size = 2048\n",
        "chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "len(chunks)"
      ],
      "metadata": {
        "id": "DQS3qJSHtZNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Embeddings\n",
        "\n",
        "def get_text_embedding(input):\n",
        "    embeddings_batch_response = client.embeddings(\n",
        "          model=\"mistral-embed\",\n",
        "          input=input\n",
        "      )\n",
        "    return embeddings_batch_response.data[0].embedding\n",
        "text_embeddings = np.array([get_text_embedding(chunk) for chunk in chunks])"
      ],
      "metadata": {
        "id": "OxYGYl62tZTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load into Vector Database\n",
        "\n",
        "import faiss\n",
        "\n",
        "d = text_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(text_embeddings)"
      ],
      "metadata": {
        "id": "rAEZHJ9UtZcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Embeddings for a Question\n",
        "\n",
        "question = \"What were the two main things the author worked on before college?\"\n",
        "question_embeddings = np.array([get_text_embedding(question)])"
      ],
      "metadata": {
        "id": "bkdyZ8wCtypG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retreive Relevant Chunks\n",
        "\n",
        "D, I = index.search(question_embeddings, k=2) # distance, index\n",
        "retrieved_chunk = [chunks[i] for i in I.tolist()[0]]"
      ],
      "metadata": {
        "id": "j-n_aLZCt3BY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt Example\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Context information is below.\n",
        "---------------------\n",
        "{retrieved_chunk}\n",
        "---------------------\n",
        "Given the context information and not prior knowledge, answer the query.\n",
        "Query: {question}\n",
        "Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "CvZrjVgit7xS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}